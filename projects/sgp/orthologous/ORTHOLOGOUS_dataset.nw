% -*- mode: Noweb; noweb-code-mode: perl-mode; tab-width: 4 -*-
\documentclass[11pt]{article}
%
%2345678901234567890123456789012345678901234567890123456789012345678901234567890
%        1         2         3         4         5         6         7         8
%
% $Id: ORTHOLOGOUS_dataset.nw,v 1.2 2001-08-17 17:35:27 jabril Exp $
%
\usepackage{noweb}
\usepackage[a4paper,offset={0pt,0pt},hmargin={2cm,2cm},vmargin={1cm,1cm}]{geometry}
\usepackage{graphics}
\usepackage[dvips]{graphicx}
%% pstricks
\usepackage[dvips]{pstcol}
\usepackage{pstricks}
%\usepackage{pst-node}
%\usepackage{pst-char}
%\usepackage{pst-grad}
%% bibliography
\usepackage{natbib}
%% latex2html
\usepackage{url}
\usepackage{html}     
\usepackage{htmllist} 
%% tables    
%\usepackage{colortbl}
%\usepackage{multirow}
%\usepackage{hhline}
%\usepackage{tabularx}
%\usepackage{dcolumn}
%% seminar
%\usepackage{semcolor,semlayer,semrot,semhelv,sem-page,slidesec}
%% draft watermark
%\usepackage[all,dvips]{draftcopy}
%\draftcopySetGrey{0.9}
%\draftcopyName{CONFIDENTIAL}{100}
%% layout
\usepackage{fancyhdr} % Do not use \usepackage{fancybox} -> TOCs disappear
%\usepackage{lscape}
\usepackage{rotating}
%\usepackage{multicol}
%% fonts
\usepackage{times}\fontfamily{ptm}\selectfont
\usepackage{t1enc}

% noweb options
\noweboptions{smallcode}
\def\nwendcode{\endtrivlist \endgroup} % relax page breaking scheme
\let\nwdocspar=\par                    %
 
% Colors for gff2ps
\input ColorDefs.tex
% New Commands are defined here
\newcommand{\sctn}[1]{\section{#1}}
\newcommand{\subsctn}[1]{\subsection{#1}}
\newcommand{\subsubsctn}[1]{\subsubsection{#1}}
\newcommand{\subsubsubsctn}[1]{\paragraph{#1}\vskip 1ex}
\newcommand{\desc}[1]{\item[#1] \ \\}

% PSTRICKs definitions
\pslongbox{ExFrame}{\psframebox}
\newcommand{\cln}[1]{\fcolorbox{black}{#1}{\textcolor{#1}{\rule[-.3ex]{1cm}{1ex}}}}
\newpsobject{showgrid}{psgrid}{subgriddiv=0,griddots=1,gridlabels=6pt}
% \pscharpath[fillstyle=solid, fillcolor=verydarkcyan, linecolor=black, linewidth=1pt]{\sffamily\scshape\bfseries\veryHuge #1 }

%%%%% global urls
% \newcommand{\getpsf}[1]{\html{(\htmladdnormallink{Get PostScript file}{./Psfiles/#1})}}   
\def\mtjabril{\htmladdnormallink{\textbf{jabril@imim.es}}{MAILTO:jabril@imim.es?subject=[ORTHOLOGOUS SET]}}
\def\mthomology{\htmladdnormallink{\textbf{homology@viaken.com}}{MAILTO:homology@viaken.com?subject=[HOMOLOGY]}}

% defs
\def\drome{\textit{Drosophila melanogaster}}
\def\dro{\textit{Drosophila}}
\def\dme{\textit{D. melanogaster}}
\def\seq{\texttt{\textbf{X62937}}}
\def\nowf{[[DromeRepeats.nw]]}
\def\biop{\textsc{BioPerl}}
\def\rptm{\textsc{RepeatMasker}}
\def\bl{\textsc{Blast}}
\def\bn{\textsc{blastn}}
\def\bx{\textsc{blastx}}
\def\bp{\textsc{blastp}}
\def\tbn{\textsc{tblastn}}
\def\tbx{\textsc{tblastx}}
\def\pb{\texttt{parseblast}}
\def\ps{\textsc{PostScript}}
\def\gnid{\texttt{geneid}}
\def\gnsc{\texttt{genscan}}
\def\twsc{\texttt{twinscan}}
\def\slam{\textsc{slam}}
\def\sgp{\textsc{sgp}}
\def\gps{\texttt{gff2ps}}
\def\aps{\texttt{aplot}}
\def\data{\textbf{Human/Mouse Orthologous}}

% Setting text for footers and headers

\def\tit{\textsc{ORTHOLOGOUS Dataset}}
\fancyhead{} % clear all fields
\fancyfoot{} % clear all fields
\fancyhead[RO,LE]{\thepage}
\fancyhead[LO,RE]{\rightmark}
\fancyfoot[LO,LE]{\small\textbf{Genome Informatics Research Lab}}
\fancyfoot[CO,CE]{\small\textsl{Abril, JF}}
\fancyfoot[RO,RE]{\small\textbf{\today}}
\renewcommand{\headrulewidth}{1pt}
\renewcommand{\footrulewidth}{1pt}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{document}
@ 
\thispagestyle{empty}

\begin{titlepage}

\ \vfill
\begin{center}
\textsc{\textbf{\Huge Building\\ ORTHOLOGOUS\\[1ex] Dataset}}\\[5ex]

%\textbf{\Large Authors List Here}\\[1ex]
\textbf{\Large Josep F. Abril}\\[5ex] % \raisebox{0.85ex}{\footnotesize$\,\dag$}\\[0.5ex]

\textbf{\large --- \today ---}\\[10ex]

\begin{abstract}
\begin{center}
\parbox{0.75\linewidth}{
} % parbox
\end{center}
\end{abstract}

\vfill

\begin{raggedleft}
\scalebox{0.9 1}{\Large\textsl{\textbf{Genome Informatics Research Lab}}}\\
Grup de Recerca en Infom\`atica Biom\`edica\\
Institut Municipal d'Investigaci\'o M\`edica\\
Universitat Pompeu Fabra\\[2ex]
\raisebox{0.85ex}{\footnotesize$\dag\,$}{\large e-mail: \mtjabril}\\
\end{raggedleft}
\end{center}

\end{titlepage} %'

%%%%%%%%%%%%%%%%%%%% FRONTMATTER

\newpage
\pagenumbering{roman}
\setcounter{page}{1}
\pagestyle{fancy}
% Marks redefinition must go here because pagestyle 
% resets the values to the default ones.
\renewcommand{\sectionmark}[1]{\markboth{}{\thesection.\ #1}}
\renewcommand{\subsectionmark}[1]{\markboth{}{\thesubsection.\ \textsl{#1}}}

\tableofcontents
\listoftables
\listoffigures

\vfill
\begin{center}
{\small$<$ \verb$Id: ORTHOLOGOUS_dataset.nw,v 1.2 2001-08-17 17:35:27 jabril Exp $$>$ }
\end{center}

%%%%%%%%%%%%%%%%%%%% MAINMATTER

\newpage
\pagenumbering{arabic}
\setcounter{page}{1}

\sctn{Introduction}

Sequence comparisons at nucleotide/aminoacid level among phylogenetically related species would help to produce better annotations and to find new genes, as it has been suggested in the literature. At this moment, in which it has been obtained the first draf of the human genome and the mouse genome project is reaching a good sequence coverage, that approach will we useful in the re-annotation of the current human genes and in the search of novel human genes. 
\begin{comment}
Homology between human and mouse sequences serves as a useful guide for identifying genes in both organisms. Additionally, conserved sequences that have no coding potential are good candidates for regulatory elements.
-- From \url|http://bio.cse.psu.edu/mousegroup/doc.html|
An annotation of the orthologous test set of genomic sequences and their regulatory regions is available at \url|http://bio.cse.psu.edu/mousegroup/test8/|
\end{comment}

This document contains the procedures we followed to train our gene-prediction tools in order to find the optimal parameters which raise the most accurate predictions. All the command-line scripts are detailed on the main sections, while stand-alone scripts are described and implemented in the appendixes. There you can also find the results for some of the analysis performed on the sequences. 

\subsctn{Main goals}

\subsctn{Protocol outline}

Here we are drawing the main steps we followed 

\begin{description}
 \item[Masking Sequences]
 \item[Homology Search]
 \item[Gene-Finding]
 \item[Syntenic Gene-Prediction]
 \item[Sequence Analysis] \ \\
   \begin{description}
    \item[G+C Content]
    \item[Splice Sites Distribution]
    \item[Exonic Structure Conservation]
   \end{description}
\end{description}

\subsctn{The sequences test set}

It was agreed to test gene-prediction programs on a eight sequences set that are syntenic between human and mouse. They were published at '\url|http://zilla.lbl.gov/TESTS/|', there is also an active mailing list at {\mthomology}. Table~\ref{tbl:seqnames} lists sequence names, their lengths for human and mouse, and the number of annotated genes contained in each.\\

\begin{comment}
<<BASH commands>>=
gawk '{ print $1 }' $DATASETS/genes.Hsap | sort | uniq -c
      5 Hsap_BTK
      2 Hsap_CFTR
      1 Hsap_DFNA5
      6 Hsap_ELN
     11 Hsap_HOXA
     19 Hsap_KVLQT1
     93 Hsap_MHC
      3 Hsap_SIL
gawk '{
        printf "%-12s %6.1f Kb\n",$1,$2/1000;
        }' $DATASETS/length.Hsap $DATASETS/length.Mmus 
Hsap_BTK       78.9 Kb
Hsap_CFTR     424.8 Kb
Hsap_DFNA5    243.3 Kb
Hsap_ELN      388.7 Kb
Hsap_HOXA     219.2 Kb
Hsap_KVLQT1  1279.4 Kb
Hsap_MHC     2358.6 Kb
Hsap_SIL      305.9 Kb
Mmus_BTK       88.9 Kb
Mmus_CFTR     357.9 Kb
Mmus_DFNA5    206.4 Kb
Mmus_ELN      269.2 Kb
Mmus_HOXA     202.1 Kb
Mmus_KVLQT1  1013.6 Kb
Mmus_MHC     1521.2 Kb
Mmus_SIL      234.4 Kb
@ 
\end{comment}
\begin{table}[!ht]
\begin{center}
\begin{tabular}{|c|r|r|c|l|}\hline
\textbf{Region} & \multicolumn{2}{c|}{\textbf{Sequence Length}} & \textbf{\#Gen} & \textbf{Comment} \\\cline{2-3}
           & \textbf{Human} & \textbf{Mouse} & & \\\hline\hline
BTK        &   78.9 Kb &   88.9 Kb &  5 &             \\
CFTR       &  424.8 Kb &  357.9 Kb &  2 & "Gene poor" \\
DFNA5      &  243.3 Kb &  206.4 Kb &  1 &             \\
ELN        &  388.7 Kb &  269.2 Kb &  6 & (Elastin)   \\
HOXA       &  219.2 Kb &  202.1 Kb & 11 & repeat poor \\
KVLQT1     &    1.3 Gb &    1.0 Gb & 19 &             \\
MHC        &    2.4 Gb &    1.5 Gb & 93 & repeat rich \\
SIL        &  305.9 Kb &  234.4 Kb &  3 &             \\[1.5ex]
								     
Chrom 22   &          &  4 Mb    &    & \raisebox{-2ex}{\shortstack[l]{Ongoing discussion to choose\\GoldenPath or Sanger Center Version}} \\\hline
\end{tabular}
\caption{\label{tbl:seqnames} Official human/mouse homologous sequences set.}
\end{center}
\end{table}

{\data} database contains those 8 pairs of orthologous sequences from human and mouse. Table~\ref{tbl:genelist} on page~\pageref{tbl:genelist} lists the gene identifiers already annotated for each human sequence.


\newpage %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\sctn{Building orthologous dataset}

\subsctn{Downloading Data set}

The first sequence dataset was obtained from '\url|http://waldo.wi.mit.edu/~danb/HomologSeqs/|'. There were some differences between that set and the one used by {\twsc} gene-prediction team, coordinates mapped from ??Sanger?? and Golden Path did not match well. Those differences did our program, {\gnid}, to make predictions that were not comparable to the {\twsc} ones (so after their evaluation our program did pretty bad predictions).

Next dataset was agreed to be available from '\url|http://zilla.lbl.gov/TESTS/|'. We found ``duplicated'' genes in the original files from that site, in three of the test sequences:

\begin{center}
\begin{tabular}{cl}
Hsap\_ELN    & WBSCR5, LIMK1 \\
Hsap\_KVLQT1 & TSSC4 \\
Hsap\_MHC    & TAP2, LTB, HSPA1A, HSPA1B, AIF1, TNXA/TNXB \\
\end{tabular}
\end{center}

Those duplications correspond to alternative splicing forms, but it is not clear yet how we have to deal with them, so that we have discarded the shorter gene or the gene with less exons (in TNXA/TNXB case, which exons were overlapping ---or the same---, we removed TNXA). 
 
<<BASH commands DATASETS>>=
#
# DOWNLOADING DataSets
wget -b --no-parent --mirror --tries=0  \
     --output-file=download_orthologous.log    \
     --no-host-directories --cut-dirs=1 \
     'http://zilla.lbl.gov/TESTS/'
#
@
\begin{comment}
# 
# http://zilla.lbl.gov/VISTAS/Chr6/NT_002572/Mm.fasta
\end{comment}
 

\subsctn{Preparing files for the analysis}

\subsubsctn{Writing files for sequence IDs}

Here, we assign human and mouse locus names to each sequence in the test set, the locus names will serve as file names either as indexes in some scripts.\\

\begin{table}[!ht]
\begin{center}
\begin{tabular}{|@{\quad}c@{\quad}|c}\cline{1-1}
\begin{minipage}[b]{8cm}
\vskip 1ex
<<Sequence IDs>>=
BTK     Hsap_BTK     Mmus_BTK
CFTR    Hsap_CFTR    Mmus_CFTR
DFNA5   Hsap_DFNA5   Mmus_DFNA5
ELN     Hsap_ELN     Mmus_ELN
HOXA    Hsap_HOXA    Mmus_HOXA
KVLQT1  Hsap_KVLQT1  Mmus_KVLQT1
MHC     Hsap_MHC     Mmus_MHC
SIL     Hsap_SIL     Mmus_SIL
@
\vskip 1ex
\end{minipage}
&
\hspace{1em}\parbox[b]{5cm}{\caption{\label{tbl:seqIDs} Contents of the main IDs file which was generated tangling this table from the document.}}
\\\cline{1-1}
\end{tabular}
\end{center}
\end{table}

<<BASH commands DATASETS>>=
#
# Extracting IDs from main document.
notangle -R"Sequence IDs" $WORK/$nwfile.nw > $ID ;
#
perl -ane 'print "$F[1]\n"' $ID > $HSAP ;
perl -ane 'print "$F[2]\n"' $ID > $MMUS ;
#
cat $HSAP $MMUS > $ID.all ;
#
@

\subsubsctn{Moving and renaming fasta files}

We move fasta files from the download directories to the corresponding ones. Furthermore, we filter them through [[fasta_renamer.pl]] not only to rename ID record to hold the same string as the file name, but to normalize length for all the sequence records in each fasta file.

<<BASH commands DATASETS>>=
#
# MOVING and RENAMING fasta files
ChckDirs $DATASETS/fasta $DATASETS/fasta/raw $DATASETS/fasta/masked \
         $DATASETS/fasta/orimasked $DATASETS/fasta/softmasked \
         $DATASETS/annotation $DATASETS/annotation/desc ;
#
# Preparing fasta files
IDIR="$DATASETS/_tmp" ;
ODIR="$DATASETS/fasta/raw" ;
while read locus human mouse ;
  do {
    $BIN/fasta_renamer.pl $IDIR/$locus/Hs.fasta \
        $DATASETS/annotation/desc/Hsap_$locus Hsap_$locus \
        > $ODIR/Hsap_$locus;
    $BIN/fasta_renamer.pl $IDIR/$locus/Mm.fasta \
        $DATASETS/annotation/desc/Mmus_$locus Mmus_$locus \
        > $ODIR/Mmus_$locus;
    } ;
  done < $ID ;
MergeFiles $ODIR ;
#
# The same if masked files where provided
IDIR="$DATASETS/_tmp" ;
ODIR="$DATASETS/fasta/orimasked" ;
while read locus human mouse ;
  do {
    $BIN/fasta_renamer.pl $IDIR/$locus/Hs.fasta.masked \
        $DATASETS/annotation/desc/Hsap_$locus.msk Hsap_$locus \
        > $ODIR/Hsap_$locus;
    $BIN/fasta_renamer.pl $IDIR/$locus/Mm.fasta.masked \
        $DATASETS/annotation/desc/Mmus_$locus.msk Mmus_$locus \
        > $ODIR/Mmus_$locus;
    } ;
  done < $ID ;
MergeFiles $ODIR ;
#
@

\subsubsctn{Getting lengths from description files}

<<BASH commands DATASETS>>=
#
IDIR="$DATASETS/annotation/desc" ;
multicat ()
{
  cat "$@" | while read n ;
    do {
      cat $DATASETS/annotation/desc/$n ;
      } ;
    done;
}
multicat $HSAP | gawk '{printf "%-12s%8s\n",$1,$3}' - > $DATASETS/length.Hsap;
multicat $MMUS | gawk '{printf "%-12s%8s\n",$1,$3}' - > $DATASETS/length.Mmus;
@

\subsctn{Masking fasta sequences}

<<BASH commands DATASETS>>=
#
# MASKING FASTA SEQUENCES
ChckDirs $DATASETS/masking ;
# Running RepeatMasker
run_RptMsk ()
{
  #
  # run_RptMsk - Running RepeatMasker
  #
  # USAGE: run_RptMsk options workdir fastadir outputdir IDsfile
  #
  # 'options' RepeatMasker command-line options
  # 'workdir' temporary path for RepeatMasker files
  # 'fastadir' where to get from input fasta files
  # 'outputdir' where to save masked fasta files
  # 'IDsfile' IDs to loop 
  #
  CMD="RepeatMasker $1"; WDIR=$2 ; FDIR=$3 ; ODIR=$4 ; TID=$5 ;
  #
  ChckDirs $WDIR $WDIR/tmp $WDIR/gff $WDIR/gff-projection $ODIR ;
  #
  WDIR="$WDIR/tmp" ;
  while read locus ; 
    do {
      echo "### REPEAT MASKING ON $locus ..." ;
      cp -v $FDIR/$locus $WDIR/$locus ;
      # 8 procs at monstre
      $CMD $WDIR/$locus ;
      /bin/rm -v $WDIR/$locus ;
      mv -v $WDIR/$locus.masked $ODIR/$locus;
      #
      };
    done < $TID ;
}
#
@ 

<<BASH commands DATASETS>>=
#
RptMsk2GFF ()
{
  #
  # RptMsk2GFF - Converting RepeatMasker repeats table into GFF
  #
  # USAGE: RptMsk2GFF fastadir outputdir logsdir IDsfile [options]
  #
  # 'fastadir' where to get from input masked fasta files
  # 'outputdir' where to save GFF files
  # 'logsdir' where to save logs
  # 'IDsfile' IDs to loop
  # 'options' options for getfastamasked.pl
  #           '-s|--softmasked' if masked fasta file is softmasked
  #                             (lowercase instead of "N"s)
  #
  IDIR=$1 ;
  ODIR=$2 ;
  LDIR=$3 ;
  TID=$4 ;
  OPTS=$5 ;
  #
  ChckDirs $ODIR $LDIR;
  #
  while read locus ;
    do {
      #
      echo "### FINDING MASKED REGIONS COORDS ON $locus ..." ;
      $BIN/getfastamasked.pl $OPTS < $IDIR/$locus > $ODIR/$locus \
                                                 2> $LDIR/$locus ;
      };
    done < $TID ;
}
#
@ 

<<BASH commands DATASETS>>=
#
FastaMsk2GFF ()
{
  #
  # FastaMsk2GFF - Finding masked regions in fasta files and saving into GFF
  #
  # USAGE: FastaMsk2GFF inputdir outputdir IDsfile
  # 
  # 'inputdir' where to get from the RepeatMasker repeats table
  # 'outputdir' where to save GFF files
  # 'IDsfile' IDs to loop
  #
  IDIR=$1 ;
  ODIR=$2 ;
  TID=$3 ;
  #
  ChckDirs $ODIR $LDIR;
  #
  while read locus ;
    do {
      echo "### REPEATS TBL TO GFF - WORKING ON $locus ..." ;
      gawk 'BEGIN{ OFS="\t" }
        NR>3{
          str = ($9!="C") ? "+" : "-";
          print $5,"RepeatMasker",$11,$6,$7,$1,str,".",$10"."NR-3;
        }' $IDIR/$locus.out \
         > $ODIR/$locus ;
      };
    done < $TID ;
}
#
@

\subsubsctn{Downloaded masked fasta sequences} 

Here we retrieve masked regions coords from 'orimasked' fasta files

<<BASH commands DATASETS>>=
#
# Retrieving masked regions coords for orimasked fasta files
WDIR="$DATASETS/masking/orimasked" ;
ChckDirs $WDIR $WDIR/gff $WDIR/gff-projection $WDIR/tmp $WDIR/logs ;
while read locus human mouse ;
  do { 
    cp -v $DATASETS/_tmp/$locus/Hs.fasta.out $WDIR/tmp/Hsap_$locus.out ;
    cp -v $DATASETS/_tmp/$locus/Mm.fasta.out $WDIR/tmp/Mmus_$locus.out  ;
    } ;
  done < $ID ;
#
RptMsk2GFF $DATASETS/fasta/orimasked \
           $WDIR/gff-projection $WDIR/logs $ID.all ;
FastaMsk2GFF $WDIR/tmp $WDIR/gff $ID.all ;
#
@ 

\subsubsctn{Masking fasta sequences} 

\subsubsubsctn{Default masking}

<<BASH commands DATASETS>>=
# Masking fasta sequences
WDIR="$DATASETS/masking/default" ;
run_RptMsk "-parallel 8" $WDIR \
           $DATASETS/fasta/raw $DATASETS/fasta/masked $ID.all ;
RptMsk2GFF $DATASETS/fasta/masked \
           $WDIR/gff-projection $WDIR/logs $ID.all ;
FastaMsk2GFF $WDIR/tmp $WDIR/gff $ID.all ;
#
@

\subsubsubsctn{Soft masking (lowercase symbols)} (!!! TO DO !!!)

<<BASH commands DATASETS>>=
# Masking fasta sequences (with softmask options)
WDIR="$DATASETS/masking/softmasked" ;
run_RptMsk "-parallel 8 -xsmall" $WDIR \
           $DATASETS/fasta/raw $DATASETS/fasta/softmasked $ID.all ;
RptMsk2GFF $DATASETS/fasta/softmasked \
           $WDIR/gff-projection $WDIR/logs $ID.all '-s';
FastaMsk2GFF $WDIR/tmp $WDIR/gff $ID.all ;
#
@

\subsctn{Mapping annotations to GFF}

<<BASH commands DATASETS>>=
#
ChckDirs $DATASETS/annotation $DATASETS/annotation/coords \
         $DATASETS/annotation/fullgff $DATASETS/annotation/gff \
         $DATASETS/annotation/gtf2 $DATASETS/annotation/cds ;
#
IDIR="$DATASETS/_tmp" ;
ODIR="$DATASETS/annotation" ;
while read locus human mouse ;
  do {
    #
    # due to a problem with alternative splicing forms 
    # I must edit some $ODIR/coords/ files by hand ...
    #
 #  cp -vf $IDIR/$locus/Hs.exons.refGene $ODIR/coords/$human ;
    #
    gawk '$3 !~ "utr" { print $0 }' $ODIR/coords/$human > $ODIR/cds/$human ;
    gawk 'BEGIN{ seq=ARGV[1]; ARGV[1]="" }
          $1  ~ "#" { print $0 }
          $1 !~ "#" { $1=seq; print $0 }' $locus \
          $IDIR/$locus/Hs.exons.refGene.GFF2 \
          > $ODIR/fullgff/$human ;
    $BIN/coords2gff.pl $human < $ODIR/cds/$human > $ODIR/gff/$human
    # gawk '$3==CDS { print $0 }' $ODIR/fullgff/$human > $ODIR/gff/$human ;
    $BIN/gff2gtf.pl < $ODIR/gff/$human > $ODIR/gtf2/$human ;
    } ;
  done < $ID ;
#
# Preparing GFF files for evaluation program:
MergeGFF $DATASETS/annotation/gff Hsap 1 ;
#
@

\subsctn{Other auxiliary files}

<<BASH commands DATASETS>>=
#
gawk '$3 == "Gene" {print $1,$9,$4,$5,$7}' $DATASETS/annotation/gff/Hsap_* \
                                           > $DATASETS/genes.Hsap ;
cat $DATASETS/annotation/desc/Hsap_*[^.msk] > $DATASETS/desc.Hsap ;
cat $DATASETS/annotation/desc/Mmus_*[^.msk] > $DATASETS/desc.Mmus ;
#
ChckDirs $DATASETS/annotation/length ;
gawk 'BEGIN{
    OFS="\t";
    opath=ARGV[1];
    ARGV[1]="";
  }
  {
    file= opath "/" $1;
    # split($1,n,"_");
    # name=n[2];
    name=$1;
    print "# Writing to ", file | "cat 1>&2";
    printf "%s\tannotation\tSequence\t1\t%s\t.\t.\t.\t.\n", name, $2 > file;
  }' $DATASETS/annotation/length $DATASETS/length.Hsap $DATASETS/length.Mmus ;
#
@

\subsctn{Building WU-BLAST databases (only for mouse seqs)}

<<BASH commands DATASETS>>=
#
ChckDirs $DATASETS/blastdb ;
WDIR="$DATASETS/blastdb/wublast" ;
ChckDirs $WDIR $WDIR/raw $WDIR/masked $WDIR/orimasked $WDIR/softmasked ;
#
IDIR="$DATASETS/fasta" ;
ODIR="$DATASETS/blastdb/wublast" ;
{ cat $MMUS; echo "all.Mmus"; } | while read n ;
  do {
    echo "### WORKING ON $n RAW" ;
    pressdb $IDIR/raw/$n        -o $ODIR/raw/$n        ;
    echo "### WORKING ON $n ORIMASKED" ;
    pressdb $IDIR/orimasked/$n  -o $ODIR/orimasked/$n  ;
    echo "### WORKING ON $n MASKED" ;
    pressdb $IDIR/masked/$n     -o $ODIR/masked/$n     ;
    echo "### WORKING ON $n SOFTMASKED" ;
    pressdb $IDIR/softmasked/$n -o $ODIR/softmasked/$n ;
    } ;
  done ;
#
@

\newpage %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\sctn{Homology Search}

\subsctn{Running {\tbx} on ALEPH server}

<<BASH commands ANALYSIS>>=
#
# Running in /home/ug/jabril/no_backup/PBS
BASE="/home/ug/jabril/no_backup/PBS" ;
WGS="/seq/genomes/M.musculus/WGS/wublast8" ;
WGS3X="$WGS/Mm.WGS001_010 $WGS/Mm.WGS010_020 $WGS/Mm.WGS021_030" ;
WGS3X="$WGS3X $WGS/Mm.WGS031_040 $WGS/Mm.WGS041_050 $WGS/Mm.WGS051_060" ;
WGS3X="$WGS3X $WGS/Mm.WGS061_070 $WGS/Mm.WGS071_081" ;
export BASE WGS3X;
#
# loop que encua els fitxers PBS
runpbs ()
{
  while read gene locus mouse ;
    do {
      echo "### Queuing $gene ..." ;
      db="$2" ;
      [ $1 -eq 1 ] && db="$db/$mouse" ;
      export locus db ;
      qsub -V $BASE/PBS.sh ;
      } ;
    done < $BASE/id ;
}
#
#
ChckDirs $BASE $BASE/matrix $BASE/matrix/aa \
    $BASE/fasta $BASE/fasta/raw $BASE/fasta/blastdb \
    $BASE/fasta/blast $BASE/fasta/logs \
    $BASE/fasta/blast3X $BASE/fasta/logs3X \
    $BASE/fastamasked $BASE/fastamasked/raw $BASE/fastamasked/blastdb \
    $BASE/fastamasked/blast $BASE/fastamasked/logs \
    $BASE/fastamasked/blast3X $BASE/fastamasked/logs3X ;
#
#
cp -vapudf $DATASETS/fasta/raw/*                         $BASE/fasta/raw/ ;
cp -vapudf $DATASETS/blastdb/wublast.tblastx/raw/*       $BASE/fasta/blastdb/ ;
cp -vapudf $DATASETS/fasta/orimasked/*                   $BASE/fastamasked/raw/ ;
cp -vapudf $DATASETS/blastdb/wublast.tblastx/orimasked/* $BASE/fastamasked/blastdb/ ;
#
# Working on raw files - ORTHOLOGOUS SEQS
IN="$BASE/fasta/raw" ;
OUT="$BASE/fasta/blast" ;
ERROR="$BASE/fasta/logs" ;
BLASTOPTIONS="Z=3000000000 -nogaps -hspmax=10000 -filter=xnu -matrix=blosum62mod" ; # 
export IN OUT ERROR BLASTOPTIONS ;
pushd $BASE/fasta/logs ;
runpbs 1 "$BASE/fasta/blastdb" ;
popd ;
#
# Working on orimasked files - ORTHOLOGOUS SEQS
IN="$BASE/fastamasked/raw" ;
OUT="$BASE/fastamasked/blast" ;
ERROR="$BASE/fastamasked/logs" ;
BLASTOPTIONS="Z=3000000000 -nogaps -hspmax=10000 -filter=xnu -matrix=blosum62mod" ;
export IN OUT ERROR BLASTOPTIONS ;
pushd $BASE/fastamasked/logs ;
runpbs 1 "$BASE/fastamasked/blastdb" ;
popd ;
#
# Working on raw files - 3X SEQS
IN="$BASE/fasta/raw" ;
OUT="$BASE/fasta/blast3X" ;
ERROR="$BASE/fasta/logs3X" ;
BLASTOPTIONS="-nogaps -hspmax=10000 -filter=xnu -matrix=blosum62mod Z=3000000000" ;
export IN OUT ERROR BLASTOPTIONS ;
pushd $BASE/fasta/logs3X ;
runpbs 0 "$WGS3X" ;
popd ;
#
# Working on orimasked files - 3X SEQS
IN="$BASE/fastamasked/raw" ;
OUT="$BASE/fastamasked/blast3X" ;
ERROR="$BASE/fastamasked/logs3X" ;
BLASTOPTIONS="-nogaps -hspmax=10000 -filter=xnu -matrix=blosum62mod Z=3000000000" ;
export IN OUT ERROR BLASTOPTIONS ;
pushd $BASE/fastamasked/logs3X ;
runpbs 0 "$WGS3X" ;
popd ;
#
#
ChckDirs $ANALYSIS/blast ;
WDIR="$ANALYSIS/blast/wublast.blastn" ;
ChckDirs $WDIR $WDIR/raw   $WDIR/masked   $WDIR/orimasked   $WDIR/softmasked \
               $WDIR/raw3X $WDIR/masked3X $WDIR/orimasked3X $WDIR/softmasked3X ;
WDIR="$ANALYSIS/blast/wublast.tblastx" ;
ChckDirs $WDIR $WDIR/raw   $WDIR/masked   $WDIR/orimasked   $WDIR/softmasked \
               $WDIR/raw3X $WDIR/masked3X $WDIR/orimasked3X $WDIR/softmasked3X ;
#
#
cp -vapudf $BASE/fasta/blast/*         $ANALYSIS/blast/wublast.tblastx/raw/
cp -vapudf $BASE/fastamasked/blast/*   $ANALYSIS/blast/wublast.tblastx/orimasked/
cp -vapudf $BASE/fasta/blast3X/*       $ANALYSIS/blast/wublast.tblastx/raw3X/
cp -vapudf $BASE/fastamasked/blast3X/* $ANALYSIS/blast/wublast.tblastx/orimasked3X/
#
@

<<PBS tblastx shell>>=
#!/bin/bash
#
# PBS.sh - Running tblastx on ALEPH server
#
:
#PBS -e $ERROR/$locus.error
#PBS -o $ERROR/$locus.out
#PBS -q ace@aleph.imim.es
#PBS -V
#
export BLASTMAT="$BASE/matrix/" ;
 [ -e "$OUT/$locus" ]  && /bin/rm $OUT/$locus ;
[ -e "$ERROR/$locus" ] && /bin/rm $ERROR/$locus ;
for mousedb in $db ;
  do {
    echo "### PBS: TBLASTX Working on : $locus x $mousedb" >> $ERROR/$locus ;
    tblastx $mousedb $IN/$locus $BLASTOPTIONS \
            >> $OUT/$locus 2>> $ERROR/$locus ;
    echo "### PBS: TBLASTX ... DONE $mousedb !!!" >> $ERROR/$locus ;
    } ;
  done ;
@

<<BASH commands ANALYSIS>>=
#
WGS="/seq/genomes/M.musculus/WGS/wublast8" ;
WGS3X="$WGS/Mm.WGS001_010 $WGS/Mm.WGS010_020 $WGS/Mm.WGS021_030" ;
WGS3X="$WGS3X $WGS/Mm.WGS031_040 $WGS/Mm.WGS041_050 $WGS/Mm.WGS051_060" ;
WGS3X="$WGS3X $WGS/Mm.WGS061_070 $WGS/Mm.WGS071_081" ;
WDIR="/home/ug/jabril/tmp/projects/masked" ;
BLASTMAT="/home/ug/jabril/tmp/projects/wublast.tblastx/" ;
BLASTOPTIONS="-topcomboN=4 W=5 -filter=xnu+seg Z=3000000000 -nogaps -hspmax=1000000 -matrix=blosum62mod" ;
export WGS3X WDIR BLASTMAT BLASTOPTIONS ;
locus="Hsap_SIL" ; # running on monstre1
locus="Hsap_CFTR" ; # running on monstre2
locus="Hsap_DFNA5" ; # running on monstre3
locus="Hsap_KVLQT1" ; # running on monstre4
for mousedb in $WGS3X ;
  do {
    db=`basename $mousedb` ;
    echo "### TBLASTX Working on : $locus x $db" ;
    tblastx $mousedb $WDIR/$locus $BLASTOPTIONS \
            > $WDIR/$locus.$db.tbx 2> $WDIR/$locus.$db.err &
    } ;
  done ;
#
@

\subsctn{Running {\bn} on orthologous sequences}

<<BASH commands ANALYSIS>>=
#
MergeFiles ../fasta/masked/ ;
MergeFiles ../fasta/softmasked/ ;
#
WDIR="$ANALYSIS/blast/wublast.blastn/masked" ;
ChckDirs $WDIR $WDIR/out $WDIR/gff $WDIR/ps $WDIR/logs ;
BLASTOPTIONS="Z=3000000000 -hspmax=1000000" ; # no filters for nucleotides
while read locus human mouse ;
  do {
    echo "### RUNNING BLASTN on $locus" ;
    blastn $DATASETS/blastdb/wublast/masked/$mouse \
           $DATASETS/fasta/masked/$human $BLASTOPTIONS \
         > $ANALYSIS/blast/wublast.blastn/masked/out/$human.$mouse \
        2> $ANALYSIS/blast/wublast.blastn/masked/logs/$human.$mouse.blastn ;
    } ;
  done < $ID ;
#
while read locus human mouse ;
  do {
    echo "### RUNNING PARSEBLAST on $locus" ;
    parseblast --aplot --full-scores --comments --verbose \
           $ANALYSIS/blast/wublast.blastn/masked/out/$human.$mouse \
         > $ANALYSIS/blast/wublast.blastn/masked/gff/$human.$mouse \
        2> $ANALYSIS/blast/wublast.blastn/masked/logs/$human.$mouse.parseblast ;
    } ;
  done < $ID ;
#
@ 

\subsctn{Comparing results from different {\bl} programs}

We are using {\aps} to visualize the differences among three approaches: {\bn}, {\tbx} and similarity regions filtered by {\sgp} from {\tbx}.

\subsubsctn{Human x FO Mouse sequences}

<<BASH commands ANALYSIS>>=
#
# Running GFF2APLOT
WDIR="$ANALYSIS/blast/wublast.blastn/masked" ;
pushd $WORK/tests/ ; # to force gff2aplot saving default config file there
while read locus human mouse ;
  do {
    echo "### RUNNING PARSEBLAST on $locus" ;
    gff2aplot -PVO $PARAM/gff2aplot/ortho_masked_a4.rc -- \
                   $WDIR/gff/$human.$mouse \
                   $DATASETS/annotation/gff/$human \
                 > $WDIR/ps/$human.$mouse.ps \
                2> $WDIR/logs/$human.$mouse.aplot ;
    } ;
  done < $ID ;
popd ;
WDIR="$ANALYSIS/blast/wublast.blastn/masked" ;
pushd $WORK/tests/ ; # to force gff2aplot saving default config file there
while read locus human mouse ;
  do {
    echo "### RUNNING PARSEBLAST on $locus" ;
    gff2aplot -PV -I a2 -O $PARAM/gff2aplot/ortho_masked_a4.rc -- \
                   $WDIR/gff/$human.$mouse \
                   $DATASETS/annotation/gff/$human \
                 > $WDIR/ps/$human.$mouse.a2.ps \
                2> $WDIR/logs/$human.$mouse.aplot.a2 ;
    } ;
  done < $ID ;
popd ;
#
@ 

\subsubsctn{Customization files for {\gps}}

<<GFF2APLOT customization: ortho masked>>=
## ########################################################################## ##
##                                                                            ##
##                  USER CUSTOMIZATION FILE FOR GFF2APLOT                     ##
##                                                                            ##
## ########################################################################## ##
##
## This is the file in which you can define
##   the OPTIONS and FEATURES required by gff2aplot program.
## 
## If you want to modify this file, please, do not
##   forget to make a backup copy of your old file 
##   (like .gff2aplot.rc.old or .gff2aplot.rc.bck).
##
## Creation Date: 27.01.99
## Last Revision: 20.04.99
##
## Creator: Josep Francesc ABRIL FERRANDO
##
##  e-mail:        jabril@imim.es
##
## ########################################################################## ##
## #################### OPTIONS for gff2aplot PROGRAM ##################### ##
## ########################################################################## ##
##
FL ########################################################################## ##
## #################################### FLAGs ############################### ##
##
## You could set FLAG variables to:
##       0/OFF/NO/N/FALSE/F - Switch OFF
##       1/ON/YES/Y/TRUE/T  - Switch ON
##
## Variable ############# Switch ############
##
Display_TITLE             : Y
Display_SUBTITLE          : Y
Display_X-Axis_LABEL      : Y
Display_Y-Axis_LABEL      : Y
Display_Percent-Box_LABEL : Y
Display_Extra-Box_LABEL   : Y
Display_PERCENT-BOX       : N
Display_EXTRA-BOX         : N
Display_GENE_LABEL        : Y
Display_GENE_RULE         : Y
Display_HalfHeightBOX     : Y
Display_FullHeightBOX     : Y
Display_BOX_LABEL         : Y
Display_UserDef_BOX_LABEL : Y
Display_ARROW             : Y
Display_JOINS             : Y
Display_RIBBON            : Y
Display_SELECTION-BOX     : Y
Display_GFF               : N
Display_GFF-ReverseOrder  : N
Display_FUNCTION          : N
APlotLine_GroupScore      : N
APlotLine_ScaleWidth      : N
APlotLine_ScaleGrey       : N
XY_AXES_Same-SIZE         : N
Display_TickMark-LABEL    : Y
Display_APlot_X-Ticks     : Y
Display_Percent_X-Ticks   : Y
Display_ExtraBox_X-Ticks  : Y
Display_APlot_Y-Ticks     : Y
Display_Percent_Y-Ticks   : Y
Display_ExtraBox_Y-Ticks  : Y
Display_OnlyLower_X-Ticks : N
Display_GRID              : N
ZOOM_Zoom                 : N
ZOOM_Area                 : N
Zoom_Marks                : N
##
DF ########################################################################## ##
## ############################# DEFAULT VALUES ############################# ##
##
## Some Default Values...
##
## Variable ######## Definition ######## 
##
PAGE_SIZE               :  a4
FEATURE_LABELS_LENGTH   :  0     # Number of chars displayed in labels (0 means show full label string).
GROUP_LABELS_LENGTH     :  0     # Number of chars displayed in labels (0 means show full label string).
FEATURE_X-LABELS_ANGLE  :  0     # In degrees.
GROUP_X-LABELS_ANGLE    :  0     # In degrees.
FEATURE_Y-LABELS_ANGLE  :  0     # In degrees.
GROUP_Y-LABELS_ANGLE    :  0     # In degrees.
FEATURE_LABELS_FONTSIZE :  1     # Font size scale Factor.
GROUP_LABELS_FONTSIZE   :  1     # Font size scale Factor.
BACKGROUND_COLOR        : white
FOREGROUND_COLOR        : black
APlotBox_BGCOLOR        :  BG
PercentBox_BGCOLOR      :  BG
ExtraBox_BGCOLOR        :  BG
Strand-Arrows_COLOR     :  FG
Join-Lines_COLOR        :  FG
SelectionBox_BGCOLOR    : grey
Function_COLOR          : red
Zoom_Area_Mark_COLOR    : lightred
PERCENT_ORIGIN          :  50
PERCENT_END             : 100
ScaleMajorTICKMARK      :   2    # major tickmarks per axis.
ScaleMinorTICKMARK      :   5    # minor tickmarks per each major.
PercentMajorTICKMARK    :   5    # major tickmarks per axis.
PercentMinorTICKMARK    :   5    # minor tickmarks per each major.
ExtraMajorTICKMARK      :   2    # major tickmarks per axis.
ExtraMinorTICKMARK      :   5    # minor tickmarks per each major.
##
OP ########################################################################## ##
## #################################### OPTIONs ############################# ##
##
## Changing default values overrides any other definition you made for features.
##
##   ##DEFAULT##  means that program uses for these options
##                those values you have defined in feature table.
##         FG    the option is defined with FOREGROUND_COLOR.
##         BG    the option is defined with BACKGROUND_COLOR.
##
## Variable ######## Definition ######## 
##
Align_NAME            : ##DEFAULT##
X-Sequence_NAME       : ##DEFAULT##
Y-Sequence_NAME       : ##DEFAULT##
TITLE                 : ##DEFAULT##
SUBTITLE              : ##DEFAULT##
X-Axis_LABEL          : ##DEFAULT##
Y-Axis_LABEL          : ##DEFAULT##
Percent-Box_LABEL     : ##DEFAULT##
Percent-Box_SUBLABEL  : ##DEFAULT##
Extra-Box_LABEL       : ##DEFAULT##
Extra-Box_SUBLABEL    : ##DEFAULT##
HalfSizeBox_BGCOLOR   : ##DEFAULT##
FullSizeBox_BGCOLOR   : ##DEFAULT##
Ribbon_BGCOLOR        : ##DEFAULT##
SEQUENCE1_ORIGIN      : ##DEFAULT##
SEQUENCE1_END         : ##DEFAULT##
SEQUENCE2_ORIGIN      : ##DEFAULT##
SEQUENCE2_END         : ##DEFAULT##
Zoom_SEQUENCE1_ORIGIN : ##DEFAULT##
Zoom_SEQUENCE1_END    : ##DEFAULT##
Zoom_SEQUENCE2_ORIGIN : ##DEFAULT##
Zoom_SEQUENCE2_END    : ##DEFAULT##
TICKMARK              : ##DEFAULT##
SMALLTICKMARK         : ##DEFAULT##
##
FT ########################################################################## ##
## #################################### GFF FEATUREs DEFINITION ############# ##
## 
## ########### Description of each element of the Features Array. ########### ##
##
## (str) means a string of chars (in a string numbers are treated as chars).
## (bin) means you only could define variable as
##       0/OFF/NO/N/FALSE/F = Switch OFF the element.
##       1/ON/YES/Y/TRUE/T  = Switch ON  the element.
## (FHN) means you can choose between "(F)ull" or "(H)alf" size Boxes,
##       also you can define "(N)one", then the feature is without a box.
## (NLRB) means you can choose among "(N)o lines", "draw (L)ines at <feature>
##       boundaries", "(R)ibbons" or "(B)oth -Lines and Ribbons".
## (HND) means "(H)alfSize", "(N)ormalSize" or "(D)oubleSize" LineWidth.
##
## (clr) means that you can choose among the following color names:
##
##    black | verydarkgrey | darkgrey | grey | lightgrey | verylightgrey | white
##       verydarkgreen | darkgreen | green | lightgreen | verylightgreen
##   verydarkskyblue | darkskyblue | skyblue | lightskyblue | verylightskyblue
##          verydarkblue | darkblue | blue | lightblue | verylightblue
##         verydarkcyan | darkcyan | cyan | lightcyan | verylightcyan
##     verydarkviolet | darkviolet | violet | lightviolet | verylightviolet
##            verydarkred | darkred | red | lightred | verylightred
##     verydarkorange | darkorange | orange | lightorange | verylightorange
##     verydarkyellow | darkyellow | yellow | lightyellow | verylightyellow
##        verydarkbrown | darkbrown | brown | lightbrown | verylightbrown 
##
##       If you do not want to define a color, you can enter
##        BG (background color) or FG (foreground color), 
##        but you must choose one of the above definitions.
## 
## ## 
## Feature (str): A feature name. Only <features> defined below
##    will be recognized in your .gff file.
## ## 
## XTR (bin): Force those <features> for which XTR is switched ON
##   to be displayed in the third panel, if the Plot Option 
##   "Display_EXTRA-BOX" is switched ON.
## ## 
## Box (FHN): Define the box size (FHN) for <feature>.
## ##
## Line (NLRB): Draw lines across all panels for the <feature>.
## ##
## Join (bin): Switch ON to connect elements of one group with splice symbols.
## ##
## Arrw (bin): Swicth ON to display an arrow that shows the <feature>'s strand.
## ##
## Lbl (bin): Swicth ON to display the <feature>'s label
##   (if it's defined in the .gff file).
## ##
## Color (clr): Fill <Box> with this color.
## ##
## CLine (clr): Fill Line <Ribbons> with this color.
## ##
## Wdth (HND): You can choose among three predefined LineWidths.
## ##
## Layr : Layer where is drawed each feature.
##   You must pass an integer for feature ordering (1..n),
##   put 0 to print the feature always on top. 
## ##
##  
## ########################## Features Definition ################################ ##
## Feature  #XTR #Box #Line#Join#Arrw#Lbl #Wdth#Layr#Color ###########CLine #########
##
gene          N    H    L    N    Y    N    H    1    blue             lightgrey
first         N    F    R    Y    N    N    H    0    red              lightgrey
internal      N    F    R    Y    N    N    H    0    red              lightgrey
terminal      N    F    R    Y    N    N    H    0    red              lightgrey    
#
sine          N    N    R    N    N    N    H    6    BG               verylightgreen
line          N    N    R    N    N    N    H    6    BG               verylightgreen
alu           N    N    R    N    N    N    H    6    BG               lightgreen   
repeat        N    N    R    N    N    N    H    6    BG               verylightgreen
## ######1#########2#########3#########4#########5#########6#########7#########8#####
##  
SP ########################## Special gff Features ############################### ##
##
GROUPLIMITS : gene
PLOTLIMITS  : sequence                                             
APLOT       : hsp
HIGHLIGHT   : boxit
RECTANGLE   : rectangle
CIRCLE      : circle
TEXT        : text
FUNCTION    : function
EXTRABOX    : est
## ######1#########2#########3#########4#########5#########6#########7#########8#####
@

\newpage %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\sctn{Gene predictions}

Preparing directories:

<<BASH commands ANALYSIS>>=
#
GI="$ANALYSIS/geneid" ;
GS="$ANALYSIS/genscan" ;
TS="$ANALYSIS/twinscan" ;
SP="$ANALYSIS/sgp" ;
R="Hsap.raw" ;
O="Hsap.orimasked" ;
for a in $GI $GS $TS $SP ;
  do {
    ChckDirs $a ;
    for b in $a/$R $a/$O ;
      do {
        ChckDirs $b ;
        for c in gff gtf2 cds prot logs tmp ps ps/_tmp ;
          do {
            ChckDirs $b/$c ;
            } ;
          done ;
        } ;
      done ;
    } ;
  done ;
for b in $SP/$R $SP/$O ;
  do {
    for c in hsp sr hsp-rs tbx ;
      do {
        ChckDirs $b/$c ;
        } ;
      done ;
    } ;
  done ;
#
@ 

\subsctn{Running {\gnid}} 

<<BASH commands ANALYSIS>>=
#
run_GENEID () 
{
  #
  # run_GENEID - Running GENEID and Evaluation for a given sequence set
  #
  # USAGE: run_GENEID testname sequence testset IDfile
  #
  # 'testname' is the subdir of $MAIN where to save all the results
  # 'sequence' is path to the fasta file/s containing the query sequence
  # 'testset' is a GFF file containing the real annotation for evaluation
  # 'IDfile' is a file listing the IDs of sequences to be processed
  #
  PROG="GENEID" ; prog="geneid" ;
  GENEID="/projects/sgp/param/geneid/human3iso.param" ;
  CMD="/projects/sgp/bin/geneid -vG" ;
      # GENEID tool command-line options:
      #  '-v' be verbose
      #  '-G' GFF output
  # Setting VARS
  MAIN="$ANALYSIS/geneid" ;
  RUN="$1" ;
  BASE="$MAIN/$RUN" ;
  ISEQ="$2" ;
  TSET="$3" ;
  SPC="$4" ;
  IDS="$ID.$SPC" ;
  ODIR="$BASE/gff" ;
  EDIR="$BASE/logs" ;
  #
  # Checking if DIRS does EXIST
  ChckDirs $MAIN $BASE ;
  for c in gff gtf2 cds prot logs tmp ps ps/_tmp ;
    do { ChckDirs $BASE/$c ; } ; done ;
  while read locus ;
    do {
        echo "### Running $PROG on $locus ..." 1>&2 ;
        $CMD $ISEQ/$locus > $ODIR/$locus 2> $EDIR/$locus ;
      } ;
    done < $IDS ;
  #
  # Performing EVALUATION
  MergeGFF $ODIR $SPC 0 ; # It produces $ODIR/all.Hsap
  #
  # EVALUATION tool command-line options:
  #  -v: Verbose. Print all messages
  #  -a: Average. Print average stats (more than 1 sequence)
  #  -t: Total. Print total stats (more than 1 sequence)
  #  -s: Short. Print a short output
  echo "### Running EVALUATION on $PROG ..." 1>&2 ;
  { echo "###" ; echo "### EVALUATION of $PROG RESULTS on $RUN" ; echo "###" ;
    echo "### $BASE/eval_$prog.$RUN" ; echo "###" ;
    echo "### "`whoami`" - "`date` ; echo "###" ; } > $BASE/eval_$prog.$RUN ;
  $SGPBIN/evaluation -ta  $ODIR/all.Hsap $TSET >> $BASE/eval_$prog.$RUN ;
  { echo "###" ; echo "### EVALUATION of $PROG RESULTS on $RUN" ; echo "###" ;
    echo "### $BASE/eval_${prog}_brief.$RUN" ; echo "###" ;
    echo "### "`whoami`" - "`date` ; echo "###" ; } > $BASE/eval_${prog}_brief.$RUN ;
  $SGPBIN/evaluation -tsa $ODIR/all.Hsap $TSET >> $BASE/eval_${prog}_brief.$RUN ;
} 
#
@ 

\subsubsctn{{\gnid} on raw sequences} 

<<BASH commands ANALYSIS>>=
#
# Raw sequences
run_GENEID Hsap.raw $DATASETS/fasta/raw \
                    $DATASETS/annotation/gff/all.Hsap Hsap ;
#
@ 

\subsubsctn{{\gnid} on downloaded masked sequences} 

<<BASH commands ANALYSIS>>=
#
# Masked sequences (already masked: orimasked)
run_GENEID Hsap.orimasked $DATASETS/fasta/orimasked \
                          $DATASETS/annotation/gff/all.Hsap Hsap ;
#
@
 
\subsubsctn{{\gnid} on masked sequences} 

<<BASH commands ANALYSIS>>=
#
# Masked sequences
run_GENEID Hsap.masked $DATASETS/fasta/masked \
                       $DATASETS/annotation/gff/all.Hsap Hsap ;
#
@ 

\subsctn{Running {\gnsc}}
 
<<BASH commands ANALYSIS>>=
#
run_GENSCAN () 
{
  #
  # run_GENSCAN - Running GENSCAN and Evaluation for a given sequence set
  #
  # USAGE: run_GENSCAN testname sequence testset IDfile
  #
  # 'testname' is the subdir of $MAIN where to save all the results
  # 'sequence' is path to the fasta file/s containing the query sequence
  # 'testset' is a GFF file containing the real annotation for evaluation
  # 'IDfile' is a file listing the IDs of sequences to be processed
  #
  PROG="GENSCAN" ; prog="genscan" ;
  GENSCAN="/usr/local/molbio/Install/GENSCAN/param/HumanIso.smat" ;
  CMD="/usr/local/molbio/bin/genscan $GENSCAN" ;
      # genscan paramfilename sequencefilename [-v]
      #  '-v' be verbose
  # Setting VARS
  MAIN="$ANALYSIS/genscan" ;
  RUN="$1" ;
  BASE="$MAIN/$RUN" ;
  ISEQ="$2" ;
  TSET="$3" ;
  SPC="$4" ;
  IDS="$ID.$SPC" ;
  GSCN="$BASE/tmp" ;
  ODIR="$BASE/gff" ;
  EDIR="$BASE/logs" ;
  #
  # Checking if DIRS does EXIST
  ChckDirs $MAIN $BASE ;
  for c in gff gtf2 cds prot logs tmp ps ps/_tmp ;
    do { ChckDirs $BASE/$c ; } ; done ;
  while read locus ;
    do {
        echo "### Running $PROG on $locus ..." 1>&2 ;
        $CMD $ISEQ/$locus > $GSCN/$locus 2> $EDIR/$locus ;
        $SGPBIN/genscan2gff seqname=$human < $GSCN/$locus \
                          > $ODIR/$locus 2>> $EDIR/$locus ;
      } ;
    done < $IDS ;
  #
  # Performing EVALUATION
  MergeGFF $ODIR $SPC 0 ; # It produces $ODIR/all.Hsap
  #
  # EVALUATION tool command-line options:
  #  -v: Verbose. Print all messages
  #  -a: Average. Print average stats (more than 1 sequence)
  #  -t: Total. Print total stats (more than 1 sequence)
  #  -s: Short. Print a short output
  echo "### Running EVALUATION on $PROG ..." 1>&2 ;
  { echo "###" ; echo "### EVALUATION of $PROG RESULTS on $RUN" ; echo "###" ;
    echo "### $BASE/eval_$prog.$RUN" ; echo "###" ;
    echo "### "`whoami`" - "`date` ; echo "###" ; } > $BASE/eval_$prog.$RUN ;
  $SGPBIN/evaluation -ta  $ODIR/all.Hsap $TSET >> $BASE/eval_$prog.$RUN ;
  { echo "###" ; echo "### EVALUATION of $PROG RESULTS on $RUN" ; echo "###" ;
    echo "### $BASE/eval_${prog}_brief.$RUN" ; echo "###" ;
    echo "### "`whoami`" - "`date` ; echo "###" ; } > $BASE/eval_${prog}_brief.$RUN ;
  $SGPBIN/evaluation -tsa $ODIR/all.Hsap $TSET >> $BASE/eval_${prog}_brief.$RUN ;
} 
#
@ 

\subsubsctn{{\gnsc} on raw sequences} 

<<BASH commands ANALYSIS>>=
#
# Raw sequences
run_GENSCAN Hsap.raw $DATASETS/fasta/raw \
                     $DATASETS/annotation/gff/all.Hsap Hsap ;
#
@ 

\subsubsctn{{\gnsc} on downloaded masked sequences} 

<<BASH commands ANALYSIS>>=
#
# Masked sequences (already masked: orimasked)
run_GENSCAN Hsap.orimasked $DATASETS/fasta/orimasked \
                           $DATASETS/annotation/gff/all.Hsap Hsap ;
#
@
 
\subsubsctn{{\gnsc} on masked sequences} 

<<BASH commands ANALYSIS>>=
#
# Masked sequences
run_GENSCAN Hsap.masked $DATASETS/fasta/masked \
                        $DATASETS/annotation/gff/all.Hsap Hsap ;
#
@

\subsctn{Working on {\twsc} results}

{\twsc} original data was downloaded from \url|http://genes.cs.wustl.edu/8-orthologs/all-files.tgz| .

<<BASH commands ANALYSIS>>=
#
process_TWINSCAN () 
{
  #
  # process_TWINSCAN - Processing TWINSCAN results and evaluating them
  #                    for a given sequence set
  #
  # USAGE: process_TWINSCAN testname testset IDfile
  #
  # 'testname' is the subdir of $MAIN where to save all the results
  # 'testset' is a GFF file containing the real annotation for evaluation
  # 'IDfile' is a file listing the IDs of sequences to be processed
  #
  PROG="TWINSCAN" ; prog="twinscan" ;
  # Setting VARS
  MAIN="$ANALYSIS/twinscan" ;
  RUN="$1" ;
  BASE="$MAIN/$RUN" ;
  TSET="$2" ;
  SPC="$3" ;
  IDS="$ID"; # IDS="$ID.$SPC" ;
  TWSCN="$BASE/tmp" ;
  ODIR="$BASE/gff" ;
  EDIR="$BASE/logs" ;
  #
  # Checking if DIRS does EXIST
  ChckDirs $MAIN $BASE ;
  for c in gff gtf2 cds prot logs tmp ps ps/_tmp ;
    do { ChckDirs $BASE/$c ; } ; done ;
  while read locus human mouse ;
    do {
        echo "### Running $PROG on $locus ..." 1>&2 ;
        gawk 'BEGIN{
                OFS="\t";
                seq=ARGV[1];
                ARGV[1]="";
              }
              $3 == "CDS" {
                $1=seq;
                gsub(/[\"\;]/,"",$10);
                $9=$10;
                $10=$11=$12="";
                print $0;
              }' $human $TWSCN/$locus/$locus.$SPC.fasta.gff > $ODIR/$human ;
      } ;
    done < $IDS ;
  #
  # Performing EVALUATION
  MergeGFF $ODIR $SPC 0 ; # It produces $ODIR/all.Hsap
  #
  # EVALUATION tool command-line options:
  #  -v: Verbose. Print all messages
  #  -a: Average. Print average stats (more than 1 sequence)
  #  -t: Total. Print total stats (more than 1 sequence)
  #  -s: Short. Print a short output
  echo "### Running EVALUATION on $PROG ..." 1>&2 ;
  { echo "###" ; echo "### EVALUATION of $PROG RESULTS on $RUN" ; echo "###" ;
    echo "### $BASE/eval_$prog.$RUN" ; echo "###" ;
    echo "### "`whoami`" - "`date` ; echo "###" ; } > $BASE/eval_$prog.$RUN ;
  $SGPBIN/evaluation -ta  $ODIR/all.Hsap $TSET >> $BASE/eval_$prog.$RUN ;
  { echo "###" ; echo "### EVALUATION of $PROG RESULTS on $RUN" ; echo "###" ;
    echo "### $BASE/eval_${prog}_brief.$RUN" ; echo "###" ;
    echo "### "`whoami`" - "`date` ; echo "###" ; } > $BASE/eval_${prog}_brief.$RUN ;
  $SGPBIN/evaluation -tsa $ODIR/all.Hsap $TSET >> $BASE/eval_${prog}_brief.$RUN ;
} 
#
@ 

\begin{comment}
<<BASH commands ANALYSIS>>=
#
renameSEQS ()
{
  # renameSEQS ls_command reg_exp substitution_value
  #
  $1 | while read n ; 
    do {
      k=`echo $n | sed "s/$2/$3/"` ;
      [ -e "$n" ] && mv -v $n $k || echo "## FILE DOES NOT EXIST: $n" ;
    } ;
    done ;
}
#
pushd $ANALYSIS/twinscan/Hsap.20010722/tmp/
pushd $ANALYSIS/twinscan/Hsap.20010803/tmp/
mv Elastin ELN ;
cd ELN ;
renameSEQS 'ls -1 Elastin*' '^Elastin' 'ELN' ;
cd .. ;
mv HOXa HOXA ;
cd HOXA ;
renameSEQS 'ls -1 HOXa*' '^HOXa' 'HOXA' ;
cd .. ;
mv KvLQT1 KVLQT1 ;
cd KVLQT1 ;
renameSEQS 'ls -1 KvLQT1*' '^KvLQT1' 'KVLQT1' ;
( gawk "{print \$1}" $ID ; echo 'CD4' ) | \
  while read j; \
    do { cd $j; renameSEQS 'ls -1' '.Hs.' '.Hsap.'; cd .. ; }; done ;
popd ;
#
@ 
\end{comment}
<<BASH commands ANALYSIS>>=
#
process_TWINSCAN Hsap.20010722 $DATASETS/annotation/gff/all.Hsap Hsap ;
#
process_TWINSCAN Hsap.20010803 $DATASETS/annotation/gff/all.Hsap Hsap ;
#
@

\subsctn{Working on {\slam} results}

{\slam} original data was downloaded from \url|http://bio.math.berkeley.edu/slam/8pairs/|

\begin{comment}
<<BASH commands ANALYSIS>>=
#
renameSEQS 'ls -1 hs.btk*' '^hs.btk' 'BTK.Hs'
renameSEQS 'ls -1 hs.dfna5*' '^hs.dfna5' 'DFNA5.Hs'
renameSEQS 'ls -1 hs.hoxa*' '^hs.hoxa' 'HOXA.Hs'
#
@
\end{comment}
<<BASH commands ANALYSIS>>=
#
wget -b --no-parent --mirror --tries=0           \
     --output-file=download_orthologous_slam.log \
     --no-host-directories --cut-dirs=2          \
     'http://bio.math.berkeley.edu/slam/8pairs/' ;
#
@

\subsctn{Running {\sgp}}

<<BASH commands ANALYSIS>>=
#
run_SGP () 
{
  #
  # run_SGP - Running SGP and Evaluation for a given sequence set
  #
  # USAGE: run_SGP testname sequence blastdata testset IDfile
  #
  # 'testname' is the subdir of $MAIN where to save all the results
  # 'sequence' is path to the fasta file/s containing the query sequence
  # 'blastdata' is path to the blast output/s for homology evidences
  # 'testset' is a GFF file containing the real annotation for evaluation
  # 'IDfile' is a file listing the IDs of sequences to be processed
  #
  PROG="SGP" ; prog="sgp" ;
  # Setting VARS
  MAIN="$ANALYSIS/sgp" ;
  RUN="$1" ;
  BASE="$MAIN/$RUN" ;
  ISEQ="$2" ;
  BDIR="$3" ;
  TSET="$4" ;
  SPC="$5" ;
  IDS="$ID.$SPC" ;
  HSP_SR="$BASE/tmp" ;
  ODIR="$BASE/gff" ;
  EDIR="$BASE/logs" ;
  #
  # Checking if DIRS does EXIST
  ChckDirs $MAIN $BASE ;
  for c in hsp sr hsp-rs tbx gff gtf2 cds prot logs tmp ps ps/_tmp ;
    do { ChckDirs $BASE/$c ; } ; done ;
  #
  # Running SGP TOOL
  while read locus ;
    do {
        echo "### Running $PROG on $locus ..." 1>&2 ;
        # SGGP tool command-line options:
        #  '-t filename' read tblastx file
        #  '-k prefix' keep intermediate files with prefix (trailing / required)
        #  '-1 seqfile_1'
        #  '-d database'
        $SGP -v -1 $ISEQ/$locus -d /tmp/ -k $HSP_SR/ \
                -t $BDIR/$locus > $ODIR/$locus 2> $EDIR/$locus ;
      } ;
    done < $IDS ;
  #
  # Performing EVALUATION
  MergeGFF $ODIR $SPC 0 ; # It produces $ODIR/all.Hsap
  #
  # EVALUATION tool command-line options:
  #  -v: Verbose. Print all messages
  #  -a: Average. Print average stats (more than 1 sequence)
  #  -t: Total. Print total stats (more than 1 sequence)
  #  -s: Short. Print a short output
  { echo "###" ; echo "### EVALUATION of $PROG RESULTS on $RUN" ; echo "###" ;
    echo "### $BASE/eval_$prog.$RUN" ; echo "###" ;
    echo "### "`whoami`" - "`date` ; echo "###" ; } > $BASE/eval_$prog.$RUN ;
  $SGPBIN/evaluation -ta  $ODIR/all.Hsap $TSET >> $BASE/eval_$prog.$RUN ;
  { echo "###" ; echo "### EVALUATION of $PROG RESULTS on $RUN" ; echo "###" ;
    echo "### $BASE/eval_${prog}_brief.$RUN" ; echo "###" ;
    echo "### "`whoami`" - "`date` ; echo "###" ; } > $BASE/eval_${prog}_brief.$RUN ;
  $SGPBIN/evaluation -tsa $ODIR/all.Hsap $TSET >> $BASE/eval_${prog}_brief.$RUN ;
  #
  # Copying files to where they are going to be used
  CMMD="mv -v" ; # Instead of "cp -vapudf"
  while read locus ;
    do {
    # $CMMD $HSP_SR/$locus.sgp    $ODIR/$locus ; # already exists
      $CMMD $HSP_SR/$locus.hsp    $BASE/hsp/$locus ;
      $CMMD $HSP_SR/$locus.sr     $BASE/sr/$locus ;
      $CMMD $HSP_SR/$locus.hsp-rs $BASE/hsp-rs/$locus ;
      $CMMD $HSP_SR/$locus.tbx    $BASE/tbx/$locus ;
      } ;
    done < $IDS ;
} 
#
@ 

<<BASH commands ANALYSIS>>=
#
####
#### Using "STANDARD" SGP
#
export SGP="/projects/sgp/bin/SGP2-2/sggp2" ;
#
# SGP on Raw sequences
run_SGP Hsap.raw $DATASETS/fasta/raw \
               $ANALYSIS/blast/wublast.tblastx/raw \
               $DATASETS/annotation/gff/all.Hsap Hsap ;
#
# SGP on Masked sequences (already masked: orimasked)
run_SGP Hsap.orimasked $DATASETS/fasta/orimasked \
               $ANALYSIS/blast/wublast.tblastx/orimasked \
               $DATASETS/annotation/gff/all.Hsap Hsap ;
#
####
#### Roderic's TESTS on a SGP variant
#
export HOME='/home/ug/rguigo' ; # to avoid modifying Roderic's scripts
export SGP="/home/ug/rguigo/research/humus/SGP2-2/bin/sggp2" ;
#
# SGP on Masked sequences (already masked: orimasked)
run_SGP rguigo.orimasked $DATASETS/fasta/orimasked \
               $ANALYSIS/blast/wublast.tblastx/orimasked \
               $DATASETS/annotation/gff/all.Hsap Hsap ;
#
# SGP on TBX results from Pankaj (W=5) for ORI masked sequences
run_SGP rguigo.orimasked3X_pankaj_W5 $DATASETS/fasta/orimasked \
               $ANALYSIS/blast/wublast.tblastx/orimasked3X/pankaj_W5 \
               $DATASETS/annotation/gff/all.Hsap Hsap ;
#
# SGP on TBX results from Pankaj (W=5) for IMIM masked sequences
run_SGP rguigo.masked3X_pankaj_W5 $DATASETS/fasta/masked \
               $ANALYSIS/blast/wublast.tblastx/masked3X/pankaj_W5 \
               $DATASETS/annotation/gff/all.Hsap Hsap ;
#
export HOME='/home/ug/jabril' ;
#
@ 

<<BASH commands ANALYSIS>>=
#
# Roderic's Tests on a SGP variant (TAKING files from his LOCAL PATH)
#
IDIR="$ANALYSIS/sgp/rguigo" ;
ChckDirs $IDIR ;
for c in gff gtf2 cds prot logs tmp ps ps/_tmp ;
  do {
    ChckDirs $IDIR/$c ;
    } ;
  done ;
for c in hsp sr hsp-rs tbx ;
  do {
    ChckDirs $IDIR/$c ;
    } ;
  done ;
#
MergeGFF $ANALYSIS/sgp/rguigo/gff/$locus Hsap 0 ;
#
$SGPBIN/evaluation -tsa /home/ug/rguigo/research/humus/SGP2-2/11.2/ortho.sgp \
                        $DATASETS/annotation/gff/all.Hsap                    \
                      > $ANALYSIS/sgp/rguigo/eval_sgp.Hsap_RGUIGO ;
$SGPBIN/evaluation -tsa $ANALYSIS/sgp/rguigo/gff/all.Hsap                    \
                        $DATASETS/annotation/gff/all.Hsap                    \
                      > $ANALYSIS/sgp/rguigo/eval_sgp.Hsap_RGUIGO.2 ;
#
IDIR="/home/ug/rguigo/research/humus/SGP2-2/11.2/sgp" ;
ODIR="$ANALYSIS/sgp/rguigo" ;
while read locus ;
  do {
    cp -vapudf $IDIR/$locus.sgp     $ODIR/gff/$locus ;
    perl -npe 's/^\s+//o' $IDIR/$locus.hsp \
                                  > $ODIR/hsp/$locus ;
    cp -vapudf $IDIR/$locus.sr      $ODIR/sr/$locus ;
    cp -vapudf $IDIR/$locus.hsp-rs  $ODIR/hsp-rs/$locus ;
    cp -vapudf $IDIR/$locus.tbx     $ODIR/tbx/$locus ;
    } ;
  done < $HSAP ;
#
@

\subsctn{Printing gene-prediction statistics}

<<BASH commands ANALYSIS>>=
#
### PRINTING GENE-PREDICTION EVALUATIONS
ENSCRIPT="enscript -1C -Gjf Courier7 -M A4" ;
#
# GENEID evaluation
$ENSCRIPT $ANALYSIS/geneid/Hsap.raw/eval_geneid.Hsap.raw ;
$ENSCRIPT -r $ANALYSIS/geneid/Hsap.raw/eval_geneid_brief.Hsap.raw ;
$ENSCRIPT $ANALYSIS/geneid/Hsap.orimasked/eval_geneid.Hsap.orimasked ;
$ENSCRIPT -r $ANALYSIS/geneid/Hsap.orimasked/eval_geneid_brief.Hsap.orimasked ;
$ENSCRIPT $ANALYSIS/geneid/Hsap.masked/eval_geneid.Hsap.masked ;
$ENSCRIPT -r $ANALYSIS/geneid/Hsap.masked/eval_geneid_brief.Hsap.masked ;
#
# GENSCAN evaluation
$ENSCRIPT $ANALYSIS/genscan/Hsap.raw/eval_genscan.Hsap.raw ;
$ENSCRIPT -r $ANALYSIS/genscan/Hsap.raw/eval_genscan_brief.Hsap.raw ;
$ENSCRIPT $ANALYSIS/genscan/Hsap.orimasked/eval_genscan.Hsap.orimasked ;
$ENSCRIPT -r $ANALYSIS/genscan/Hsap.orimasked/eval_genscan_brief.Hsap.orimasked ;
$ENSCRIPT $ANALYSIS/genscan/Hsap.masked/eval_genscan.Hsap.masked ;
$ENSCRIPT -r $ANALYSIS/genscan/Hsap.masked/eval_genscan_brief.Hsap.masked ;
#
# SLAM evaluation
#
# TWINSCAN evaluation
$ENSCRIPT $ANALYSIS/twinscan/Hsap.20010722/eval_twinscan.Hsap.20010722 ;
$ENSCRIPT -r $ANALYSIS/twinscan/Hsap.20010722/eval_twinscan_brief.Hsap.20010722 ;
$ENSCRIPT $ANALYSIS/twinscan/Hsap.20010803/eval_twinscan.Hsap.20010803 ;
$ENSCRIPT -r $ANALYSIS/twinscan/Hsap.20010803/eval_twinscan_brief.Hsap.20010803 ;
#
# SGP evaluation
$ENSCRIPT $ANALYSIS/sgp/Hsap.raw/eval_sgp.Hsap.raw ;
$ENSCRIPT -r $ANALYSIS/sgp/Hsap.raw/eval_sgp_brief.Hsap.raw ;
$ENSCRIPT $ANALYSIS/sgp/Hsap.orimasked/eval_sgp.Hsap.orimasked ;
$ENSCRIPT -r $ANALYSIS/sgp/Hsap.orimasked/eval_sgp_brief.Hsap.orimasked ;
# SGP evaluation (Roderic's SGP variant)
$ENSCRIPT $ANALYSIS/sgp/rguigo/eval_sgp.Hsap_RGUIGO ;
$ENSCRIPT $ANALYSIS/sgp/rguigo/eval_sgp.Hsap_RGUIGO.2 ;
$ENSCRIPT $ANALYSIS/sgp/rguigo.orimasked/eval_sgp.rguigo.orimasked ;
$ENSCRIPT -r $ANALYSIS/sgp/rguigo.orimasked/eval_sgp_brief.rguigo.orimasked ;
$ENSCRIPT $ANALYSIS/sgp/rguigo.orimasked3X_pankaj_W5/eval_sgp.rguigo.orimasked3X_pankaj_W5 ;
$ENSCRIPT -r $ANALYSIS/sgp/rguigo.orimasked3X_pankaj_W5/eval_sgp_brief.rguigo.orimasked3X_pankaj_W5 ;
$ENSCRIPT $ANALYSIS/sgp/rguigo.masked3X_pankaj_W5/eval_sgp.rguigo.masked3X_pankaj_W5 ;
$ENSCRIPT -r $ANALYSIS/sgp/rguigo.masked3X_pankaj_W5/eval_sgp_brief.rguigo.masked3X_pankaj_W5 ;
#
@

\newpage %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\sctn{Making plots for {\sgp}}

\subsctn{Preparing GFF files}

<<BASH commands ANALYSIS>>=
#
# geneid and genscan files (Twinscan used as is)
while read locus ;
  do {
    echo "### Working on $locus..." ;
    #
    IDIR="$ANALYSIS/genscan/Hsap.orimasked" ;
    ODIR="$IDIR/ps/_tmp/genscan" ;
    [ -e $ODIR ] || ChckDirs $ODIR ;
    gawk 'BEGIN{OFS="\t"}
          $1!~/^#|^[ \t]*$/ {
              $9="gene_"$9;
              print;
          }' $IDIR/gff/$locus > $ODIR/$locus ;
    #
    IDIR="$ANALYSIS/geneid/Hsap.orimasked" ;
    ODIR="$IDIR/ps/_tmp/geneid" ;
    [ -e $ODIR ] || ChckDirs $ODIR ;
    gawk 'BEGIN{OFS="\t"}
          $1!~/^#|^[ \t]*$/ {
              print;
          }' $IDIR/gff/$locus > $ODIR/$locus ;
    } ;
  done < $HSAP ; 
#
# FullOrthologous against sequences
while read locus ;
  do {
    echo "### Working on $locus..." ;
    #
    IDIR="$ANALYSIS/sgp/Hsap.orimasked" ;
    ODIR="$IDIR/ps/_tmp/sgp" ;
    [ -e $ODIR ] || ChckDirs $ODIR ;
    gawk 'BEGIN{ OFS="\t" }
          { if ($1 !~ /^#|^[ \t]*$/) { $2="SGP.homol" };
            print $0;
            }' $IDIR/gff/$locus > $ODIR/$locus ;
    #
    IDIR="$ANALYSIS/sgp/Hsap.orimasked" ;
    ODIR="$IDIR/ps/_tmp/tblastx" ;
    [ -e $ODIR ] || ChckDirs $ODIR ;
    gawk 'BEGIN{ OFS="\t" }
          { if ($1 !~ /^#|^[ \t]*$/) { $2="tblastx.homol"; $8="." };
            print $0;
          }' $IDIR/hsp-rs/$locus > $ODIR/$locus ;
    } ;
  done < $HSAP ; 
#
# FullOrthologous against sequences (Roderic's SGP testing version)
while read locus ;
  do {
    echo "### Working on $locus..." ;
    #
    IDIR="$ANALYSIS/sgp/rguigo" ;
    ODIR="$IDIR/ps/_tmp/sgp" ;
    [ -e $ODIR ] || ChckDirs $ODIR ;
    gawk 'BEGIN{ OFS="\t" }
          { if ($1 !~ /^#|^[ \t]*$/) { $2="SGP.homol" };
            print $0;
            }' $IDIR/gff/$locus > $ODIR/$locus ;
    #
    IDIR="$ANALYSIS/sgp/rguigo" ;
    ODIR="$IDIR/ps/_tmp/tblastx" ;
    [ -e $ODIR ] || ChckDirs $ODIR ;
    gawk 'BEGIN{ OFS="\t" }
          { if ($1 !~ /^#|^[ \t]*$/) { $2="tblastx.homol"; $8="." };
            print $0;
            }' $IDIR/hsp-rs/$locus > $ODIR/$locus ;
    } ;
  done < $HSAP ; 
#
# 3X against sequences (Roderic's SGP testing version)
while read locus ;
  do {
    echo "### Working on $locus..." ;
    #
    IDIR="$ANALYSIS/sgp/rguigo.masked3X_pankaj_W5" ;
    ODIR="$IDIR/ps/_tmp/sgp" ;
    [ -e $ODIR ] || ChckDirs $ODIR ;
    gawk 'BEGIN{ OFS="\t" }
          { if ($1 !~ /^#|^[ \t]*$/) { $2="SGP.3X" };
            print $0;
            }' $IDIR/gff/$locus > $ODIR/$locus ;
    #
    ODIR="$IDIR/ps/_tmp/tblastx" ;
    [ -e $ODIR ] || ChckDirs $ODIR ;
    gawk 'BEGIN{ OFS="\t" }
          { if ($1 !~ /^#|^[ \t]*$/) { $2="tblastx.3X"; $8="." };
            print $0;
            }' $IDIR/hsp-rs/$locus > $ODIR/$locus ;
    } ;
  done < $HSAP ; 
#
@

\subsctn{Making plots with {\gps}}

<<BASH commands ANALYSIS>>=
#
run_GFF2PS ()
{
  # 
  # run_GFF2PS - Making plots with gff2ps (a4+a3+wide formats)
  #
  # USAGE: run_GFF2PS working_dir "GFF_files_list"
  #
  # 'working_dir' where to save plots
  # "GFF_files_list" a list of GFF files (with full path) to be plotted
  #
  ODIR="$1/gff2ps" ;
  GFFfiles="$2";
  ChckDirs $ODIR \
           $ODIR/a3      $ODIR/a4      $ODIR/wide \
           $ODIR/a3/logs $ODIR/a4/logs $ODIR/wide/logs ;
  #
  while read locus ; # Requires previous $IDIR 
    do {
      echo "### Plotting $locus" ;
      gff2ps -VC $PARAM/gff2ps/ortho_orimasked_a4.rc   -- $GFFfiles \
              2>&1 > $ODIR/a4/$locus   | tee $ODIR/a4/logs/$locus ;
      gff2ps -VC $PARAM/gff2ps/ortho_orimasked_a3.rc   -- $GFFfiles \
              2>&1 > $ODIR/a3/$locus   | tee $ODIR/a3/logs/$locus ;
      gff2ps -VC $PARAM/gff2ps/ortho_orimasked_wide.rc -- $GFFfiles \
              2>&1 > $ODIR/wide/$locus | tee $ODIR/wide/logs/$locus ;
      } ;
    done < $HSAP ;
}
#
@ 

\subsubsctn{Human x FO Mouse (Roderic's SGP results)} %'

We are going to display the following data: 

\begin{tabular}{rl}
annotation   & [[$DATASETS/annotation/gff/$locus]] \\
sgp          & [[$ANALYSIS/sgp/rguigo/ps/_tmp/sgp/$locus]] \\
geneid msk   & [[$ANALYSIS/geneid/Hsap.masked/ps/_tmp/geneid/$locus]] \\
twinscan msk & [[$ANALYSIS/twinscan/Hsap.20010803/gff/$locus]] \\
genscan msk  & [[$ANALYSIS/genscan/Hsap.masked/ps/_tmp/genscan/$locus]] \\
hsp-rs       & [[$ANALYSIS/sgp/rguigo/ps/_tmp/tblastx/$locus]] \\
repeats      & [[$DATASETS/masking/default/gff/$locus]] \\
\end{tabular}

<<BASH commands ANALYSIS>>=
#
IDIR="$ANALYSIS/sgp/rguigo/ps" ;
GFFIN="$DATASETS/annotation/gff" ;
GFFIN="$GFFIN $IDIR/_tmp/sgp" ;
# GFFIN="$GFFIN $ANALYSIS/geneid/Hsap.orimasked/ps/_tmp/geneid" ;
GFFIN="$GFFIN $ANALYSIS/geneid/Hsap.masked/ps/_tmp/geneid" ;
# GFFIN="$GFFIN $ANALYSIS/twinscan/Hsap.orimasked/gff" ;
GFFIN="$GFFIN $ANALYSIS/twinscan/Hsap.20010803/gff" ;
# GFFIN="$GFFIN $ANALYSIS/genscan/Hsap.orimasked/ps/_tmp/genscan" ;
GFFIN="$GFFIN $ANALYSIS/genscan/Hsap.masked/ps/_tmp/genscan" ;
GFFIN="$GFFIN $IDIR/_tmp/tblastx" ;
# GFFIN="$GFFIN $DATASETS/masking/orimasked/gff" ;
GFFIN="$GFFIN $DATASETS/masking/default/gff" ;
RunGFF2PS $IDIR "$GFFIN" ;
#
@ 

\subsubsctn{Human x WGS3X Mouse (Roderic's SGP results)} %'

We are going to display the following data: 

\begin{tabular}{rl}
annotation   & [[$DATASETS/annotation/gff/$locus]] \\
sgp          & [[$ANALYSIS/sgp/rguigo.masked3X_pankaj_W5/ps/_tmp/sgp/$locus]] \\
geneid msk   & [[$ANALYSIS/geneid/Hsap.masked/ps/_tmp/geneid/$locus]] \\
% NOT YET: we do not know if we got twinscan results for 3XWGS
% twinscan msk & [[$ANALYSIS/twinscan/Hsap.20010803/gff/$locus]] \\
genscan msk  & [[$ANALYSIS/genscan/Hsap.masked/ps/_tmp/genscan/$locus]] \\
hsp-rs       & [[$ANALYSIS/sgp/rguigo/ps/_tmp/tblastx/$locus]] \\
repeats      & [[$DATASETS/masking/default/gff/$locus]] \\
\end{tabular}

<<BASH commands ANALYSIS>>=
#
#### Human against Mouse 3X 
IDIR="$ANALYSIS/sgp/rguigo.masked3X_pankaj_W5/ps" ;
GFFIN="$DATASETS/annotation/gff" ;
GFFIN="$GFFIN $IDIR/_tmp/sgp" ;
# GFFIN="$GFFIN $ANALYSIS/geneid/Hsap.orimasked/ps/_tmp/geneid" ;
GFFIN="$GFFIN $ANALYSIS/geneid/Hsap.masked/ps/_tmp/geneid" ;
# NOT YET: we do not know if we got twinscan results for 3XWGS
# GFFIN="$GFFIN $ANALYSIS/twinscan/Hsap.orimasked/gff" ;
# GFFIN="$GFFIN $ANALYSIS/twinscan/Hsap.20010803/gff" ;
# GFFIN="$GFFIN $ANALYSIS/genscan/Hsap.orimasked/ps/_tmp/genscan" ;
GFFIN="$GFFIN $ANALYSIS/genscan/Hsap.masked/ps/_tmp/genscan" ;
GFFIN="$GFFIN $IDIR/_tmp/tblastx" ;
# GFFIN="$GFFIN $DATASETS/masking/orimasked/gff" ;
GFFIN="$GFFIN $DATASETS/masking/default/gff" ;
RunGFF2PS $IDIR "$GFFIN" ;
#
@

\subsubsctn{Human x WGS3X Mouse + FO Mouse (Roderic's SGP results)} %'

<<BASH commands ANALYSIS>>=
#
#### Human against Mouse 3X + Human against Mouse Homologous 
IDIR="$ANALYSIS/sgp/rguigo.masked3X_pankaj_W5/ps_3X+FO" ;
ChckDirs $IDIR ;
GFFIN="" #################### (TO DEFINE!!!!)
RunGFF2PS $IDIR "$GFFIN" ;
#
@

\subsubsctn{Customization files for {\gps}}

+ LAYOUT

<<Common Layout Settings>>=
zoom=*..*
# major_tickmarks_num=10
# minor_tickmarks_num=10
major_tickmarks_nucleotides=1000
minor_tickmarks_nucleotides=250
#
left_source_label_width=2.5cm
show_blocks_top-bottom=off
#
group_label_scale=2
#
@

<<Settings for a3 paper size>>=
page_size=a3
page_orientation=Landscape
# page_number=1
blocks_x_page=4
nucleotides_x_line=30000
#
@ 

<<Settings for a4 paper size>>=
page_size=a4
page_orientation=Landscape
# page_number=1
blocks_x_page=3
nucleotides_x_line=10000
#
@ 

<<Settings for wide display>>=
page_bbox=wide,400,3000
page_orientation=Landscape
# page_number=1
blocks_x_page=1
# nucleotides_x_line=10000
#
@ 

+ FEATURES

<<Common Features Settings>>=
*::fill_shape_mode=1_color
gene::shape=none
@

<<Repeats Features Settings>>=
LINE/L2::feature_color=verydarkred
SINE/Alu::feature_color=verydarkgreen
SINE/MIR::feature_color=verydarkbrown
LTR/ERV1::feature_color=verydarkblue
Low_complexity::feature_color=verydarkyellow
Simple_repeat::feature_color=verydarkorange
#
@

+ GROUPS

<<Common Group Settings>>=
*::group_line=none
*::group_shape=thick_line
@

+ SOURCES

<<Common Source Settings>>=
*::unfold_grouped_ungrouped=off
*::unfold_ungrouped_line=off
*::unfold_grouped_line=off
*::range=none
*::source_line_color=black
*::source_line=long_dotted
#
@
 
<<annotation source settings>>=
annotation::feature_color=darkgreen
annotation::group_color=verydarkgreen
annotation::left_label=ANNOTATION
@ 

<<sgp source settings>>=
SGP.3X::feature_color=darkorange
SGP.3X::group_color=verydarkorange
SGP.3X::left_label=SGP 3X
SGP.homol::feature_color=darkorange
SGP.homol::group_color=verydarkorange
SGP.homol::left_label=SGP
@ 

<<geneid source settings>>=
geneid_v1.0::feature_color=lightviolet
geneid_v1.0::group_color=darkviolet
geneid_v1.0::left_label=GENEID
@ 

<<twinscan source settings>>=
Twinscan-1.0::feature_color=verylightbrown
Twinscan-1.0::group_color=brown
Twinscan-1.0::left_label=TWINSCAN
@ 

<<genscan source settings>>=
genscan::feature_color=blue
genscan::group_color=verydarkblue
genscan::left_label=GENSCAN
@ 

<<tblastx source settings>>=
tblastx.3X::feature_color=red
tblastx.3X::group_color=verydarkred
tblastx.3X::left_label=TBLASTX 3X
tblastx.homol::feature_color=red
tblastx.homol::group_color=verydarkred
tblastx.homol::left_label=TBLASTX
@ 

<<repeatmasker source settings>>=
# RepeatMasker::feature_color=####
# RepeatMasker::group_color=####
RepeatMasker::left_label=REPEATS
@ 

<<orimasked source settings>>=
# masked::feature_color=####
# masked::group_color=####
masked::left_label=MASKED
@ 

+ CUSTOM FILES

<<GFF2PS customization: ortho orimasked a4>>=
##########################################
##   CUSTOM FILE FOR GFF2PS - A4 PAGE   ##
##########################################
#
# ortho_orimasked_a4.rc
#
<<Version Control Id Tag>>
#
# L ######PAGE LAYOUT & PROGRAM OPTIONS######
#
<<Settings for a4 paper size>>
<<Common Layout Settings>>
#
# F ############GENOMIC FEATURES############
#
<<Common Features Settings>>
#
# G ############GROUP FEATURES##############
#
<<Common Group Settings>>
#
# S ############SOURCE FEATURES#############
#
<<Common Source Settings>>
<<annotation source settings>>
<<sgp source settings>>
<<geneid source settings>>
<<twinscan source settings>>
<<genscan source settings>>
<<tblastx source settings>>
<<orimasked source settings>>
@ 

<<GFF2PS customization: ortho orimasked a3>>=
##########################################
##   CUSTOM FILE FOR GFF2PS - A3 PAGE   ##
##########################################
#
# ortho_orimasked_a3.rc
#
<<Version Control Id Tag>>
#
# L ######PAGE LAYOUT & PROGRAM OPTIONS######
#
<<Settings for a3 paper size>>
<<Common Layout Settings>>
#
# F ############GENOMIC FEATURES############
#
<<Common Features Settings>>
#
# G ############GROUP FEATURES##############
#
<<Common Group Settings>>
#
# S ############SOURCE FEATURES#############
#
<<Common Source Settings>>
<<annotation source settings>>
<<sgp source settings>>
<<geneid source settings>>
<<twinscan source settings>>
<<genscan source settings>>
<<tblastx source settings>>
<<orimasked source settings>>
@ 

<<GFF2PS customization: ortho orimasked wide>>=
############################################
##   CUSTOM FILE FOR GFF2PS - WIDE PAGE   ##
############################################
#
# ortho_orimasked_wide.rc
#
<<Version Control Id Tag>>
#
# L ######PAGE LAYOUT & PROGRAM OPTIONS######
#
<<Settings for wide display>>
<<Common Layout Settings>>
#
# F ############GENOMIC FEATURES############
#
<<Common Features Settings>>
#
# G ############GROUP FEATURES##############
#
<<Common Group Settings>>
#
# S ############SOURCE FEATURES#############
#
<<Common Source Settings>>
<<annotation source settings>>
<<sgp source settings>>
<<geneid source settings>>
<<twinscan source settings>>
<<genscan source settings>>
<<tblastx source settings>>
<<orimasked source settings>>
@ 

\newpage %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\sctn{Preparing files on web site (as \textbf{gmaster})}

<<BASH commands ANALYSIS>>=
#
while read locus ;
  do {
    echo "### Converting GFF to GTF2: $locus ..." ;
    $BIN/gff2gtf.pl < $ANALYSIS/sgp/rguigo/gff/$locus \
                    > $ANALYSIS/sgp/rguigo/gtf2/$locus ;
    } ;
  done < $HSAP ; 
@ 

\subsctn{Results on human/mouse homologous sequence comparison}

\begin{comment}
ODIR="./homologseqs" ;
ANALYSIS="/projects/sgp/orthologous" ;
HSAP="/projects/datasets/orthologous/id.Hsap" ;
\end{comment}
<<BASH commands ANALYSIS>>=
#
# Remember to set ODIR, ANALYSIS and HSAP by gmaster
#
CP="cp -vapudf" ;
#
while read locus ;
  do {
    echo "### Copying files for $locus ..." ;
    $CP $ANALYSIS/sgp/rguigo/ps/_tmp/sgp/$locus    $ODIR/$locus.gff ;
    gawk 'BEGIN{ OFS="\t" }
          { if ($1 !~ /^#|^[ \t]*$/) { $2="SGP.homol" };
            print $0;
            }' $ANALYSIS/sgp/rguigo/gtf2/$locus \
              > $ODIR/$locus.gtf ;
    $CP $ANALYSIS/sgp/rguigo/hsp/$locus            $ODIR/$locus.hsp ;
    $CP $ANALYSIS/sgp/rguigo/tbx/$locus            $ODIR/$locus.tbx ;
    $CP $ANALYSIS/sgp/rguigo/ps/gff2ps/a4/$locus   $ODIR/$locus.a4.ps ;
    $CP $ANALYSIS/sgp/rguigo/ps/gff2ps/a3/$locus   $ODIR/$locus.a3.ps ;
    # $CP $ANALYSIS/sgp/rguigo/ps/gff2ps/wide/$locus $ODIR/$locus.wide.ps ;
    } ;
  done < $HSAP ; 
#
pushd $ODIR ;
#
cat Hsap_*.gff > All.gff ;
cat Hsap_*.gtf > All.gtf ;
cat Hsap_*.hsp > All.hsp ;
cat Hsap_*.tbx > All.tbx ;
#
tar -zcvf HomologyA3PS.tar.gz Hsap_*.a3.ps ;
tar -zcvf HomologyA4PS.tar.gz Hsap_*.a4.ps ;
tar -zcvf HomologyGFF.tar.gz  Hsap_*.gff ;
tar -zcvf HomologyGTF.tar.gz  Hsap_*.gtf ;
tar -zcvf HomologyHSP.tar.gz  Hsap_*.hsp ;
tar -zcvf HomologyTBX.tar.gz  Hsap_*.tbx  ;
#
@ 

\subsctn{Results on human/mouse 3X WGS sequence comparison} % TO DO

\begin{comment}
ODIR="./homologseqs" ;
ANALYSIS="/projects/sgp/orthologous" ;
HSAP="/projects/datasets/orthologous/id.Hsap" ;
\end{comment}
<<BASH commands ANALYSIS>>=
#
# Remember to set ODIR, ANALYSIS and HSAP by gmaster
#
CP="cp -vapudf" ;
#
@ 

\newpage %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\appendix %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\sctn{Related Tables and Plots}

\subsctn{Annotated Human Genes for Homologous Sequences Set}

\begin{comment}
<<BASH commands>>=
gawk 'BEGIN{ 
        lncnt=0;
        ROWS=47;
        header="\\begin{tabular}[t]{|r|lrrc|}\n\\hline\n";
        header=header"\\lb{1cm}{r}{SEQ} & \\lb{1.5cm}{l}{GENE} & ";
        header=header"\\lb{1cm}{r}{START} & \\lb{1cm}{r}{END} & ";
        header=header"\\lb{0.5cm}{c}{STR} \\\\";
        print "\\newcommand{\\lb}[3]{\\makebox[#1][#2]{#3}}\n";
        print "\\begin{tabular}{c@{\\quad}c@{\\quad}c}"; # main table
        print header;
        }
      { split($1,n,"_");
        corr="";
        if ( lncnt%ROWS == 0 && lncnt > 0 ) {
          print "\\hline\n\\end{tabular}\n &";
          print header;
          n[2]="\\raisebox{-2.25ex}{\\shortstack{" n[2] "\\\\(\\textit{cont.})}}";
          corr="[-1.75ex]";
          } 
        if ( cnt[n[2]] && n[2] !~ /\{cont\.\}/ ) {
          n[2]=""; 
          } 
        else { 
          printf "\\hline\n"; 
          cnt[n[2]]++;
          }
        printf "%8s & %-10s & %8s & %8s & %s \\\\%s\n", n[2],$2,$3,$4,$5,corr;
        lncnt++;
        }
      END{ 
        print "\\hline\n\\end{tabular}\n\\\\";
        print "\\end{tabular}"; # main table
        }' $DATASETS/genes.Hsap > $DOCS/tables/genelist.tex ;
@ 
\end{comment}

\begin{table}[!h]
\hspace{-0.5cm}
\fbox{
\rotatebox{90}{
\begin{minipage}[c][17.5cm][c]{22.5cm}
\begin{center}
\begin{scriptsize}
 \input ./tables/genelist.tex
\end{scriptsize}
\caption[Annotated genes for the human sequences in the test set]{\label{tbl:genelist} Annotated genes for the human sequences in the {\data} test set.}\vskip 1ex
\end{center}
\end{minipage}
}}
\end{table}

\newpage

\newpage %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\sctn{Main [[README]] files}

Here we provide the basic skeleton for the [[README]] files we will generate on each main directories for the current dataset.

<<DATASETS README>>=
#
#                 PREPARING DATASETS FOR
<<README common>>
<<BASH commands DATASETS>>
@ 

<<SGP README>>=
#
#               RUNNING GENE-PREDICTION FOR
<<README common>>
<<BASH commands ANALYSIS>>
@ 

<<SPLICING README>>=
#
#                  SPLICING ANALYSIS ON
<<README common>>
<<BASH commands SPLICING>>
@ 

<<README common>>=
#           8 ORTHOLOGOUS HUMAN/MOUSE SEQUENCES
#
# This README file was tangled from ORTHOLOGOUS_dataset.nw
#
<<Version Control Id Tag>>
#
# EXPORTING GLOBAL VARS and DEFINING BASIC SHELL FUNCTIONS
#
<<BASH Environment Variables>>
#
@ 

<<tangling - READMEs>>=
notangle -R"DATASETS README" $WORK/$nwfile.nw \
    > $DATASETS/README ;
notangle -R"SGP README" $WORK/$nwfile.nw \
    > $ANALYSIS/README ;
notangle -R"SPLICING README" $WORK/$nwfile.nw \
    > $SPLICING/README ;
@

% \newpage %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\sctn{Programs not included in this document}

The \sgp used in this approach uses different scrips and programs. When we started it was still not well controled. Therefore we decided to copy the binary files from [[~rguigo/research/humus/SGP2-2/sggp2/bin]] to [[/projects/sgp/bin/SGP2-2/]]. The copied files were the following:

\begin{center}
\begin{tabular}{l}
geneid          \\
blast2gff       \\
blast2hsp       \\
human3iso.param \\
\end{tabular}
\end{center}

The path variable in the sggp2 shell script has been changed to [[/projects/sgp/bin/SGP2-2/]].

\newpage %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\sctn{Scripts Central}

\subsctn{[[fasta_renamer.pl]]: renaming and reformating fasta files}

<<Renaming fasta sequence IDs>>=
<<PERL shebang>>
#
# fasta_renamer.pl infile descfile new_seq_id > outfile
#
#     Replacing sequence name 
#     for single sequence fasta files
#     and reformating sequence to 80 cols.
#
use lib qw( /usr/lib/perl5/site_perl/5.005/ /usr/lib/perl5/5.00503/ ) ;
use Bio::Seq;
use Bio::SeqIO;

my ($infile,$descfile,$newid) = @ARGV;

my $seqin  = Bio::SeqIO->new(-format => 'FASTA', -file => "$infile");
my $seqout = Bio::SeqIO->new(-format => 'FASTA', -fh => \*STDOUT);

open(DESC,"> $descfile");
while (my $sequence = $seqin->next_seq()) {
    my ($sid,$len,$seq,$desc);
    print STDERR "### READING FASTA... $newid\n";
    $sid  = $sequence->display_id();
    $desc = $sequence->desc();
    $len  = $sequence->length();
    $seq  = $sequence->seq();
    $sid =~ s/\s+/\_/og;
    $seq =~ tr/[a-z]/[A-Z]/;
    print STDERR "### WRITING FASTA... $newid\n";
    print DESC "$newid $sid $len $desc\n";
    $sequence->display_id($newid);
    $sequence->desc('');
    $sequence->seq($seq);
    $seqout->write_seq($sequence);
}; # while 
close(DESC);
exit(0);
@

\newpage

\subsctn{[[coords2gff.pl]]: converting coords files into GFF}

<<Raw coords to GFF>>=
<<PERL shebang>>
#
# coords2gff.pl seqname < coords_file > GFF_file
#
#     Converting raw coords files to GFF
#
# use Data::Dumper;
# local $Data::Dumper::Purity = 0;
# local $Data::Dumper::Deepcopy = 1;

my ($seqname,%gff,$string);
$seqname = shift @ARGV;
%gff = ();
$string = ("\%s\t" x 8)."\%s\n";

my $c = 0;
while (<STDIN>) {
    next if /^\s*$/o;
    my ($l,$a,$b,$s,$r);
    chomp;
    $l = $_;
	# print STDERR "$. (X): $l\n";
    $l =~ /^[><]/o && do {
	    # print STDERR "$. (A): $l\n";
        $l =~ s/^([><])\s*//o && ($s = $1);
        $r = \%{ $gff{++$c} };
        ($r->{gn_start},$r->{gn_end},$r->{gn_name}) = split /\s+/og, $l, 3;
        $r->{gn_name} =~ s/\s+$//og;
        $r->{gn_name} =~ s/\s+/_/og;
        $r->{strand} = ($s eq '>') ? '+' : (($s eq '<') ? '-' : '.');
        # $r->{exons} = ();
        next;
	}; # $newgene ?
	# print STDERR "$. (B): $l\n";
    ($a,$b,undef) = split /\s+/og, $l, 3;
    push @{ $gff{$c}{exons} }, [ $a, $b ];
}; # while
# print STDERR Dumper(\%gff);

foreach my $i (1..$c) {
    my $r = \%{ $gff{$i} };
    my $exnum = scalar(@{ $r->{exons} });
    print STDOUT "\# $seqname - $r->{gn_name}: ".
        ($exnum)." exons\n";
    printf STDOUT $string, 
        $seqname,'annotation','Gene',$r->{gn_start},$r->{gn_end},
        '.',$r->{strand},'.',$r->{gn_name};
    $r->{strand} eq '-' && (@{ $r->{exons} } = reverse @{ $r->{exons} });
    my ($lastori,$lastend,$lastfrm) = (0,0,0);
    foreach my $j (0..$#{ $r->{exons} }) {
        my ($feat,$ori,$end,$frm);
        ($ori,$end) = @{ ${ $r->{exons} }[$j] };
	  THIS: {
        ($j == 0) && do {
            $feat = 'First';
            $exnum == 1 && ($feat = 'Single');
            $frm = 0;
            last THIS;
        }; # $d == 0
        $frm = (($lastend - $lastori + 1) + $lastfrm) % 3;
        ($j == $#{ $r->{exons} }) && do {
            $feat = 'Terminal';
            last THIS;
        }; # $d == $#{ $r->{exons} }
        $feat = 'Internal';
      }; # THIS
        # print STDERR "$r->{gn_name} ($j): $ori $end $frm : ".
        #              "$lastori $lastend $lastfrm\n";
        ($lastori,$lastend,$lastfrm) = ($ori,$end,$frm);
        printf STDOUT $string, 
            $seqname,'annotation',$feat,$ori,$end,
            '.',$r->{strand},$frm,$r->{gn_name};
    }; # foreach @j
}; # foreach $i

exit(0);
@ 

\newpage

\subsctn{[[getfastamasked.pl]]: retrieve masked from fasta sequences}

<<Masked from fasta sequences>>=
<<PERL shebang>>
#
# getfastamasked.pl < fastafile > GFFfile
#
#     Retrieving masked regions coords from fasta files
#
use Bio::Seq;
use Bio::SeqIO;
<<Use Modules - Benchmark>>
my $PROGRAM = 'getfastamasked.pl';
my ($T,$F) = (1,0);
my $DATE = localtime;
my $USER = defined($ENV{USER}) ? $ENV{USER} : '??????';
my $host = `hostname`;
chomp($host);
my $line = ('#' x 80)."\n";
my $s = '### ';
#
my ($id,$seq) = ('','');
my ($total_time);

print STDERR << "+++EOR+++";
$line$s\n$s Running $PROGRAM\n$s
$s HOST: $host
$s USER: $USER
$s DATE: $DATE\n$s\n$line$s
+++EOR+++

&main();

$total_time = &timing($T);
print STDERR << "+++EOR+++";
$s\n$line$s\n$s $PROGRAM FINISHED\n$s
$s TOTAL TIME: $total_time\n$line
+++EOR+++

exit(0);

sub main() {
    my $seqin = Bio::SeqIO->new(-format => 'FASTA', -fh => \*STDIN);
    while (my $sequence = $seqin->next_seq()) {
        my ($sid,$len,$seq,@nuc,@coords,$masked_flg,$match,$msk_num);
        @coords = ();
        <<Setting sequence variables from fasta record>>
        <<Finding masked regions coords>>
        <<Writing masked regions coords in GFF>>
    }; # while 
} # main
<<Common PERL subs - Benchmark>>
@ 

<<Setting sequence variables from fasta record>>=
print STDERR "### READING FASTA............\n";
$sid  = $sequence->display_id();
$len  = $sequence->length();
$seq  = $sequence->seq();
@ 

<<Finding masked regions coords>>=
print STDERR "###         PARSING SEQUENCE: $sid ($len bp)\n";
@nuc = split //og, $seq;
($masked_flg,$match) = ($F,$F) ;
for (my $n = 0; $n <= $#nuc; $n++) {
    $match = ( $nuc[$n] =~ /[NnXx]/o ) ? $T : $F;
    ( !$masked_flg && $match ) && do {
        $masked_flg = $T ;
        # $n contains the last non-masked nucleotide
        push @coords, ($n + 1);
        next;
    };
    $masked_flg && do {
        $match && (next);
        $masked_flg = $F ;
        # $n contains the last masked nucleotide now
        push @coords, $n;
    };
}; # for nuc in $seq
# if last nucleotide is masked, previous loop not includes its coord. 
$masked_flg &&( push @coords, $len);
@ 

<<Writing masked regions coords in GFF>>=
$msk_num = scalar(@coords) / 2;
print STDERR "###         WRITING GFF COORDS: $msk_num masked regions found.\n";
for (my $n = 0; $n <= $#coords; $n+=2) {
    my $GFFstring = ("\%s\t" x 5).(".\t" x 3).".\n";
    printf STDOUT $GFFstring, $sid, "masked", "masked", @coords[$n..($n + 1)];
}; # for coords in @coords
@ 

\newpage

\subsctn{[[splitfastaseq.pl]]: split large fasta sequences}

<<Breaking fasta sequences>>=
<<PERL shebang>>
#
# splitfastaseq.pl \
#     seqlength overlap < fastafile > output
#
#     Breaking large fasta sequences to build 
#     databases for running tblastx faster
# 
use lib qw( /usr/lib/perl5/site_perl/5.005/ );
use Bio::Seq;
use Bio::SeqIO;
use Benchmark;
my ($T,$F) = (1,0);
my @Timer = (new Benchmark);
my $PROGRAM = 'splitfastaseq.pl';
my $DATE = localtime;
my $USER = defined($ENV{USER}) ? $ENV{USER} : '??????';
my $host = `hostname`;
chomp($host);
my $line = ('#' x 80)."\n";
my $s = '### ';
#
my ($id,$ln,$sq) = ('',0,'');
my ($total_time,$seq);
my ($maxlen,$overlap) = @ARGV;

print STDERR << "+++EOR+++";
$line$s\n$s Running $PROGRAM\n$s
$s HOST: $host
$s USER: $USER
$s DATE: $DATE\n$s\n$line$s
+++EOR+++

&getseq();
&splitseq();

$total_time = &timing($T);
print STDERR << "+++EOR+++";
$s\n$line$s\n$s $PROGRAM FINISHED\n$s
$s TOTAL TIME: $total_time\n$line
+++EOR+++

exit(0);

sub getseq() { # assuming here single sequence input fasta files
    print STDERR "$s Processing fasta file.\n";
    my $seqin = Bio::SeqIO->new(-format => 'FASTA', -fh => \*STDIN);
    while (my $iseq = $seqin->next_seq()) {
        $id = $iseq->display_id();
        $ln = $iseq->length();
        $sq = $iseq->seq();
        last; # to make sure that we only catch a single fasta sequence
    }; # while next_seq
    $seq = Bio::Seq->new( -seq => $sq , -id => $id );
    print STDERR "$s Processing DONE: ".(&timing($F))."\n$s\n";
} # getseq
#
sub splitseq() {
    my ($e,$sid,$ssq,$nseq,$wseq);
    my ($t,$sqlen) = (1,($maxlen + $overlap - 1));
    print STDERR "$s Creating splitted-sequence fasta file ($ln nt).\n";
    my $seqout = Bio::SeqIO->new(-format => 'FASTA', -fh => \*STDOUT);
    while ($t < $ln) {
         $e = $t + $sqlen;
         ($e > $ln) && ($e = $ln);
         $sid = "$id\_$t\_$e";
         print STDERR "$s --> $id : from $t to $e (".($e - $t + 1)." nt)\n";
         $ssq = $seq->subseq($t,$e);
         $t += $maxlen;
         #
         $wseq = Bio::Seq->new( -seq => $ssq , -id => $sid );
         $seqout->write_seq($wseq);
    }; # while  
    print STDERR "$s Splitting DONE: ".(&timing($F))."\n$s\n";
} # splitseq
#
sub timing() {
    push @Timer, (new Benchmark);
    # partial time
    $_[0] ||
        (return timestr(timediff($Timer[$#Timer],$Timer[($#Timer - 1)])));
    # total time
    return timestr(timediff($Timer[$#Timer],$Timer[0]));
} # timing
@ 

\newpage

\subsctn{[[gff2gtf.pl]]: translating GFF to GTF2}

<<GFF to GTF>>=
<<PERL shebang>>
#
# gff2gtf.pl < infile > outfile
#
#     Converting GFF formated records into GTF
#
# use lib qw( /usr/lib/perl5/site_perl/5.005/ /usr/lib/perl5/5.00503/ ) ;
use Benchmark;
# use Data::Dumper;
# local $Data::Dumper::Purity = 0;
# local $Data::Dumper::Deepcopy = 1;
my ($T,$F) = (1,0);
my @Timer = (new Benchmark);
my $PROGRAM = 'gff2gtf.pl';
my $DATE = localtime;
my $USER = defined($ENV{USER}) ? $ENV{USER} : '??????';
my $host = `hostname`;
chomp($host);
my $line = ('#' x 80)."\n";
my $s = '### ';
#
print STDERR << "+++EOR+++";
$line$s\n$s Running $PROGRAM\n$s
$s HOST: $host
$s USER: $USER
$s DATE: $DATE\n$s\n$line$s
+++EOR+++

my %genes;
my @f = ();
my $gcnt = 0;
while (<>) {
    /^\# Gene/o && do {
        $gcnt++;
        $genes{$gcnt}{COMMENT} = $_;
        next;
    };
    next if /^\#/o;
    next if /^\s*$/o;
    chomp;
    @f = split /\s+/og, $_;
    push @{ $genes{$gcnt}{FEATURES} }, [ @f[0..8] ];
}; # while

# print STDERR Dumper(\%genes);

my $GTFrec = ("\%s\t" x 8)."\%s\n";
foreach my $i (1..$gcnt) {
    print STDOUT $genes{$i}{COMMENT};
    my ($main,$tail_O,$tail_E,$groupflg,$gtfgroup) = ('','','',$T,'');
    foreach my $j (0..$#{ $genes{$i}{FEATURES} }) {
        my ($seq,$source,$feat,$start,$end,
            $score,$strand,$frame,$group,
            $cdsfeat,$cdsori,$cdsend,$t);
        ($seq,$source,$feat,$start,$end,
            $score,$strand,$frame,$group) =
                @{ $genes{$i}{FEATURES}[$j] };
        $score = '.';
        $groupflg && do {
            $group =~ s/gene_//o;
            $t = &fill_left($group,3,"0");
            $gtfgroup = "gene_id $t; transcript_id $t.1";
            $groupflg = $F;
        }; # $groupflg
      FEATS: {
          $feat eq 'Single' && do {
              ($cdsfeat,$cdsori,$cdsend) = &get_start($start,$end,$strand);
              $tail_O = sprintf($GTFrec,$seq,$source,$cdsfeat,$cdsori,$cdsend,
                                $score,$strand,'0',$gtfgroup);
              ($cdsfeat,$cdsori,$cdsend) = &get_final($start,$end,$strand);
              $tail_E = sprintf($GTFrec,$seq,$source,$cdsfeat,$cdsori,$cdsend,
                                $score,$strand,'0',$gtfgroup);
              last FEATS;
          }; # Single
          $feat eq 'First' && do {
              ($cdsfeat,$cdsori,$cdsend) = &get_start($start,$end,$strand);
              $tail_O = sprintf($GTFrec,$seq,$source,$cdsfeat,$cdsori,$cdsend,
                                $score,$strand,'0',$gtfgroup);              
              last FEATS;
          }; # First
          $feat eq 'Terminal' && do {
              ($cdsfeat,$cdsori,$cdsend) = &get_final($start,$end,$strand);
              $tail_E = sprintf($GTFrec,$seq,$source,$cdsfeat,$cdsori,$cdsend,
                                $score,$strand,'0',$gtfgroup);
                  # only if nucleotides of stop codon not included
                  #     $strand eq '+' && ($end = $end + 3);
                  #     $strand eq '-' && ($start = $start - 3);
              # last FEATS;
          }; # Terminal
        }; # FEATS
        $feat = 'CDS';
        $main .= sprintf($GTFrec,$seq,$source,$feat,$start,$end,
                         $score,$strand,$frame,$gtfgroup); 
    }; # foreach $j
    print STDOUT "$main$tail_O$tail_E";
}; # foreach $i

my $total_time = &timing($T);
print STDERR << "+++EOR+++";
$s\n$line$s\n$s $PROGRAM FINISHED\n$s
$s TOTAL TIME: $total_time\n$line
+++EOR+++

exit(0);

sub get_start() {
    my ($o,$e,$s) = @_;
    my $str = "start_codon";
    $s eq '+' && do {
       return $str, $o, ($o + 2);
    }; # forward
    $s eq '-' && do {
       return $str, ($e - 2), $e;
    }; # reverse
    die("### ERROR: Strand not defined... ($o $e : $s)... $!");
} # 
#
sub get_final() {
    my ($o,$e,$s) = @_;
    my $str = "stop_codon";
    $s eq '+' && do {
        return $str, ($e - 2), $e;
           # only if nucleotides of stop codon not included
           #     return $str, ($e + 1), ($e + 3);
    }; # forward
    $s eq '-' && do {
        return $str, $o, ($o + 2);
           # only if nucleotides of stop codon not included
           #     return $str, ($o - 3), ($o -1);
    }; # reverse
    die("### ERROR: Strand not defined... ($o $e : $s)... $!");
} # 
#
sub fill_left() { ($_[2] x ($_[1] - length($_[0]))).$_[0] } 
#
sub timing() {
    push @Timer, (new Benchmark);
    # partial time
    $_[0] ||
        (return timestr(timediff($Timer[$#Timer],$Timer[($#Timer - 1)])));
    # total time
    return timestr(timediff($Timer[$#Timer],$Timer[0]));
} # timing
@ 

\newpage

\subsctn{pspager.pl}

\subsubsctn{Page formats definition}

\input tables/PageSizeTbl.tex


\subsubsctn{Available page sizes}

<<LATEX page format table>>=
%
% PageSizeTbl.tex
%
% Page Sizes used in "pspager.pl".
%
% <<Version Control Id Tag>>
%
\label{sec:pagesizes}
\def\prog{\texttt{pspager.pl}}
%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\vfill
\begin{table}[!ht]
\begin{center}
\setlength{\fboxsep}{2pt}
%\setlength{\arrayrulewidth}{1pt}
\fbox{
 \begin{tabular}{|c||r|r||r|r||r|r|} \hline
  \raisebox{-0.5ex}[0pt]{PAGE} &
  \multicolumn{6}{c|}{PAGE SIZE}\\ \cline{2-7} \raisebox{0.25ex}[0pt]{FORMAT} &
  \multicolumn{2}{c||}{(in points)} &
  \multicolumn{2}{c||}{(in cms)} &
  \multicolumn{2}{c|}{(in inches)}\\ \hline\hline
  <<page sizes latex definition>>
 \end{tabular}
} % fbox
\caption{\label{tbl:PageSztbl}Page Sizes defined in {\prog}.}\hspace{1cm}
  %\refstepcounter{table}
  %\addcontentsline{lot}{section}{
  %   \thetable\hspace{1em}Page Sizes available at {\prog}.}
\end{center}
\end{table}
\vfill
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
@

<<Docs>>=
echo "Extracting \"$DOCS/PageSizeTbl.tex\"..." ;
notangle -R"LATEX page format table" $WORK/$nwfile.nw \
         > $DOCS/tables/PageSizeTbl.tex ;
@ 

<<PostScript FORMATS>>=
sub ps_page_formats() {
  my %tmp = ();
  print STDOUT "%% Paper Sizes (in points)\n";
  print STDOUT "/pagedict ".($formats + 2)." dict def pagedict begin %% ".
               $formats." formats + 2 definitions\n";
  foreach my $key (keys %FORMATS) { $tmp{$FORMATS{$key}->[0]} = $key };
  for (my $j = 1; $j <= $formats; $j++) { 
      my $name = $tmp{$j};
      my $ref = \$FORMATS{$name};
      my $pgsz = &fill_left($$ref->[1],4," ").&fill_left($$ref->[2],5," ");
      print STDOUT "/pg".(&fill_right($name,10," "))."{ $pgsz } def\n";
      };
  print STDOUT "end %% pagedict\n";}
@

<<Global Vars>>=
my $formats = 0;
my %FORMATS = (   # [ FormatNUMBER, X(short edge), Y(long edge) ]
  <<page sizes perl definition>>
  );
@ 

\subsubsctn{Page format definition} %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\label{sec:PAGEdef}

\subsubsubsctn{ISO standard page sizes: A series}

<<page sizes perl definition>>=
  a0        => [ ++$formats, 2384, 3370 ],
  a1        => [ ++$formats, 1684, 2384 ],
  a2        => [ ++$formats, 1190, 1684 ],
  a3        => [ ++$formats,  842, 1190 ],
  a4        => [ ++$formats,  595,  842 ],
  a5        => [ ++$formats,  420,  595 ],
  a6        => [ ++$formats,  297,  420 ],
  a7        => [ ++$formats,  210,  297 ],
  a8        => [ ++$formats,  148,  210 ],
  a9        => [ ++$formats,  105,  148 ],
  a10       => [ ++$formats,   73,  105 ],
@
<<page sizes latex definition>>=
%               points    -  centimeters  -     inches
a0          & 2384 & 3370 &  84.1 & 118.9 &  33.1 &  46.8 \\
a1          & 1684 & 2384 &  59.4 &  84.1 &  23.4 &  33.1 \\
a2          & 1190 & 1684 &  42.0 &  59.4 &  16.5 &  23.4 \\
a3          &  842 & 1190 &  29.7 &  42.0 &  11.7 &  16.5 \\
a4          &  595 &  842 &  21.0 &  29.7 &   8.3 &  11.7 \\
a5          &  420 &  595 &  14.8 &  21.0 &   5.8 &   8.3 \\
a6          &  297 &  420 &  10.5 &  14.8 &   4.1 &   5.8 \\
a7          &  210 &  297 &   7.4 &  10.5 &   2.9 &   4.1 \\
a8          &  148 &  210 &   5.2 &   7.4 &   2.1 &   2.9 \\
a9          &  105 &  148 &   3.7 &   5.2 &   1.5 &   2.1 \\
a10         &   73 &  105 &   2.6 &   3.7 &   1.0 &   1.5 \\ \hline\hline
@

\subsubsubsctn{ISO standard page sizes: B series}

<<page sizes perl definition>>=
  b0        => [ ++$formats, 2920, 4127 ],
  b1        => [ ++$formats, 2064, 2920 ],
  b2        => [ ++$formats, 1460, 2064 ],
  b3        => [ ++$formats, 1032, 1460 ],
  b4        => [ ++$formats,  729, 1032 ],
  b5        => [ ++$formats,  516,  729 ],
  b6        => [ ++$formats,  363,  516 ],
  b7        => [ ++$formats,  258,  363 ],
  b8        => [ ++$formats,  181,  258 ],
  b9        => [ ++$formats,  127,  181 ],
  b10       => [ ++$formats,   91,  127 ],
@
<<page sizes latex definition>>=
%               points    -  centimeters  -     inches
b0          & 2920 & 4127 & 103.0 & 145.6 &  40.6 &  57.3 \\
b1          & 2064 & 2920 &  72.8 & 103.0 &  28.7 &  40.6 \\
b2          & 1460 & 2064 &  51.5 &  72.8 &  20.3 &  28.7 \\
b3          & 1032 & 1460 &  36.4 &  51.5 &  14.3 &  20.3 \\
b4          &  729 & 1032 &  25.7 &  36.4 &  10.1 &  14.3 \\
b5          &  516 &  729 &  18.2 &  25.7 &   7.2 &  10.1 \\
b6          &  363 &  516 &  12.8 &  18.2 &   5.0 &   7.2 \\
b7          &  258 &  363 &   9.1 &  12.8 &   3.6 &   5.0 \\
b8          &  181 &  258 &   6.4 &   9.1 &   2.5 &   3.6 \\
b9          &  127 &  181 &   4.5 &   6.4 &   1.8 &   2.5 \\
b10         &   91 &  127 &   3.2 &   4.5 &   1.3 &   1.8 \\ \hline\hline
@

\subsubsubsctn{US standard page sizes}

<<page sizes perl definition>>=
  executive => [ ++$formats,  540,  720 ],
  folio     => [ ++$formats,  612,  936 ],
  legal     => [ ++$formats,  612, 1008 ],
  letter    => [ ++$formats,  612,  792 ],
  quarto    => [ ++$formats,  610,  780 ],
  statement => [ ++$formats,  396,  612 ],
 '10x14'    => [ ++$formats,  720, 1008 ],
  ledger    => [ ++$formats, 1224,  792 ],
  tabloid   => [ ++$formats,  792, 1224 ],
@
<<page sizes latex definition>>=
%               points    -  centimeters  -     inches
executive   &  540 &  720 &  19.0 &  25.4 &   7.5 &  10.0 \\
folio       &  612 &  936 &  21.6 &  33.0 &   8.5 &  13.0 \\
legal       &  612 & 1008 &  21.6 &  35.6 &   8.5 &  14.0 \\
letter      &  612 &  792 &  21.6 &  27.9 &   8.5 &  11.0 \\
quarto      &  610 &  780 &  21.5 &  27.5 &   8.5 &  10.8 \\
statement   &  396 &  612 &  14.0 &  21.6 &   5.5 &   8.5 \\ \hline\hline
10x14       &  720 & 1008 &  25.4 &  35.6 &  10.0 &  14.0 \\
ledger      & 1224 &  792 &  43.2 &  27.9 &  17.0 &  11.0 \\
tabloid     &  792 & 1224 &  27.9 &  43.2 &  11.0 &  17.0 \\ \hline
@

\subsubsubsctn{Page sizes help}

<<pages help>>=
The following page sizes are available: from A0 to A10, 
from B0 to B10, 10x14, executive, folio, ledger, legal, 
letter, quarto, statement and tabloid.
@

\subsubsctn{The program}

<<pspager.pl>>=
<<PERL shebang>>
#
# pspager.pl : printing virtual pages into several physical ones.
#
# USAGE: pspager.pl [options] PSfile > PSfile_page 
#
# VARIABLES
<<Global Vars - pspager>>
#
# MAIN LOOP
<<Main Loop - pspager>>
#
# FUNCTIONS
<<Functions - pspager>>
@ 

<<Main Loop - pspager>>=
&parse_commandline();
&parse_inputfile($PSinput);
&setting_vars();
&write_PS_output();

exit(0);
@ 

<<Functions - pspager>>=
sub parse_commandline() {
    <<looking for STDIN>>

    $SIG{__WARN__} = sub { &warn('UNKNOWN_CL_OPTION',$T,$_[0]) };
    GetOptions(
               <<command-line options>>
               ) || (&warn('CMD_LINE_ERROR',$T), exit(1));
    $SIG{__WARN__} = 'DEFAULT';

    <<open LOGFILE>>

    &header('',"RUNNING $PROGRAM",'',"User: $USER","Date: $DATE");

    &header("SETTING DEFAULTS");
    %DefaultVars = ();
    &set_default_vars;

    &header("CHECKING COMMAND-LINE OPTIONS");
    @data_files = ();
    &set_input_file($cmdln_stdin);
    @ARGV = (); # ensuring that command-line ARGVs array is empty

    &set_custom_files();

    <<Check command-line options>>

    &footer("COMMAND-LINE CHECKED");
} # parse_commandline
@

<<Functions - pspager>>=
sub parse_inputfile() {
} # parse_inputfile
@

<<Functions - pspager>>=
sub setting_vars() {
} # setting_vars
@

<<Functions - pspager>>=
sub write_PS_output() {
} # write_PS_output
@

<<pspager.pl>>=
my ($ctx, $cty) = (0, 0);
my ($x, $y);
# my @page_OUT = (  792,  1224 ); # 11x17 (tabloid) page format
my @page_OUT = (  612,  792 ); # letter page format
# my @page_OUT = (  595,  842 ); # a4 page format
my $margin = 20;
my ($xdelta, $ydelta) = ($page_OUT[0]-($margin * 2), $page_OUT[1]-($margin * 2));

my @page_IN;
push @page_IN, shift @ARGV, shift @ARGV;

my $orientation = shift @ARGV;
my $orflg = $orientation eq "l" ? "true" : "false";

my $file = $ARGV[0];

print STDERR ("#"x40)."\n## RUNNING multipager ON: $file\n".("#"x40)."\n";
print STDERR "## PAGE IN:  $page_IN[0] - $page_IN[1] (".($orientation eq "l" ? "Landscape" : "Portrait").")\n";
print STDERR "## PAGE OUT: $page_OUT[0] - $page_OUT[1] (Portrait)\n".("#"x40)."\n";

for ($x=0;$x<$page_IN[0];$x+=$xdelta) {
        $ctx++; $cty = 0;
        for ($y=0;$y<$page_IN[1];$y+=$ydelta) {
                $cty++;
                print STDERR "## Printing Page X($ctx) Y($cty)\n";
                open(K,"< $file");
                open(L,"> $file.MULTI.$ctx\_$cty");
                while (<K>) {
                        print L $_;
                        /^%%BeginProlog/ && &pscode;
                }
                close(L);
                close(K);
        }
}

sub pscode {
        print L << "EOF";
%%
/cutmrg $margin def
/lndscp $orflg def
/bbox { 4 copy 3 1 roll exch 6 2 roll 8 -2 roll moveto lineto lineto lineto closepath } bind def 
% 0 0 $page_OUT[0] $page_OUT[1] bbox 1 0 0 0 setcmykcolor fill newpath
/cutmrk {
  gsave 
  translate scale
  0 setgray 0.125 setlinewidth
  gsave 0 -1 moveto 0 cutmrg neg lineto stroke grestore
  gsave -1 0 moveto cutmrg neg 0 lineto stroke grestore
  grestore
  } bind def 
/mkmrk {
   gsave 0 0 translate cutmrg 12 add cutmrg 12 sub moveto /Helvetica-Bold findfont 9 scalefont setfont (Page $ctx/$cty - X($x):Y($y)) show grestore     
    1  1 cutmrg                  cutmrg                   cutmrk
   -1 -1 $page_OUT[0] cutmrg sub $page_OUT[1] cutmrg sub  cutmrk
    1 -1 cutmrg                  $page_OUT[1] cutmrg sub  cutmrk
   -1  1 $page_OUT[0] cutmrg sub cutmrg                   cutmrk
   cutmrg cutmrg $page_OUT[0] cutmrg sub $page_OUT[1] cutmrg sub  bbox 
  gsave 1 setgray fill grestore
  % gsave stroke grestore
  clip       
  newpath    
  } bind def 
%%           
2 dict dup /PageSize [ $page_OUT[0] $page_OUT[1] ] put dup /ImagingBBox null put setpagedevice
mkmrk lndscp { cutmrg $x add neg cutmrg $y add neg translate } { cutmrg $x sub cutmrg $y sub translate } ifelse
%%
EOF
}
@ 

<<pspager.pl>>=
%!PS-Adobe-3.0 
%%Title: (Using EPS file in Form in VM) 
%%BoundingBox: 0 0 612 792 
%%DocumentProcessColors: Black 
%%Pages: 3 
%%PageOrder: Special 
%%EndComments 
%%BeginProlog 
%%BeginResource: procset helper_ops 1.0 0 
%%Title: (Helper Operators) 
%%Version: 1.0 
userdict /helper_ops 10 dict dup begin put

/L1? {
    /languagelevel where {
       pop languagelevel 2 lt
    }{
       true
    } ifelse
} bind def

/StartDoc { 
    userdict begin 
    /PreForm save def 
    /showpage {} def
} bind def

/EndDoc { 
    PreForm restore 
    end % userdict
} bind def

/rfill { % llx lly w h rfill --
    gsave newpath 
    4 -2 roll moveto % use x, y coordinates
    2 copy 0.0 lt exch 0.0 lt xor { % check for one arg only being neg 
        dup 0.0 exch rlineto % do height first 
        exch 0.0 rlineto 
        neg 0.0 exch rlineto
    }{ 
        exch dup 0.0 rlineto % do width first 
        exch 0.0 exch rlineto
        neg 0.0 rlineto
    } ifelse
    closepath
    fill grestore
} bind def

/add_var_data { % procedure to add variable data to fill in form
    /Times-Roman findfont 12 scalefont setfont 
    L1? { % if Level 1, need to draw white boxes where data will be placed
        gsave
        1 setgray
        87 360 350 20 rfill
        190 430 350 20 rfill
        190 535 350 20 rfill
        190 600 350 20 rfill
        grestore
    } if
    97 370 moveto show
    200 440 moveto show
    200 545 moveto show
    200 610 moveto show
} bind def

/emitpage { 
    L1? {
       add_var_data copypage
    }{
       TestForm execform add_var_data showpage
    } ifelse
} bind def

/emitlastpage {
    L1? {
       add_var_data showpage
    }{
       emitpage
    } ifelse
} bind def

currentdict readonly pop end
%%EndResource

%%BeginResource: procset forms_procs 1.0 0 
%%Title: (Forms Procs)
%%Version: 1.0
userdict /forms_procs 10 dict dup begin put

/STRING_SIZE 16000 def
/ARRAY_SIZE 5 def % UPDATE DEPENDING ON SIZE OF INCLUDED DOCUMENT
                  % (leave room for initial counter and final empty string)

/buffer STRING_SIZE string def 

/readdata {
  L1? { % readdata -- 
      StartDoc
  }{    % array readdata --
      1 {                             % put counter on stack
                                      % stack: array counter
          2 copy                      % stack: array counter array counter
          inputFile buffer readstring % read contents of currentfile into buffer
                                      % stack: array counter array counter string boolean
          4 1 roll                    % put boolean indicating EOF lower on stack
          STRING_SIZE string copy     % copy buffer string into new string 
                                      % stack: array counter boolean array counter newstring
          put                         % put string into array
          not {exit} if               % if EOF has been reached, exit loop.
          1 add                       % increment counter
        } loop
      % increment counter and place empty string in next position 
      1 add 2 copy () put pop
      currentglobal true setglobal exch

          0 1 array put % create an array for counter in global VM,
                        % so as not to be affected by save/restore calls in EPS file.
                        % place as first element of string array. 
      setglobal  % restore previously set value
  } ifelse
} bind def
currentdict readonly pop end
%%EndResource

%%EndProlog
%%BeginSetup
helper_ops begin
forms_procs begin
userdict begin

L1? not {
   % set MaxFormItem to be equivalent to MaxFormCache
   1 dict begin
        /MaxFormItem currentsystemparams /MaxFormCache get def
   currentdict end
   setuserparams
}if

% download form
%%BeginResource: form TestForm 
L1? not { % for > L1 case, define a form resource
  /TestForm
  10 dict begin
     /FormType 1 def
     /EPSArray ARRAY_SIZE array def
     /AcquisitionProc {
        EPSArray dup 0 get dup 0 get % array counter_array counter
        dup 3 1 roll                 % array counter counter_array counter
        1 add 0 exch put             % increment counter
        get                          % use old counter as index into array, placing
                                     % next string on operand stack.
     } bind def
     /PaintProc {
       begin
         StartDoc
           EPSArray 0 get 0 1 put
           /AcquisitionProc load 0 () /SubFileDecode filter
           cvx exec
       end % form dict
     } bind def
     /BBox [ 29 222 583 759] def % UPDATE FOR INCLUDED DOCUMENT
     /Matrix [1 0 0 1 0 0] def
  currentdict end def % TestForm
  /inputFile currentfile 0 (% EOD_Marker_5882)
  /SubFileDecode filter def
  TestForm /EPSArray get 
} if

readdata
%%BeginDocument: landscape_form % UPDATE TO NAME OF INCLUDED DOCUMENT

%%EndDocument
EndDoc % put this call after included EPS file. Followed by 
% EOD_Marker_5882 % The % EOD_Marker_#### comment, which is needed so that 
                  % SubFileDecode filter will reach end of data.
%%EndResource
%%EndSetup

%%Page: 1 1
%%BeginPageSetup
/pgsave save def
%%EndPageSetup
(Joe Smith)                                  % parameters of example form
(1281 Market Street, San Jose, CA 95053)     % parameters of example form
(408-225-1818)                               % parameters of example form
(Trim two pine trees in NE corner of lot.)   % parameters of example form
emitpage                                     % calling example form
%%PageTrailer
pgsave restore

%%Trailer
end % userdict
end % forms_procs
end % helper_procs
%%EOF
@

<<EPSbbox>>=
%%
% $Id: ORTHOLOGOUS_dataset.nw,v 1.2 2001-08-17 17:35:27 jabril Exp $
%
% Place this after the "%% EndComments" tag for small snapshots of the figure.
%
% 2 dict dup /PageSize [ 595 842 ] put dup /ImagingBBox null put setpagedevice
% 0.2 0.2 scale
%                    [ 595 842 ] for a4     (0.2 0.2 scale)
%                    [ 612 792 ] for letter (0.1925 0.1925 scale)
%                    [ 297 420 ] for a6     (0.1 0.1 scale)
%
%%
% S 2116 340 2910 400 bbox bgcolor scmyk fill R % 40"x57" - old margins
S 2116 300 2910 370 bbox bgcolor scmyk fill R % 40"x57"
%% S 108 108 T 0 0 2808 4032 bbox fgcolor scmyk 1 slw K R % 40"x57"
%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%% CROP MARKS
%%
/cutmrg 1 in def
/cuturx 3024 def % 40"x57"
/cutury 4248 def % 40"x57"
/cutmrk { S fgcolor scmyk 1 slw T F S 0 -1 m 0 cutmrg neg l K newpath 1 0 m cutmrg 0 l K R R } bdf 
S
-1  1   cutmrg              cutmrg              cutmrk
 1 -1   cuturx cutmrg sub   cutury cutmrg sub   cutmrk
-1 -1   cutmrg              cutury cutmrg sub   cutmrk
 1  1   cuturx cutmrg sub   cutmrg              cutmrk
R
%%
%%% CROP MARKS
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%% EPS Functions
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%
/EPSDict 10 dict def
EPSDict begin
  /N { def } def
  /B { bind def } N
  /S { exch } N
  /X { S N } B
  /A { dup } B
  /TR { translate } N
  /KDict 50 dict N 
  KDict begin
    /@SpecialDefaults{
      /hs 612 N
      /vs 792 N
      /ho 0 N
      /vo 0 N
      /hsc 1 N
      /vsc 1 N
      /ang 0 N
      /CLIP 0 N
      /rwiSeen false N
      /rhiSeen false N
      /letter {} N
      /note {} N
      /a4 {} N
      /a3 {} N
      /legal {} N
      }B
    /@scaleunit 100 N
    /@hscale { @scaleunit div /hsc X } B
    /@vscale { @scaleunit div /vsc X } B
    /@hsize { /hs X /CLIP 1 N } B
    /@vsize { /vs X /CLIP 1 N } B
    /@clip { /CLIP 2 N } B
    /@hoffset { /ho X } B
    /@voffset { /vo X } B
    /@angle { /ang X } B
    /@rwi { 10 div /rwi X /rwiSeen true N } B
    /@rhi { 10 div /rhi X /rhiSeen true N } B
    /@llx { /llx X } B
    /@lly { /lly X } B
    /@urx { /urx X } B
    /@ury { /ury X } B
    /magscale true def
    end % KDict
  /@beginspecial{
    KDict begin % begin_KDict_@beginspecial
      /EPSsave save N
      gsave
        @SpecialDefaults count /ocount X
        /dcount countdictstack N
    }N
  /@setspecial{
    CLIP 1 eq {
      newpath 0 0 moveto hs 0 rlineto 0 vs rlineto hs neg 0 rlineto closepath clip
      }if
    ho vo TR hsc vsc scale ang rotate
    rwiSeen {
      rwi urx llx sub div
      rhiSeen { rhi ury lly sub div }{ dup } ifelse
      scale llx neg lly neg TR
     }{
      rhiSeen { rhi ury lly sub div dup scale llx neg lly neg TR }if
      }ifelse
    CLIP 2 eq{
      newpath llx lly moveto urx lly lineto urx ury lineto llx ury lineto closepath clip
      }if
    /showpage {} N
    /erasepage {} N
    /copypage {} N
    newpath
    } N
  /@endspecial {
    count ocount sub { pop } repeat
    countdictstack dcount sub { end } repeat grestore
    EPSsave restore
    end % begin_KDict_@beginspecial
    } N
end
%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%% LEGEND MAIN TITLE
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%
EPSDict begin
 @beginspecial
 80 @hoffset 4400 @voffset  % 40"x57"
 270 @angle                          % OK
 235 @llx 35 @lly 375 @urx 2820 @ury % OK
 % 2030 @rwi
 @clip
 @setspecial
%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%BeginDocument: Legend_Title.ps
%%
%%% Insert PS file HERE for MAIN TITLE
%%
%%EndDocument: Legend_Title.ps
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%
 @endspecial % EPSDict
%%
%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%% TEXT LEGEND
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%
EPSDict begin
 @beginspecial
 % 120 @hoffset 255 @voffset % 39"x56"
 228 @hoffset 300 @voffset   % 40"x57"
 270 @angle                          % OK
 212 @llx 30 @lly 400 @urx 1407 @ury % OK
 2030 @rwi
 @clip
 @setspecial
%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%BeginDocument: Legend_Text.ps
%%
%%% Insert PS file HERE for LEGEND TEXT
%%
%%EndDocument: Legend_Text.ps
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%
 @endspecial % EPSDict
%%
%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%% KEY FIGURE LEGEND
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%
EPSDict begin
 @beginspecial
 % 1690 @hoffset 255 @voffset % 39"x56"
 1798 @hoffset 300 @voffset   % 40"x57"
 270 @angle                         % OK
 212 @llx 30 @lly 400 @urx 944 @ury % OK
 2030 @rwi
 @clip
 @setspecial
%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%BeginDocument: Legend_Key.ps
%%
%%% Insert PS file HERE for LEGEND KEY
%%
%%EndDocument: Legend_Key.ps
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%
 @endspecial % EPSDict
%%
%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%% EPS
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%

@ 

\newpage

\sctn{Common code blocks}

\subsctn{PERL scripts}

<<PERL shebang>>=
#!/usr/bin/perl -w
# This is perl, version 5.005_03 built for i386-linux
<<Version Control Id Tag>>
#
use strict;
@

<<Global Constants - Boolean>>=
my ($T,$F) = (1,0); # for 'T'rue and 'F'alse
@

We also set here the date when the script is running and who is the user running it.

<<Global Vars - User and Date>>=
my $DATE = localtime;
my $USER = defined($ENV{USER}) ? $ENV{USER} : '??????';
@


\subsubsctn{Timing our scripts}

The '[[Benchmark]]' module encapsulates a number of routines to help to figure out how long it takes to execute a piece of code and the whole script.

<<Use Modules - Benchmark>>=
use Benchmark;
  <<Timer ON>>
@ 

See '[[man Benchmark]]' for further info about this package. 
We set an array to keep record of timing for each section.

<<Timer ON>>=
my @Timer = (new Benchmark);
@ 

<<Common PERL subs - Benchmark>>=
sub timing() {
    push @Timer, (new Benchmark);
    # partial time 
    $_[0] || 
        (return timestr(timediff($Timer[$#Timer],$Timer[($#Timer - 1)])));
    # total time
    return timestr(timediff($Timer[$#Timer],$Timer[0]));
} # timing
@ 


\subsubsctn{Printing complex Data Structures}

With '[[Data::Dumper]]' we are able to pretty print complex data structures for debugging them.


<<Use Modules - Dumper>>=
use Data::Dumper;
local $Data::Dumper::Purity = 0;
local $Data::Dumper::Deepcopy = 1;
@ 

An example on how to use: [[print STDERR Dumper(\%var_ref)]] 

\subsubsctn{Common functions}

<<Skip comments and empty records>>=
next if /^\#/o;
next if /^\s*$/o;
chomp;
@

<<Common PERL subs - Min Max>>=
#
sub max() {
    my $z = shift @_;
    foreach my $l (@_) { $z = $l if $l > $z };
    return $z;
} # max
sub min() {
    my $z = shift @_;
    foreach my $l (@_) { $z = $l if $l < $z };
    return $z;
} # min
@

<<Common PERL subs - Text fill>>=
#
sub fill_right() { $_[0].($_[2] x ($_[1] - length($_[0]))) }
sub fill_left()  { ($_[2] x ($_[1] - length($_[0]))).$_[0] }
sub fill_mid()   { 
    my $l = length($_[0]);
    my $k = int(($_[1] - $l)/2);
    ($_[2] x $k).$_[0].($_[2] x ($_[1] - ($l+$k)));
} # fill_mid
@

These functions are used to report to STDERR a single char for each record processed (useful for reporting parsed records).

<<Common PERL subs - Counter>>=
#
sub counter { # $_[0]~current_pos++ $_[1]~char
    print STDERR "$_[1]";
    (($_[0] % 50) == 0) && (print STDERR "[".&fill_left($_[0],6,"0")."]\n");
} # counter
#
sub counter_end { # $_[0]~current_pos   $_[1]~char
    (($_[0] % 50) != 0) && (print STDERR "[".&fill_left($_[0],6,"0")."]\n");
} # counter_end
@

<<Global Vars - Counter>>=
my ($n,$c); # counter and char (for &counter function)
@


\subsubsctn{Common functions for reporting program processes}
\label{sec:messagerpt}

Function '[[report]]' requires that a hash variable '[[%MessageList]]' has been set, such hash contains the strings for each report message we will need. The first parameter for '[[report]]' is a key for that hash, in order to retrieve the message string, the other parameters passed are processed by the [[sprintf]] function on that string.

<<Common PERL subs - STDERR>>=
sub report() { print STDERR sprintf($MessageList{ shift @_ },@_) }
@

The same happens to '[[warn]]' function which also requires a hash variable '[[%ErrorList]]' containing the error messages.

<<Common PERL subs - STDERR>>=
sub warn() { print STDERR sprintf($ErrorList{ shift @_ }, @_) }
@

\subsctn{{\biop} modules}

\def\bioseq{\htmladdnormallinkfoot{[[Bio::Seq]]}{http://bioperl.org/Core/POD/Bio/Seq.html}}
\def\bioseqIO{\htmladdnormallinkfoot{[[Bio::SeqIO]]}{http://bioperl.org/Core/POD/Bio/SeqIO.html}}

{\bioseq} is the {\biop} main sequence object while {\bioseqIO} is the {\bp} support for sequence input/output into files.

<<Use Modules - Bio::Seq>>=
use Bio::Seq;
use Bio::SeqIO;
@
 

\subsctn{AWK scripts}

<<GAWK shebang>>=
#!/usr/bin/gawk -f
# GNU Awk 3.0.4
<<Version Control Id Tag>>
@

\subsctn{BASH scripts}

<<BASH shebang>>=
#!/usr/bin/bash
# GNU bash, version 2.03.6(1)-release (i386-redhat-linux-gnu)
<<Version Control Id Tag>>
#
SECONDS=0 # Reset Timing
# Which script are we running...
L="####################"
{ echo "$L$L$L$L";
  echo "### RUNNING [$0]";
  echo "### Current date:`date`";
  echo "###"; } 1>&2;
@

<<BASH script end>>=
{ echo "###"; echo "### Execution time for [$0] : $SECONDS secs";
  echo "$L$L$L$L";
  echo ""; } 1>&2;
#
exit 0
@

\subsctn{Version control tags}

This document is under Revision Control System (RCS). The version you are currently reading is the following:

<<Version Control Id Tag>>=
# $Id: ORTHOLOGOUS_dataset.nw,v 1.2 2001-08-17 17:35:27 jabril Exp $
@ 

\newpage

\sctn{Extracting code blocks from this document}

From this file we can obtain both the code and the
documentation. The following instructions are needed:

\subsctn{Extracts Script code chunks from the [[noweb]] file} % \\[-0.5ex]

Remember when tangling that '-L' option allows you to include program line-numbering relative to original [[noweb]] file. Then the first line of the executable files is a comment, not a shebang, and must be removed to make scripts runnable.

<<tangling>>=
# PBS
notangle -R"PBS tblastx shell" $WORK/$nwfile.nw \
    > /home/ug/jabril/no_backup/PBS/PBS.sh ;
chmod a+x /home/ug/jabril/no_backup/PBS/PBS.sh ;
# showing line numbering comments in program (DEVEL VERSIONS)
notangle -L -R"Renaming fasta sequence IDs" $WORK/$nwfile.nw | \
    perl -ne '$.>1 && print' > $BIN/fasta_renamer.pl ;
notangle -L -R"Raw coords to GFF" $WORK/$nwfile.nw | \
    perl -ne '$.>1 && print' > $BIN/coords2gff.pl ;
notangle -L -R"Masked from fasta sequences" $WORK/$nwfile.nw | \
    perl -ne '$.>1 && print' > $BIN/getfastamasked.pl ;
notangle -L -R"Breaking fasta sequences" $WORK/$nwfile.nw | \
    perl -ne '$.>1 && print' > $BIN/splitfastaseq.pl ;
notangle -L -R"GFF to GTF" $WORK/$nwfile.nw | \
    perl -ne '$.>1 && print' > $BIN/gff2gtf.pl ;
# making them runnable
chmod a+x $BIN/fasta_renamer.pl ;
chmod a+x $BIN/coords2gff.pl ;
chmod a+x $BIN/getfastamasked.pl ;
chmod a+x $BIN/splitfastaseq.pl ;
chmod a+x $BIN/gff2gtf.pl ;
#
@ 

\subsctn{Extracting different Config Files} % \\[-0.5ex]

<<tangling>>=
#
ChckDirs $PARAM/gff2ps $PARAM/gff2aplot ;
#
notangle -R"GFF2APLOT customization: ortho masked" $WORK/$nwfile.nw \
         > $PARAM/gff2aplot/ortho_masked_a4.rc ;
#
notangle -R"GFF2PS customization: ortho orimasked a4" $WORK/$nwfile.nw \
         > $PARAM/gff2ps/ortho_orimasked_a4.rc ;
notangle -R"GFF2PS customization: ortho orimasked a3" $WORK/$nwfile.nw \
         > $PARAM/gff2ps/ortho_orimasked_a3.rc ;
notangle -R"GFF2PS customization: ortho orimasked wide" $WORK/$nwfile.nw \
         > $PARAM/gff2ps/ortho_orimasked_wide.rc ;
#
@ %$

\subsctn{Extracting documentation and \LaTeX{}'ing it} % \\[-0.5ex] %'

<<tangling>>=
#
notangle -Rweaving  $WORK/$nwfile.nw > $WORK/nw2tex ;
notangle -RLaTeXing $WORK/$nwfile.nw > $WORK/ltx ;
chmod a+x $WORK/nw2tex $WORK/ltx;
#
@ 

<<weaving>>=
<<BASH shebang>>
# weaving and LaTeXing
<<BASH Environment Variables>>
noweave -t4 -delay -index $WORK/$nwfile.nw > $DOCS/$nwfile.tex 
pushd $DOCS/ ;
latex $nwfile.tex ;
dvips $nwfile.dvi -o $nwfile.ps -t a4 ;
popd;
<<BASH script end>>
@ 

<<LaTeXing>>=
<<BASH shebang>>
# only LaTeXing
<<BASH Environment Variables>>
pushd $DOCS/ ;
latex $nwfile.tex ; 
latex $nwfile.tex ; 
latex $nwfile.tex ;
dvips $nwfile.dvi -o $nwfile.ps -t a4 ;
popd ;
<<BASH script end>>
@ %$

\subsctn{Defining working shell variables for the current project} % \\[-0.5ex]

<<BASH Environment Variables>>=
#
# ORTHOLOGOUS Dataset Variables
#
DATASETS="/projects/datasets/orthologous";
WORK="$DATASETS/_docs" ;
BIN="$WORK/bin" ;
PARAM="$BIN/param" ;
DOCS="$WORK/docs" ;
DATA="$WORK/data" ;
nwfile="ORTHOLOGOUS_dataset" ;
export DATASETS WORK BIN PARAM DOCS DATA nwfile ;
#
SGPBIN="/projects/sgp/bin" ;
export SGPBIN ;
#
# ORTHOLOGOUS Dataset Variables
#
ANALYSIS="/projects/sgp/orthologous" ;
ID="$DATASETS/id" ;
HSAP="$DATASETS/id.Hsap" ;
MMUS="$DATASETS/id.Mmus" ;
export ANALYSIS ID HSAP MMUS ;
#
# BASIC Shell Functions
#
ChckDirs ()
{
  #
  # USAGE: ChckDirs <path_list>
  #
  for name in "$@" ;
    do {
         [ -d "$name" ] && 
           echo "### Directory Already Exist: $name" ||
             mkdir --verbose $name ;
      } ;
    done ;
}
#
MergeFiles ()
{
  #
  # USAGE: MergeFiles <working_path>
  #
  echo "### REMOVING OLD FILES..." ;
  [ -e $1/all.Hsap ] && 
    /bin/rm --force --verbose $1/all.Hsap ;
  [ -e $1/all.Mmus ] &&
    /bin/rm --force --verbose $1/all.Mmus ;
  echo "### WORKING on HUMAN LOCI..." ;
  cat $HSAP | while read locus ;
    do { cat $1/$locus >> $1/all.Hsap ; } ; done ;
  echo "### WORKING on MOUSE LOCI..." ;
  cat $MMUS | while read locus ;
    do { cat $1/$locus >> $1/all.Mmus ; } ; done ;
  echo "### MERGING HUMAN and MOUSE..." ;
  cat $1/all.Hsap $1/all.Mmus > $1/all ;
}
#
MergeGFF () 
{
  #
  # USAGE: MergeGFF <working_path> <species_id> <flag>
  #
  flag=0 ;
  [ "$3" = "1" ] && flag=1 ; 
  echo "### REMOVING OLD FILES..." ;
  [ -e $1/all.$2 ] && 
    /bin/rm --force --verbose $1/all.$2 ;
  echo "### WORKING on $2 LOCI..." ;
  c=0 ;
  while read locus ;
    do {
         let c=c+1 ;
         [ $c -gt 1 ] && echo '#$ ' >> $1/all.$2 ;
         [ $flag -eq 1 ] &&
             cat $DATASETS/annotation/length/$locus >> $1/all.$2 ;
         gawk 'BEGIN{OFS="\t"}
             ($1 !~ /^#/ && $3 != "Gene") {
                 print $0;
             }' $1/$locus | sort +3n -5 - >> $1/all.$2 ; 
       } ;
    done < $DATASETS/id.$2 ;
}
#
MergeALLGFF () 
{
  #
  # USAGE: MergeGFF <working_path>
  #
  echo "### WORKING on HUMAN LOCI..." ;
  MergeGFF $1 Hsap 1 ;
  echo "### WORKING on MOUSE LOCI..." ;
  MergeGFF $1 Mmus 1 ;
  echo "### MERGING HUMAN and MOUSE..." ;
  echo '#$ ' | cat $1/all.Hsap - $1/all.Mmus > $1/all ;
}
@ 

<<tangling>>=
# TO DO: add a test to check which shell is running
# BASH shell
notangle -R'BASH Environment Variables' $WORK/$nwfile.nw \
         > $WORK/.bash_VARS ; 
# sourcing
source $WORK/.bash_VARS ;
@

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{comment}

\sctn{Obtaining signals from raw sequences}

% ~rguigo/research/humus/HUMUS-1/Conservation/

\subsctn{Running {\gnid} to get scores for sites}

We calculate scores for all sites with {\gnid}, and split the output for each site: acceptors, donors, starts and stops. We are going to use only the first two at this moment, but it is worthy having the other for future analysis.

<<BASH commands>>=
#
ChckDirs $SITES $SITES/geneid $SITES/geneid/logs ;
#
cat $HSAP $MMUS | while read locus ;
  do
    {
      echo "### WORKING on LOCUS: $locus" ;
      geneid -v -P $BASE/param/geneid/human3iso.param \
             -bedaGo $DATASETS/fasta/$locus \
              > $SITES/geneid/$locus \
             2> $SITES/geneid/logs/$locus.logs ;
    } ;
  done ;
#
# gawk '$0 !~ /^#/ {print $0 > FILENAME"."tolower($3)}' HSMIMAR.gnid.sites ;
@ 
%$

\subsctn{Extracting real splice sites}

We extract splice-site sequences, but we first need to read exonic coords and the fasta sequences.

<<BASH commands>>=
#
ChckDirs $SITES/real $SITES/real/logs ;
#
# Take care because 'all' files must contain 'sequence' record for evaluation
#   program. We move those files to temporary ones to run this command.
MergeFiles $DATASETS/gff ;
# After that we have moved the new 'all' files to 'all_gff' and
#   restored temporary 'all' files. 
#
MergeFiles $SITES/geneid/ GFF ;
#
$BIN/ExtractIntronSites.pl $ID $DATASETS/gff/all_gff \
                           $SITES/geneid/all $SITES/real \
                           2> $SITES/real/logs/ExtractIntronSites_20010711.log ;
#
MergeFiles $SITES/real/ GFF ;
#
@ 
%$

\subsctn{Visualizing structures of homologous genes}

We run {\gps} to generate the figures for each human/mouse homologous genes pair. We include cds annotation and real sites, all the plots are made on forward strand. The following commands process the GFF files and save the output to the [[$SITES/plots/tmp/]] dir. %$

<<BASH commands>>=
#
gawk 'BEGIN{ PT=ARGV[1]; ARGV[1]=""; }
   $3 == "Sequence" { 
      $7="+"; print $0 > PT"/gff_length/"$1; 
      $7="."; print $0 > PT"/gff_length/"$1; 
      $7="-"; print $0 > PT"/gff_length/"$1;
   }' $DATASETS $DATASETS/gff/all ;
#
MergeFiles $DATASETS/gff_length ;
#
ChckDirs $SITES/plots $SITES/plots/_tmp $SITES/plots/logs ;
#
cat $HSAP $MMUS | while read locus;
  do
    {
      echo "### WORKING on LOCUS: $locus" ;
      gawk '$7 == "+" { print $0 }' $DATASETS/gff_length/$locus | \
           cat - $DATASETS/gff/$locus > $SITES/plots/tmp/$locus.cds ;
      gawk '{ $2="SITES"; print $0 }' $SITES/real/$locus \
           > $SITES/plots/tmp/$locus.sites ;
    } ;
  done ;
#
@

\subsubsctn{Making the sites figures}

<<BASH commands>>=
#
while read locus human mouse ;
  do
    {
      echo "### WORKING on LOCUS: $locus" ;
      gff2ps -arVC $BIN/param/sites_hsap_mmus.gff2psrc \
          -T "$locus : H.sap $human vs M.mus $mouse" -- \
          $SITES/plots/tmp/$human.cds  $SITES/plots/tmp/$human.sites \
          $SITES/plots/tmp/$mouse.cds  $SITES/plots/tmp/$mouse.sites \
           > $SITES/plots/${human}_${mouse}.ps \
          2> $SITES/plots/logs/${human}_${mouse}.log ;
    } ;
  done < $ID ;
#
@

Once obtained the plots, we make a {\LaTeX} wrapper to visualize and/or print them, each three on a single page.

<<BASH commands>>=
#
$BIN/SitesFigureMerger.pl $ID $SITES/plots \
                          > $SITES/plots/all.tex \
                         2> $SITES/plots/all.log ;
#
pushd $DOCS/psfigures/ ;
latex all_main.tex ;
popd ;
dvips $DOCS/psfigures/all_main.dvi -o $DOCS/psfigures/all_main.ps ;
@

%
%
%
<<LaTeX wrapper main doc>>=
\documentclass[a4,11pt]{article}
%
% all_main.tex
%
% $Id: ORTHOLOGOUS_dataset.nw,v 1.2 2001-08-17 17:35:27 jabril Exp $
%
% pushd $DOCS/psfigures/; latex all_main.tex; popd;
% dvips $DOCS/psfigures/all_main.dvi -o $DOCS/psfigures/all_main.ps
%
\usepackage[a4paper,offset={0pt,0pt},hmargin={0.5cm,0.5cm},vmargin={0.5cm,0.5cm}]{geometry}
\usepackage{graphics}
\usepackage[dvips]{graphicx}
%\usepackage{lscape}
%\usepackage{rotating}
%
\begin{document}
\pagestyle{plain}
%\landscape

 \input /projects/splicing/scimit/sites/plots/all.tex

\end{document}
@ 
%
%
%

\subsubsctn{Setting {\gps} parameters}

This is the {\gps} customization file we used to obtain the {\ps} plots for sites comparison between human and mouse sequences:

<<gff2ps customization for sites>>=
#
# sites_hsap_mmus.gff2psrc
#
<<Version Control Id Tag>>
#
# L #
<<Layout settings for sites>>
#
# S #
<<Source settings for sites>>
#
# G #
<<Group settings for sites>>
#
# F #
<<Feature settings for sites>>
#
@ 

<<Layout settings for sites>>=
page_bbox=short,200,800
header_scale=0.5
margin_left=0.5cm
margin_right=0.5cm
margin_top=0.5cm
margin_bottom=0.5cm
show_outer_scale=top
show_grid=off
# group_label_scale=2.5
@
 
<<Source settings for sites>>=
*::unfold_grouped_ungrouped=off
*::unfold_grouped_line=off
*::unfold_ungrouped_line=off
*::source_line=none
SCIMIT::vert_align=bottom
SCIMIT::left_label=++sequence++
SCIMIT::track_spacing_scale=0
SITES::vert_align=top
SITES::left_label=++none++
SITES::keep_feature_label_space=off
SITES::track_spacing_scale=0.1
SITES::source_style=boxed
# SITES::range=-9..9
SITES::range=1..6
SITES::track_scale=2
@ 

<<Group settings for sites>>=
*::label=++none++
*::group_line=none
@ 

<<Feature settings for sites>>=
sequence::feature_color=violet
sequence::shape=base_line
acceptor::feature_color=red
acceptor::feature_stroke_color=red
acceptor::shape=half_right_triangle
donor::feature_color=blue
donor::feature_stroke_color=blue
donor::shape=half_left_triangle
first::shape=half_arrow_end
terminal::shape=half_arrow_head
single::shape=half_arrow
@ 

\subsctn{Reporting errors in annotation}

I have found some mistakes in the annotation of three mouse sequences when running [[ExtractIntronSites.pl]].

<<BASH commands>>=
cds_sites ()
{
  # usage:    cds_sites <seqname>
  cat $DATASETS/gff/$1 ;
  echo ":::::::::::::::" ;
  cat $SITES/geneid/$1 ;
  echo ":::::::::::::::" ;
  cat $SITES/real/$1 ;
}
@ 

\begin{verbatim}
:::::::::::::: MMINSIIG

MMINSIIG SCIMIT First    1133 1318 1.000 + 0 MIT72
MMINSIIG SCIMIT Terminal 1807 1953 1.000 + 0 MIT72

MMINSIIG geneid_v1.0 Donor    1319 1320 5.16 + . # AAGGTGAGT
MMINSIIG geneid_v1.0 Acceptor 1807 1808 0.53 + . # GCTCTGACACAACCTCCCTGGCAGTGG

:::::::::::::: MMLYL1

MMLYL1 SCIMIT First    1615 1947 1.000 + 0 MIT86
MMLYL1 SCIMIT Internal 2039 2128 1.000 + 0 MIT86
MMLYL1 SCIMIT Terminal 2844 3257 1.000 + 0 MIT86

MMLYL1 geneid_v1.0 Donor    1946 1947 3.11 + . # CAGGTCAGT
MMLYL1 geneid_v1.0 Acceptor 2037 2038 1.33 + . # TTCATGACCCACAACCCCTTACAGTGT
MMLYL1 geneid_v1.0 Donor    2129 2130 3.67 + . # ACGGTGAGT
MMLYL1 geneid_v1.0 Acceptor 2844 2845 2.86 + . # TGATGCTATCCCTTGGGTCCTCAGGGC

:::::::::::::: MUSHSP25A

MUSHSP25A SCIMIT First     756 1130 1.000 + 0 MIT62
MUSHSP25A SCIMIT Internal 1727 1792 1.000 + 0 MIT62
MUSHSP25A SCIMIT Terminal 1920 2108 1.000 + 0 MIT62

MUSHSP25A geneid_v1.0 Donor    1131 1132 4.05 + . # CTGGTGAGT
MUSHSP25A geneid_v1.0 Acceptor 1727 1728 4.83 + . # CTGACCTTCTGTCCCCACCCACAGGCA
MUSHSP25A geneid_v1.0 Donor    1791 1792 3.43 + . # CACGTGAGT
MUSHSP25A geneid_v1.0 Acceptor 1918 1919 3.22 + . # TGCCCTGATTTTCTGTGTGTCCAGGCT
\end{verbatim}

\sctn{Sequence comparison with {\bn} on non-coding regions}

We run {\bn} on the human/mouse orthologous sequences, we masked coding regions before that because we are interested to know if there are any conservation in non-coding regions. Such conservation at sequence level will mean that there are regulatory regions that will work in a similar way between human and mouse. In our case, we are interested in those regulatory elements that affect splicing placed in the intronic regions.

\subsctn{Masking coding regions}

We use [[MaskCDS.pl]] script defined in section~\ref{sec:maskcds}, page~\pageref{sec:maskcds}, to mask {\data} fasta sequences with the GFF coords of their coding regions.

<<BASH commands>>=
#
ChckDirs $DATASETS/fasta/fastamaskedcds $DATASETS/fasta/fastamaskedcds/logs ;
#
cat $HSAP $MMUS | while read locus ;
  do
    {
      echo "### WORKING on LOCUS: $locus" ;
      $BIN/MaskCDS.pl $DATASETS/fasta/fasta/$locus \
                      $DATASETS/gff/$locus \
                      > $DATASETS/fasta/fastamaskedcds/$locus \
                     2> $DATASETS/fasta/fastamaskedcds/logs/$locus ;
    } ;
  done ;
#
MergeFiles $DATASETS/fasta/fastamasked_cds/ ;
#
# To check if there was any problem while masking sequences.
#
grep '!!!' $DATASETS/fasta/fastamaskedcds/logs/* ;
#
@ 

\subsctn{Running {\bn} on masked sequences}

Once we have the sequences with their coding regions masked, we compare human and mouse orthologous sequence pairs, using human sequences as queries and mouse ones as database. Here we prepare the {\bl} databases (including human sequences, if we will use them later on other analyses).

<<BASH commands>>=
#
ChckDirs $DATASETS/blastdb/wumaskedcds ;
#
cat $HSAP $MMUS | while read locus ;
  do
    {
      echo "### WORKING on LOCUS: $locus" ;
      pressdb $DATASETS/fasta/fastamaskedcds/$locus \
           -o $DATASETS/blastdb/wumaskedcds/$locus ;
    } ;
  done ;
#
@ 

Now we are ready to run {\bn} with defaults (just database and query fasta sequence). We do not pass '-nogap' option because we are interested in finding any match although it will have few gaps but still representing a conserved region.

<<BASH commands>>=
#
ChckDirs $SCIMIT/blast $SCIMIT/blast/blastn \
         $SCIMIT/blast/blastn/wumaskedcds \
         $SCIMIT/blast/blastn/wumaskedcds/blast \
         $SCIMIT/blast/blastn/wumaskedcds/logs ;
#
while read locus human mouse;
  do
    {
      echo "### RUNNING BLASTN on LOCUS: $locus ($human seq against $mouse DB)" ;
      blastn $DATASETS/blastdb/wumaskedcds/$mouse \
             $DATASETS/fasta/fastamaskedcds/$human \
           > $SCIMIT/blast/blastn/wumaskedcds/blast/$human \
          2> $SCIMIT/blast/blastn/wumaskedcds/logs/$human ;            
    } ;
  done < $ID ;
#
@

\subsctn{Filtering HSPs and SRs}

We are parsing {\bn} output to extract the high-scoring segment pairs (HSPs). We set score field to bit-score and we also include the sequence of each HSP at the end of the GFF record (as comments).

<<BASH commands>>=
#
ChckDirs $SCIMIT/blast/blastn/wumaskedcds/hsp \
         $SCIMIT/blast/blastn/wumaskedcds/sr \
         $SCIMIT/blast/blastn/wumaskedcds/aplot ;
#
cat $HSAP | while read locus;
  do
    {
      echo "### RUNNING parseblast on: $locus" ;
      echo "### RUNNING parseblast on: $locus" 1>&2 ;
      parseblast -vbFQs $SCIMIT/blast/blastn/wumaskedcds/blast/$locus \
                     > $SCIMIT/blast/blastn/wumaskedcds/hsp/$locus ;
      parseblast -vbAQs $SCIMIT/blast/blastn/wumaskedcds/blast/$locus \
                     > $SCIMIT/blast/blastn/wumaskedcds/aplot/$locus ;
    } ;
  done 2> $SCIMIT/blast/blastn/wumaskedcds/logs/parseblast ;
#
@

Once we have obtained HSPs we can project them into similarity regions (SRs)...

\subsctn{Visualizing {\bn} alignments of homologous genes}

\subsubsctn{Making the alignment plots}

\subsubsubsctn{Running {\aps}:}

<<BASH commands>>=
#
ChckDirs $SCIMIT/blast/blastn/wumaskedcds/plots \
         $SCIMIT/blast/blastn/wumaskedcds/plots/gff2ps \
         $SCIMIT/blast/blastn/wumaskedcds/plots/gff2ps/logs \
         $SCIMIT/blast/blastn/wumaskedcds/plots/aplot \
         $SCIMIT/blast/blastn/wumaskedcds/plots/aplot/logs \
         $SCIMIT/blast/blastn/wumaskedcds/plots/_tmp ;
#
while read locus human mouse;
  do
    {
      echo "### RUNNING gff2aplot on: $locus" ;
      gff2aplot -VaP -T "$locus: $human x $mouse" -- \
           $SITES/plots/tmp/$human.cds \
           $SITES/plots/tmp/$mouse.cds \
           $SCIMIT/blast/blastn/wumaskedcds/aplot/$human \
         > $SCIMIT/blast/blastn/wumaskedcds/plots/aplot/${human}_${mouse}.ps \
        2> $SCIMIT/blast/blastn/wumaskedcds/plots/aplot/logs/${human}_${mouse} ;
    } ;
  done < $ID ;
#
@ 

\subsubsubsctn{Running {\gps}:}

<<BASH commands>>=
#
while read locus human mouse ;
  do
    {
      echo "### WORKING on LOCUS: $locus" ;
      perl -e 'open(HSP,"<".(shift @ARGV));
                open(HSAP,">".(shift @ARGV));
                open(MMUS,">".(shift @ARGV));
                while (<HSP>) {
                    next if /^\#/o;
                    next if /^\s*$/o;
                    chomp;
                    @F = split /[\s]+/og;
                    $F[6] = $F[14] = "+";
                    $F[8] = ".";
                    $F[9] =~ s/\"//og;
                    print HSAP join("\t",(@F[0..8]))."\n";
                    print MMUS join("\t",(@F[9,1,2,10,11,5,14,17,8]))."\n";
                };
                close(MMUS);
                close(HSAP);
                close(HSP);
          ' $SCIMIT/blast/blastn/wumaskedcds/hsp/$human \
            $SCIMIT/blast/blastn/wumaskedcds/plots/_tmp/$human.blastn \
            $SCIMIT/blast/blastn/wumaskedcds/plots/_tmp/$mouse.blastn ;
    } ;
  done < $ID ;
#
while read locus human mouse ;
  do
    {
      echo "### WORKING on LOCUS: $locus" ;
      gff2ps -arVC $BIN/param/blastn_hsap_mmus.gff2psrc \
             -T "$locus : H.sap $human vs M.mus $mouse" -- \
             $SITES/plots/tmp/$human.cds \
             $SCIMIT/blast/blastn/wumaskedcds/plots/_tmp/$human.blastn \
             $SITES/plots/tmp/$human.sites \
             $SITES/plots/tmp/$mouse.cds \
             $SCIMIT/blast/blastn/wumaskedcds/plots/_tmp/$mouse.blastn \
             $SITES/plots/tmp/$mouse.sites \
             > $SCIMIT/blast/blastn/wumaskedcds/plots/gff2ps/${human}_${mouse}.ps \
            2> $SCIMIT/blast/blastn/wumaskedcds/plots/gff2ps/logs/${human}_${mouse}.log ;
    } ;
  done < $ID ;
#
@

Once obtained the plots, we make a {\LaTeX} wrapper to visualize and/or print them, each three on a single page.

<<BASH commands>>=
#
$BIN/SitesFigureMerger.pl $ID $SCIMIT/blast/blastn/wumaskedcds/plots/gff2ps \
               > $SCIMIT/blast/blastn/wumaskedcds/plots/gff2ps/all_blast.tex \
              2> $SCIMIT/blast/blastn/wumaskedcds/plots/gff2ps/all_blast.log ;
#
pushd $DOCS/psfigures/ ;
latex all_blast_main.tex ;
popd ;
dvips $DOCS/psfigures/all_blast_main.dvi -o $DOCS/psfigures/all_blast_main.ps ;
@

%
%
%
<<LaTeX wrapper main doc for blast>>=
\documentclass[a4,11pt]{article}
%
% all_blast_main.tex
%
% $Id: ORTHOLOGOUS_dataset.nw,v 1.2 2001-08-17 17:35:27 jabril Exp $
%
% pushd $DOCS/psfigures/; latex all_blast_main.tex; popd;
% dvips $DOCS/psfigures/all_blast_main.dvi -o $DOCS/psfigures/all_blast_main.ps
%
\usepackage[a4paper,offset={0pt,0pt},hmargin={0.5cm,0.5cm},vmargin={0.5cm,0.5cm}]{geometry}
\usepackage{graphics}
\usepackage[dvips]{graphicx}
%\usepackage{lscape}
%\usepackage{rotating}
%
\begin{document}
\pagestyle{plain}
%\landscape

 \input /projects/splicing/scimit/blast/blastn/wumaskedcds/plots/gff2ps/all_blast.tex

\end{document}
@ 
%
%
%

\subsubsubsctn{Setting {\gps} parameters.}

<<gff2ps customization for blastn>>=
#
# blastn_hsap_mmus.gff2psrc
#
<<Version Control Id Tag>>
#
# L #
<<Layout settings for sites>>
#
# S #
<<Source settings for sites>>
BLASTN::vert_align=center
BLASTN::left_label=++none++
BLASTN::keep_feature_label_space=off
BLASTN::track_spacing_scale=0
BLASTN::source_style=boxed
BLASTN::range=none
BLASTN::track_scale=0.5
BLASTN::feature_color=darkorange
#
# G #
<<Group settings for sites>>
#
# F #
<<Feature settings for sites>>
hsp::shape=box
#
@ 

%%%%%%%%%%%%%%%%%%%% BACKMATTER

% \newpage
% 
% \bibliographystyle{apalike}
% \bibliography{/home1/rguigo/docs/biblio/References}

\newpage
\appendix

\sctn{Scripts developed for this work}

\subsctn{Filtering Real Sites}

The main goal of this script is to filter from sites obtained running {\gnid} those that correspond to real ones. We require that output from {\gnid} must be in GFF format ('-G' command-line option). The command-line usage is:

\centerline{[[ExtractIntronSites.pl <IDs_file> <CDSs_File> <Sites_File> <Output_Dir>]]}

[[<IDs_file>]] records have three fields: a gene identifier, a sequence ID for first species (human) and another one for second species (mouse). [[<CDSs_File>]] and [[<Sites_File>]] are both in GFF, first one contains exon coordinates, second must contain not only sites coords but also their sequence (appearing within the trailing record comment). Finally [[<Output_Dir>]] defines the path to which all the output files will be saved.

<<Grep Real Intron Sites>>=
<<PERL shebang>>
#
# ExtractIntronSites.pl
#
#     Filtering real sites from geneid output.
#
# Usage:
#     ExtractIntronSites.pl <IDs_file> <CDSs_File> <Sites_File> <Output_Dir>
#
#<Use Modules - RIS>>
<<Use Modules - Dumper>>
#
<<Global Vars - Counter>>
<<Global Vars - RIS>>
#
<<Main Loop - RIS>>
#
<<Main Subs - RIS>>
<<Common PERL subs - Text fill>>
<<Common PERL subs - Counter>>
@ 

<<Global Vars - RIS>>=
my ( $ids_file, $cds_file, $sites_file, $output_dir,
     $cnt, %seq_ids, %coords_list, %acceptors, %donors );
@ 

<<Main Loop - RIS>>=
print STDERR "###\n### RUNNING ExtractIntronSites.pl\n###\n".
             "### $ENV{USER} - ".(`date`)."###\n#\n";
&parse_args();
&load_seqids($ids_file);
&load_coords($cds_file);
&load_sites($sites_file);
&filter_sites();
@ 

First of all we check command-line arguments, because there are three mandatory parameters that must be files.

<<Main Subs - RIS>>=
sub parse_args() {
    scalar(@ARGV) < 4 && do {
        print "\nUSAGE: \n".
              "ExtractIntronSites.pl <IDs_file> <CDSs_File> ".
              "<Sites_File> <Output_Dir>\n\n";
        die("!!! ERROR - NOT ENOUGH COMMAND-LINE PARAMETERS. $!");
    };
    $ids_file   = shift @ARGV;
    ( -e $ids_file ) ||
        die("!!! $ids_file DOES NOT EXIST...\n");
    $cds_file   = shift @ARGV;
    ( -e $cds_file ) ||
        die("!!! $cds_file DOES NOT EXIST...\n");
    $sites_file = shift @ARGV;
    ( -e $sites_file ) ||
        die("!!! $sites_file DOES NOT EXIST...\n");
    $output_dir = shift @ARGV;
    $output_dir =~ s%/$%%o;
    ( -e $output_dir && -d _ ) ||
        die("!!! $output_dir DOES NOT EXIST...\n");
    @ARGV = ();
} # parse_args
@ 

We load sequence IDs for both species including the common sequence name.

<<Main Subs - RIS>>=
<<Main Subs - loadseqids>>
@
 
\label{func:loadseqids}
<<Main Subs - loadseqids>>=
sub load_seqids() {
    my $infile = $_[0];
    $cnt = 0;
    print STDERR "### READING SEQUENCE IDs FROM: $infile\n";
    open(IDS,"< $infile") ||
        die("!!! CANNOT OPEN FILE: $infile $!");
    while (<IDS>) {
        my @f;
        <<Skip comments and empty records>>
        @f = split /\s+/og;
        $cnt++;
        $seq_ids{$cnt}{NAME} = $f[0]; 
        $seq_ids{$cnt}{SEQ1} = $f[1]; 
        $seq_ids{$cnt}{SEQ2} = $f[2];
    }; # while (<IDS>)
    close(IDS);
    # print STDERR "SEQ_IDS - ".(Dumper(\%seq_ids));
    print STDERR "#\n# There are $cnt sequences in this file...\n#\n";
} # load_seqids
@

[[load_coords()]] 

<<Main Subs - RIS>>=
sub load_coords() {
    my $infile = $_[0];
    my (%tmp,$id);
    print STDERR "### READING COORDS FROM: $infile\n";
    open(GFF,"< $infile") ||
        die("!!! CANNOT OPEN FILE: $infile $!");
    while (<GFF>) {
        my @f;
        <<Skip comments and empty records>>
        @f = split /\s+/og;
        $id = $f[0];
        defined($coords_list{$id}) || do {
            print STDERR "> Reading Coords for: $id\n";
            $coords_list{$id}{GENENAME} = $f[8];
            $coords_list{$id}{STRAND}   = $f[6];
            @{ $tmp{$id} } = ();
        };
        push @{ $tmp{$id} }, [ @f[3,4] ] if
           (lc($f[2]) =~ /first|internal|terminal|single/);
    }; # while (<GFF>)
    close(GFF);
    foreach $id (keys %tmp) {
        print STDERR "> Processing coords for: $id\n";
        @{ $tmp{$id} } = sort { $a->[0] <=> $b->[0] } @{ $tmp{$id} };
        $coords_list{$id}{STRAND} eq '-' && do {
            @{ $tmp{$id} } = reverse map { reverse $_ } @{ $tmp{$id} };
        };
        # print STDERR 'SORTED @tmp:'.(Dumper(\@{ $tmp{$id} }));
        foreach (my $l = 0; $l <= $#{ $tmp{$id} }; $l++) {
            push @{ $coords_list{$id}{COORDS} }, $tmp{$id}[$l][0], $tmp{$id}[$l][1];
        };
        $coords_list{$id}{C_NUM} = scalar(@{ $coords_list{$id}{COORDS} }) / 2;
    }; # foreach $id
    # print STDERR Dumper(\%coords_list);
} # load_coords
@ 

[[load_sites()]] reads sites found by {\gnid} that were saved as GFF records. 

<<Main Subs - RIS>>=
sub load_sites() {
    my $infile = $_[0];
    my (@tmp,$id,$strand,$pos,$rec);
    print STDERR "### READING SITES FROM: $infile\n";
    open(SITES,"< $infile") ||
        die("!!! CANNOT OPEN FILE: $infile $!");
    $n = 0;
    while (<SITES>) {
        my @f;
        $c = '.';
        <<Skip comments and empty records>>
        $rec = $_;
        @f = split /\s+/og, $rec;
        ($id,$strand) = @f[0,6];
        lc($f[2]) eq 'acceptor' && do {
            $c = 'A';
            $pos = ($strand eq '+') ? $f[4] : $f[3] ;
            $acceptors{$id}{$strand}{$pos}{SCORE}  = $f[5];
            $acceptors{$id}{$strand}{$pos}{SEQ}    = $f[9];
            $acceptors{$id}{$strand}{$pos}{GFF}    = $rec;
        };
        lc($f[2]) eq 'donor'    && do {
            $c = 'D';
            $pos = ($strand eq '+') ? $f[3] : $f[4] ;
            $donors{$id}{$strand}{$pos}{SCORE}  = $f[5];
            $donors{$id}{$strand}{$pos}{SEQ}    = $f[9];
            $donors{$id}{$strand}{$pos}{GFF}    = $rec;
        };
    } continue { 
        &counter(++$n,$c);
    }; # while (<SITES>)
    &counter_end($n,$c);
    close(SITES);
    # print STDERR Dumper(\%acceptors);
    # print STDERR Dumper(\%donors);
} # load_sites
@ 
%$

Here we filter real sites from the whole sites set and we save to the corresponding file in the output dir (as it is set in [[$output_dir]] variable).%$ 

<<Main Subs - RIS>>=
sub filter_sites() {
    my $i;
    for ($i = 1; $i<=$cnt; $i++) {
        print STDERR "# Working on: $seq_ids{$i}{NAME}\n";
        &save_GFF($seq_ids{$i}{SEQ1}); 
        &save_GFF($seq_ids{$i}{SEQ2});
    }; # for $i
} # filter_sites
@ 

<<Main Subs - RIS>>=
sub save_GFF() {
    my $infile = $_[0];
    my ($j,$pos);
    my ($dn_cnt,$ac_cnt) = (0,0);
    my $ref = \%{ $coords_list{$infile} };
    open(GFF,"> $output_dir/$infile") || do {
        print STDERR "!!! CANNOT OPEN $output_dir/$infile ...\n";
        return;
    };
  CHECKPOINT: {
      ($ref->{C_NUM} == 1) && do {
          print STDERR "!!! $infile has no intronic sites annotated...\n";
          print GFF "#\n# $infile has no intronic sites annotated\n".
                       "#         (no cds found or single gene).#\n";
          last CHECKPOINT;
      };
      for ($j = 2; $j < ($ref->{C_NUM} * 2) - 1; $j+=2 ) {
          $pos = $ref->{COORDS}[$j];
          defined($acceptors{$infile}{$ref->{STRAND}}{$pos}{GFF}) && do {
              $ac_cnt++;
              print GFF "$acceptors{$infile}{$ref->{STRAND}}{$pos}{GFF}\n";
          };
      }; # for $j
      for ($j = 1; $j < ($ref->{C_NUM} * 2) - 1; $j+=2 ) {
          $pos = $ref->{COORDS}[$j];
          defined($donors{$infile}{$ref->{STRAND}}{$pos}{GFF}) && do {
              $dn_cnt++;
              print GFF "$donors{$infile}{$ref->{STRAND}}{$pos}{GFF}\n";
          };
      }; # for $j
    }; # CHECKPOINT
    close(GFF);
    print STDERR "#> $infile : $ref->{C_NUM} exons  ".
                 "$dn_cnt donors  $ac_cnt acceptors.\n";
} # save_GFF
# $coords_list{$id}{GENENAME}
# $coords_list{$id}{STRAND}
# $coords_list{$id}{C_NUM}
# @{ $coords_list{$id}{COORDS} }
# $acceptors{$id}{$pos}{STRAND}
# $acceptors{$id}{$pos}{SCORE}
# $acceptors{$id}{$pos}{SEQ}
# $acceptors{$id}{$pos}{GFF}
# $donors{$id}{$pos}{STRAND}
# $donors{$id}{$pos}{SCORE}
# $donors{$id}{$pos}{SEQ}
# $donors{$id}{$pos}{GFF}
@ 

\subsctn{Joining {\ps} figures with {\LaTeX}}

<<Merging Figures for Sites>>=
<<PERL shebang>>
#
# SitesFigureMerger.pl
#
#     Merging gff2ps figures set to "page_BBox=200,800" to save printing space.
#
# Usage:
#     SitesFigureMerger.pl <IDs_file> <Input_Dir> > file.tex
#
#<Use Modules - MFS>>
#
<<Global Vars - MFS>>
#
<<Main Loop - MFS>>
#
<<Main Subs - MFS>>
@

<<Global Vars - MFS>>=
my ($cnt, %seq_ids, $ids_file, $input_dir);
my $mod_value = 5;
@

<<Main Loop - MFS>>=
print STDERR "###\n### RUNNING SitesFigureMerger.pl\n###\n".
             "### $ENV{USER} - ".(`date`)."###\n#\n";
&parse_args();
&load_seqids($ids_file);
&print_LaTeX();
@

<<Main Subs - MFS>>=
sub parse_args() {
    scalar(@ARGV) < 2 && do {
        print "\nUSAGE: \n".
              "SitesFigureMerger.pl <IDs_file> <Input_Dir> > file.tex\n\n";
        die("!!! ERROR - NOT ENOUGH COMMAND-LINE PARAMETERS. $!");
    };
    $ids_file   = shift @ARGV;
    ( -e $ids_file ) ||
        die("!!! $ids_file DOES NOT EXIST...\n");
    $input_dir = shift @ARGV;
    $input_dir =~ s%/$%%o;
    ( -e $input_dir && -d _ ) ||
        die("!!! $input_dir DOES NOT EXIST...\n");
    @ARGV = ();
} # parse_args
@

We are reusing here the [[load_seqids()]] (section~\ref{func:loadseqids}, page~\pageref{func:loadseqids}). 

<<Main Subs - MFS>>=
<<Main Subs - loadseqids>>
@

<<Main Subs - MFS>>=
sub print_LaTeX() {
    my ($i, $file, $nwfig, $open_flg);
    $open_flg = 0;
    print STDOUT $ltx_header;
    for ($i = 1; $i <= $cnt; $i++) {
        print STDERR "# Working on: $seq_ids{$i}{NAME}\n";
        $file = "$input_dir/$seq_ids{$i}{SEQ1}\_$seq_ids{$i}{SEQ2}.ps";
        ($nwfig = $ltx_figure) =~ s/\:\:\:PSFILE\:\:\:/$file/o;
        ($i % $mod_value == 1) && do {
            $open_flg = 1;
            print STDOUT '\ \vfill'."\n".'\begin{center}'."\n".
                         '\noindent\begin{tabular}{c}'."\n";
            # print STDOUT '\begin{sidewaysfigure}'."\n";
        };
        print STDOUT $nwfig;
        ($i % $mod_value == 0) && do {
            $open_flg = 0;
            print STDOUT '\end{tabular}'."\n".'\end{center}'."\n".'\vfill'."\n";
            # print STDOUT '\end{sidewaysfigure}'."\n";
            print STDOUT "\n".'\newpage'."\n\n" unless $i == $cnt;
        };
    }; # for
    $open_flg && do {
        print STDOUT '\end{tabular}'."\n".'\end{center}'."\n".'\vfill'."\n";
        # print STDOUT '\end{sidewaysfigure}'."\n";
    };
} # print_LaTeX
@

<<Global Vars - MFS>>=
my $ltx_header = <<'+++EOLTX+++';
%
% This file contains a wrapper to visualize a series of PostScript plots
% obtained with gff2ps, which have the same BoundingBox (defined as 200x800)
%
+++EOLTX+++
my $ltx_figure = <<'+++EOLTX+++';
\fbox{\setlength{\fboxsep}{0pt}
 \includegraphics[angle=270,width=19cm]{:::PSFILE:::}
 } % fbox
\\[-1ex]
+++EOLTX+++
@

\subsctn{Masking CDS from fasta files}

<<Masking CDS on fasta files>>=
<<PERL shebang>>
#
# MaskCDS.pl
#
#     Masking CDS on fasta files.
#
# Usage:
#     MaskCDS.pl <fasta_file> <CDS_file(GFF)> > <fasta_masked>
#
<<Use Modules - MCFF>>
#
<<Global Vars - MCFF>>
#
<<Main Loop - MCFF>>
#
<<Main Subs - MCFF>>
<<Common PERL subs - Min Max>>
@

<<Use Modules - MCFF>>=
<<Use Modules - Bio::Seq>>
@

<<Global Vars - MCFF>>=
my (%seqs, $fasta_file, $cds_file);
@

<<Main Loop - MCFF>>=
print STDERR "###\n### RUNNING MaskCDS.pl\n###\n".
             "### $ENV{USER} - ".(`date`)."###\n#\n";
&parse_args();
&load_fasta($fasta_file);
&load_coords($cds_file);
&mask_sequence();
&write_fasta(); # STDOUT
@

<<Main Subs - MCFF>>=
sub parse_args() {
    scalar(@ARGV) < 2 && do {
        print "\nUSAGE: \n".
              "MaskCDS.pl <fasta_file> <CDS_file(GFF)> > <fasta_masked>\n\n";
        die("!!! ERROR - NOT ENOUGH COMMAND-LINE PARAMETERS. $!");
    };
    $fasta_file   = shift @ARGV;
    ( -e $fasta_file ) ||
        die("!!! $fasta_file DOES NOT EXIST...\n");
    $cds_file   = shift @ARGV;
    ( -e $cds_file ) ||
        die("!!! $cds_file DOES NOT EXIST...\n");
    @ARGV = ();
} # parse_args
@

<<Main Subs - MCFF>>=
sub load_fasta($fasta_file) {
    my $infile = $_[0];
    my ($seqin,$seq,$seqnum,$sid);
    print STDERR "### READING FASTA SEQUENCES FROM: $infile\n";
    $seqnum = 0;
    $seqin = Bio::SeqIO->new(-format => 'FASTA', -file => "$infile");
    while ($seq = $seqin->next_seq()) {
        $sid = $seq->display_id();
        $seqs{$sid}{FLG} = 1;
        $seqs{$sid}{MAX} = 0;
        $seqs{$sid}{SEQ} = $seq->seq();
        $seqs{$sid}{LEN} = $seq->length();
        $seqs{$sid}{CDS} = ();
        $seqnum++;
        }; # while next_seq
    print STDERR "#\n#   $seqnum sequences found...\n#\n";
} # load_fasta
@

We are saving CDS coords in array [[@{ $seqs{$sid}{CDS} }]], but we do not split into subarrays because we are going to parse the main array by pairs of its elements.

<<Main Subs - MCFF>>=
sub load_coords($cds_file) {
    my $infile = $_[0];
    my %recnum;
    print STDERR "### READING GFF COORDS FROM: $infile\n";
    open(GFF,"< $infile") ||
        die("!!! CANNOT OPEN FILE: $infile $!");
    while (<GFF>) {
        my ($sid,$feat,$ori,$end);
        <<Skip comments and empty records>>
        ($sid,undef,$feat,$ori,$end,undef) = split /\s+/og, $_, 6;
        $seqs{$sid}{MAX} = &max($seqs{$sid}{MAX},$ori,$end);
        push @{ $seqs{$sid}{CDS} }, ($ori,$end) if
           (lc($feat) =~ /first|internal|terminal|single/);
        $recnum{$sid}++;
    }; # while (<GFF>)
    close(GFF);
    my $ln = "";
    foreach my $sid (sort keys %recnum) {
        $ln .= "#   $recnum{$sid} GFF records found for sequence $sid...\n";
    }; # foreach
    print STDERR "#\n$ln#\n";
} # load_coords
@

<<Main Subs - MCFF>>=
sub mask_sequence() {
    my ($sid,$cds,$tmp,$msknum);
    $msknum = 0;
    print STDERR "### MASKING SEQUENCES\n#\n";
    foreach $sid (keys %seqs) {
        $tmp = \@{ $seqs{$sid}{CDS} };
        (scalar(@{$tmp}) == 0) && do {
            $seqs{$sid}{MSG} = "no coords found in its GFF files";
            print STDERR "!!! SKIPING sequence $sid: $seqs{$sid}{MSG}\n";
            $seqs{$sid}{FLG} = 0;
            next;
        };
        $seqs{$sid}{MAX} > $seqs{$sid}{LEN} && do {
            $seqs{$sid}{MSG} = "coords out of sequence length range";
            print STDERR "!!! SKIPING sequence $sid: $seqs{$sid}{MSG}\n";
            $seqs{$sid}{FLG} = 0;
            next;
        };
        for ($cds = 0; $cds < $#{$tmp}; $cds+=2) {
			my ($cds_len,$cds_ori,$cds_end,$n);
            ($cds_ori,$cds_end) = ($tmp->[$cds],$tmp->[($cds + 1)]);
            $cds_len = $cds_end - $cds_ori + 1;
            $n = "N" x $cds_len;
            substr($seqs{$sid}{SEQ}, ($cds_ori - 1), $cds_len) = $n;
        }; # foreach $cds
        $msknum++;
    }; # foreach $sid
    print STDERR "#\n#   $msknum sequences masked...\n#\n";
} # mask_sequence
@

<<Main Subs - MCFF>>=
sub write_fasta() {
    my ($seqout,$seq,$sid);
    print STDERR "### WRITING MASKED SEQUENCES to STDOUT\n#\n";
    $seqout = Bio::SeqIO->new(-format => 'FASTA', -fh => \*STDOUT);
    foreach $sid (keys %seqs) {
        $seqs{$sid}{FLG} || do {
            print STDERR "!!! Sequence $sid was not masked ... \n".            
                         "!!! ... $seqs{$sid}{MSG} \n#\n";
            # next;
        };
        $seq = Bio::Seq->new();
        $seq->display_id($sid);
        $seq->seq($seqs{$sid}{SEQ});
        $seqout->write_seq($seq);
    }; # foreach $sid
    print STDERR "#\n#   Writing masked sequences DONE...\n#\n";
} # write_fasta
@

<<Tangling SITES>>=
#
notangle -L -R"Grep Real Intron Sites" $WORK/$nwfile.nw | \
    perl -ne '$.>1 && print' > $BIN/ExtractIntronSites.pl ;
notangle -L -R"Merging Figures for Sites" $WORK/$nwfile.nw | \
    perl -ne '$.>1 && print' > $BIN/SitesFigureMerger.pl ;
notangle -L -R"Masking CDS on fasta files" $WORK/$nwfile.nw | \
    perl -ne '$.>1 && print' > $BIN/MaskCDS.pl ;
#
chmod a+x $BIN/ExtractIntronSites.pl ;
chmod a+x $BIN/SitesFigureMerger.pl ;
chmod a+x $BIN/MaskCDS.pl ;
#
notangle -R"gff2ps customization for sites" $WORK/$nwfile.nw \
    > $BIN/param/sites_hsap_mmus.gff2psrc ;
notangle -R"gff2ps customization for blastn" $WORK/$nwfile.nw \
    > $BIN/param/blastn_hsap_mmus.gff2psrc ;
#
notangle -R"LaTeX wrapper main doc" $WORK/$nwfile.nw \
    > $DOCS/psfigures/all_main.tex ;
notangle -R"LaTeX wrapper main doc for blast" $WORK/$nwfile.nw \
    > $DOCS/psfigures/all_blast_main.tex ;
#
notangle -R"MetaPost sites scores" $WORK/$nwfile.nw \
    > $DOCS/psfigures/sites_score_distribution.mp ;
notangle -R"MetaPost sites scores" $WORK/$nwfile.nw \
    > $DOCS/psfigures/sites_score_distribution.mp ;
notangle -R"MetaPost acceptors scores" $WORK/$nwfile.nw \
    > $DOCS/psfigures/acceptors_score_distribution.mp ;
notangle -R"MetaPost donors scores" $WORK/$nwfile.nw \
    > $DOCS/psfigures/donors_score_distribution.mp ;
@ 

\end{comment}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\end{document}

