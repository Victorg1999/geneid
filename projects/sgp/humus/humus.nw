% -*- mode: Noweb; noweb-code-mode: perl-mode; tab-width: 4 -*-
\documentclass[11pt]{article}
%
%2345678901234567890123456789012345678901234567890123456789012345678901234567890
%        1         2         3         4         5         6         7         8
%
% # $Id: humus.nw,v 1.33 2002-05-05 19:20:41 jabril Exp $ 
%
\usepackage{noweb}
\usepackage[a4paper,offset={0pt,0pt},hmargin={2cm,2cm},vmargin={1cm,1cm}]{geometry}
\usepackage{graphics}
\usepackage[dvips]{graphicx}
%% pstricks
\usepackage[dvips]{pstcol}
\usepackage{pstricks}
%\usepackage{pst-node}
%\usepackage{pst-char}
%\usepackage{pst-grad}
%% bibliography
\usepackage{natbib}
%% latex2html
\usepackage{url}
\usepackage{html}     
\usepackage{htmllist} 
%% tables    
\usepackage{dcolumn}
%\usepackage{colortbl}
%\usepackage{multirow}
%\usepackage{hhline}
%\usepackage{tabularx}
%% seminar
%\usepackage{semcolor,semlayer,semrot,semhelv,sem-page,slidesec}
%% draft watermark
%\usepackage[all,dvips]{draftcopy}
%\draftcopySetGrey{0.9}
%\draftcopyName{CONFIDENTIAL}{100}
%% layout
\usepackage{fancyhdr} % Do not use \usepackage{fancybox} -> TOCs disappear
%\usepackage{lscape}
%\usepackage{rotating}
%\usepackage{multicol}
\usepackage{verbatim}
%\usepackage{version}
%% fonts
\usepackage{times}\fontfamily{ptm}\selectfont
\usepackage{t1enc}

% noweb options
\noweboptions{smallcode}
\def\nwendcode{\endtrivlist \endgroup} % relax page breaking scheme
\let\nwdocspar=\par                    %

\input defs.tex % from <LaTeX new definitions> chunk

%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%
\begin{document}

<<HIDE: LaTeX new definitions>>=
%%%%% Colors for gff2ps
\input ColorDefs.tex

%%%%% New Commands are defined here
\newcommand{\sctn}[1]{\section{#1}}
\newcommand{\subsctn}[1]{\subsection{#1}}
\newcommand{\subsubsctn}[1]{\subsubsection{#1}}
\newcommand{\parsctn}[1]{\paragraph{#1}}
\newcommand{\desc}[1]{\item[#1] \ \\}
\newcommand{\todo}[1]{
  \vskip 3ex
  \hspace{-0.75cm}
   \psframebox[framearc=0.2,linecolor=darkred,linewidth=1pt,
              fillstyle=solid,fillcolor=verylightyellow,framesep=2ex]{
     \begin{minipage}[t]{16cm}
     \vskip -4.75ex
     \hspace{-1.25cm}
       \psframebox[framearc=1,linecolor=darkred,linewidth=1.25pt,
               fillstyle=solid,fillcolor=verylightorange,framesep=5pt]{
               \textcolor{darkred}{\textbf{\hspace{2ex}TO DO\hspace{2ex}}}
         } % psframebox
      \begin{itemize}\setlength{\itemsep}{-0.5ex} #1 \end{itemize}
     \end{minipage}
     } % psframebox
  \vskip 1.5ex
} % newcommand todo
\newcommand{\todoitem}[2]{
  \item[$\triangleright$] [\textit{Section}~\ref{#2}, 
                           \textit{page}~\pageref{#2}]\\ {#1}
} % newcommand todoitem
<<HIDE: new LaTeX commands>>

%%%%% PSTRICKs definitions
\pslongbox{ExFrame}{\psframebox}
\newcommand{\cln}[1]{\fcolorbox{black}{#1}{\textcolor{#1}{\rule[-.3ex]{1cm}{1ex}}}}
\newpsobject{showgrid}{psgrid}{subgriddiv=0,griddots=1,gridlabels=6pt}
% \pscharpath[fillstyle=solid, fillcolor=verydarkcyan, linecolor=black, linewidth=1pt]{\sffamily\scshape\bfseries\veryHuge #1 }
<<HIDE: new LaTeX pstricks>>

%%%%% global urls
% \newcommand{\getpsf}[1]{\html{(\htmladdnormallink{Get PostScript file}{./Psfiles/#1})}}   
<<HIDE: new LaTeX urls>>

%%%%% defs
\def\noweb{\textsc{noweb}}
\def\ps{\textsc{PostScript}}
<<HIDE: new LaTeX definitions>>

%%%%% TODO defs
<<HIDE: new defs TODO>>

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%
\def\genomelab{\textbf{Genome Informatics Research Lab}}
\def\shorttit{\textbf{Human + Mouse}}
\def\tit{\textsc{\shortstack{Human Genome Annotation\\using Mouse Homology}}}
%
\def\mtauthor{
 \htmladdnormallink{\texttt{author@imim.es}}
                   {MAILTO:author@imim.es?subject=[humus]}
 } % def mtauthor
%
\def\authorslist{
 The Author/s {\mdseries\small\dotfill \mtauthor } \\
 % Other authors here...\\
 } % def authorslist
\def\authorshort{
 Abril, JF; Parra, G; Guig\'o, R
 } % def authorshort
%
\def\license{GNU General Public License (GNU-GPL)}
%
\def\progdesc{
We are going to scale up all the processes we have tested on {\lhsap} chromosomes 22 and 21, to the whole genome approach, in which we take advantage of the homology between {\hsap} and {\lmmus} genomes to increase gene prediction accuracy and producing a better genome annotation of the coding regions.
 } % def progdesc
%
\def\showaffiliation{
\scalebox{0.9 1}{\Large\textsl{\genomelab}}\\
Grup de Recerca en Infom\`atica Biom\`edica\\
Institut Municipal d'Investigaci\'o M\`edica\\
Universitat Pompeu Fabra\\[2ex]
 } % def showaffiliation
%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%%%% Setting text for footers and headers
\fancyhead{} % clear all fields
\fancyfoot{} % clear all fields
\fancyhead[RO,LE]{\thepage}
\fancyhead[LO,RE]{\shorttit\quad\rightmark}
\fancyfoot[LO,LE]{\small\textbf{\genomelab}}
\fancyfoot[CO,CE]{\small\textsl{\authorshort}}
\fancyfoot[RO,RE]{\small\textbf{\today}}
\renewcommand{\headrulewidth}{1pt}
\renewcommand{\footrulewidth}{1pt}
%
@

<<HIDE: new LaTeX commands>>=
\newcommand{\mylst}[2]{
 \begin{center}
% \fbox{
  \begin{minipage}{0.95\linewidth}
   \textbf{#1}
   \begin{itemize}
     #2
   \end{itemize}
  \end{minipage}
% } % fbox
 \end{center}
} % newcommand->mylst
\newcommand{\whtlst}[1]{\mylst{What to do here:}{#1}} % newcommand->chklst
\newcommand{\chklst}[1]{\mylst{Check points:}{#1}} % newcommand->chklst
@ 
<<HIDE: new LaTeX pstricks>>=
@ 
<<HIDE: new LaTeX urls>>=
\def\mtjabril{\htmladdnormallink{\textbf{jabril@imim.es}}{MAILTO:jabril@imim.es?subject=[HuMus]}}
\def\mtgparra{\htmladdnormallink{\textbf{gparra@imim.es}}{MAILTO:gparra@imim.es?subject=[HuMus]}}
\def\mtrguigo{\htmladdnormallink{\textbf{rguigo@imim.es}}{MAILTO:rguigo@imim.es?subject=[HuMus]}}
\def\mthomology{\htmladdnormallink{\textbf{homology@viaken.com}}{MAILTO:homology@viaken.com?subject=[HuMus]}}
@ 
<<HIDE: new LaTeX definitions>>=
\def\perl{\textsc{Perl}}
\def\biop{\textsc{BioPerl}}
\def\ps{\textsc{PostScript}}
\def\rptm{\textsc{RepeatMasker}}
\def\bl{\textsc{Blast}}
\def\bn{\textsc{blastn}}
\def\bx{\textsc{blastx}}
\def\bp{\textsc{blastp}}
\def\tbn{\textsc{tblastn}}
\def\tbx{\textsc{tblastx}}
\def\pb{\texttt{parseblast}}
\def\gnid{\texttt{geneid}}
\def\gnsc{\texttt{genscan}}
\def\twsc{\texttt{twinscan}}
\def\slam{\textsc{slam}}
\def\sgp{\textsc{sgp}}
\def\gps{\texttt{gff2ps}}
\def\aps{\texttt{gff2aplot}}
\def\apo{\textsl{Apollo}}
\def\refseq{\textsc{RefSeq}}
\def\ens{\textit{\texttt{emsembl}}}
\def\hsap{\textit{H. sapiens}}
\def\lhsap{\textit{Homo sapiens}}
\def\mmus{\textit{M. musculus}}
\def\lmmus{\textit{Mus musculus}}
@ 
<<HIDE: new defs TODO>>=
@ 

%

\thispagestyle{empty}

\begin{titlepage}

\ \vfill
\begin{center}
\textbf{\Huge \tit}\\[5ex]

% \textbf{\Large Authors List Here}\\[1ex]
\textbf{\Large Josep F. Abril}\\[1ex]
\textbf{\Large Gen\'{\i}s Parra}\\[1ex]
\textbf{\Large Roderic Guig\'o}\\[5ex] % \raisebox{0.85ex}{\footnotesize$\,\dag$}\\[0.5ex]

\textbf{\large --- \today ---}\\[10ex]

\begin{abstract}
\begin{center}
\parbox{0.75\linewidth}{
\progdesc
} % parbox
\end{center}
\end{abstract}

\vfill

\begin{raggedleft}
\showaffiliation
\raisebox{0.85ex}{\footnotesize$\dag\,$}{\large e-mail: {\mtjabril}, {\mtgparra} and {\mtrguigo}}\\
\end{raggedleft}
\end{center}

\end{titlepage} %'

\newpage %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\thispagestyle{empty}

\ \ \\
% EMPTY PAGE

%
%%%%%%%%%%%%%%%%%%%% FRONTMATTER

\newpage %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\pagenumbering{roman}
\setcounter{page}{1}
\pagestyle{fancy}
% Marks redefinition must go here because pagestyle 
% resets the values to the default ones.
\renewcommand{\sectionmark}[1]{\markboth{}{\thesection.\ #1}}
\renewcommand{\subsectionmark}[1]{\markboth{}{\thesubsection.\ \textsl{#1}}}

\tableofcontents
\listoftables
\listoffigures

\vfill
\begin{center}
{\small$<$ \verb$Id: humus.nw,v 1.33 2002-05-05 19:20:41 jabril Exp $$>$ }
\end{center}

%%%%%%%%%%%%%%%%%%%% MAINMATTER

\newpage %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\pagenumbering{arabic}
\setcounter{page}{1}

\sctn{Introduction}

\subsctn{Project protocol}

\textbf{Issues:}
\begin{itemize}
 \item Whole genome, chromosome and process (all sequences or single sequence) runs.
 \item Results validation.
 \item Unassembled sequences IDs (those ``random''). Loop through each sequence in chromosomes.
 \item Move all verified software to a global path, like [[/usr/local/molbio/share]], \\ instead of [[/projects/sgp/bin]].
 \item Make every protocol step runnable on any machine (so wrapper must handle PBS queues too).
 \item Generate global report by chromosome.
 \item ...
\end{itemize}


\subsctn{Making up the jobs list}

Here we are going to define which will be the fields structure for the jobs file. That file will contain a set of jobs to be executed, each step within a job must have an input/output directories pair from where to read/write, and that depends on the execution date of the main job. Jobs must also be sequence oriented, where sequences are grouped within chromosomes (which will work the same way as job/steps), but this will be handled by the step-runner program (see [[stepper.pl]] definition on corresponding apendix section).\\

\noindent\hspace{-1cm}
\begin{tabular}{|@{\hspace{2ex}}c@{\hspace{2ex}}|@{\hspace{2ex}}c@{\hspace{2ex}}|}\hline
& \\
\begin{minipage}[t]{8cm}
\textbf{JOBS FILE DEFINITION}
\scriptsize
\begin{verbatim}
...
  ...
JOB_j
  * Job ID
  * Job description
  * Job main path
  * Job execution JOBXID (to set subpath)
  * STEP list:
    ...
      ...
    STEP_s
      + Step ID
      + Step description
      + Step main path
      + Step execution SXID (to set subpath) ?
      + Input dir:  IDIR
      + Output dir: ODIR
      + Error dir:  EDIR (also logs)
      + Step shell commands:
        #># STEP_CODE ----...
        ... commands ...
        #># END_OF_STEP --...
    end-of-STEP_s
    ...
      ...
end-of-JOB_j
...
  ...

\end{verbatim}
\end{minipage}
&
\begin{minipage}[t]{10cm}
\textbf{LOOPING JOBS THROUGH DATA}
\scriptsize
\begin{verbatim}
...
  ...
CHR_c
  * Set chromosome directory
  * Get sequences associated to chromosome "c"
  * SEQ list:
    ...
      ...
    SEQ_q
      + Output file is set to sequence "q" name
      + For each selected step:
        - Combine into $$ script (saving into a tmp dir)
           > common bash exports from '.project_VARS':
             HUMUS, BIN, SRC,
             LIBPERL, LIBSTEP, MySQLPAR, ...
           > current sequence definitions:
             CHR, SEQ, JOB, STEP, XID,
             CHRDIR ($HUMUS/$NCHR),
             JOBDIR ($CHRDIR/$JOB/$XID),
             IDIR, ODIR, EDIR, ...
           > build directories: 
             MkDirs ODIR;
             [EDIR != ODIR] && MkDirs EDIR
           > current step (use STEP_ID ?)
        - Report start status to DB execution table 
        - Launch $$ script to local/remote machine
        - Report termination status to DB execution table 
      + ...
    end-of-SEQ_q
    ...
      ...
end-of-CHR_c
...
  ...

\end{verbatim}
\end{minipage}
\\\hline
\multicolumn{2}{|c|}{\shortstack{
\ \\[1ex]
\textbf{PATH CONSTRUCTOR}\\[1ex]
\texttt{/projects/H.sapiens/\textbf{HSAPSTR\_v}/\textbf{CHR\_c}/\textbf{JOB\_j}/\textbf{JOBXID}/\textbf{STEP\_s}/\textbf{SEQ\_q}.files}\\[1ex]
}}
\\\hline
\end{tabular}


\subsctn{Basic squetch of job and step records }

<<Empty JOB Definition Record>>=
             #.........................(max ID length: 25chars)
####>#########>#######################<########################################<#
#># JOB_ID    ...
#># JOB_DESC  ...
#>#        :  ...
#>#        :  ...
#># JOB_PATH  ...
#># JOB_XID   ...
#># JOB_FILE  $LIBSTEP/...
#># END_OF_JOB ##################################################################
@ 


<<Empty STEP Definition Record>>=
             #.........................(max ID length: 25chars)
####>#########>#######################<########################################<#
#># STEP_ID   ...
#># STEP_DESC ...
#>#         : ...
#>#         : ...
#># STEP_PATH ...
#># STEP_XID  $<JOB_ID>
#># STEP_IDIR ...
#># STEP_ODIR ...
#># STEP_EDIR ...
#># STEP_CODE   --------------------------------------------------------------#<#
...
#<# Remove this line from code when tangling
#<#   (commands used when testing script)...
...
#># END_OF_STEP --------------------------------------------------------------#<#
@

<<Empty STEP Definition FILE>>=
<<Empty STEP Definition Record>>
<<Empty STEP Definition Record>>
...
<<Empty STEP Definition Record>>
@

\subsctn{Main job collector}

<<JOB COLLECTOR>>=
####>#########>################################################################<#
### 
### Collecting step records for each pipeline job
###
####>#########>################################################################<#
{ cat $WORK/.bash_VARS ;
  notangle -R'tangling: mySQL param' $WORK/$nwfile.nw ; } | bash ;
#
notangle -R'JOBS: Sequence Analysis'                      \
    $WORK/$nwfile.nw | egrep -v '^#<#' - | cpif $LIBSTEP/annotation.job ;
notangle -R'JOBS: Running GENEID standard'                \
    $WORK/$nwfile.nw | egrep -v '^#<#' - | cpif $LIBSTEP/geneid.job ;
notangle -R'JOBS: HsapGPa x MGSCv3 WUTBLASTX'             \
    $WORK/$nwfile.nw | egrep -v '^#<#' - | cpif $LIBSTEP/tblastx.job ;
notangle -R'JOBS: SGP with HSAPgpa x MGSCv3 homology'     \
    $WORK/$nwfile.nw | egrep -v '^#<#' - | cpif $LIBSTEP/sgp.job ;
notangle -R'JOBS: HsapGPa x MmusRIKENcDNA WUTBLASTX' \
    $WORK/$nwfile.nw | egrep -v '^#<#' - | cpif $LIBSTEP/tblastx-riken.job ;
notangle -R'JOBS: SGP with HSAPgpa x MmusRIKENcDNA homology'     \
    $WORK/$nwfile.nw | egrep -v '^#<#' - | cpif $LIBSTEP/sgp-riken.job ;
notangle -R'JOBS: SGP with HSAPgpa x MmusMGSCv3+RIKENcDNA homology'     \
    $WORK/$nwfile.nw | egrep -v '^#<#' - | cpif $LIBSTEP/sgp-mgsc+riken.job ;
notangle -R'JOBS: Visualizing Results with Apollo'        \
    $WORK/$nwfile.nw | egrep -v '^#<#' - | cpif $LIBSTEP/apollo.job ;
#
$MySQLPAR/admin_db_Hsapiens.pl ;
#
@ 

\newpage %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\sctn{Sequence Analysis}

\whtlst{
\item Get annotations for each sequence from Golden Path annotation.
\item Get fragment lengths, fragment number.
\item Get coords of N-masked regions from assembly gaps.
\item Get G+C content.
}

<<JOBheader: Sequence Analysis>>=
####>#########>#######################<########################################<#
#># JOB_ID    HSAP_GP_ANNOTATION
#># JOB_DESC  Homo sapiens Golden Path annotation.
#>#        :  Processing files downloaded from Golden-Path server
#>#        :  ( URL: http://genome.ucsc.edu/ ).
#>#        :  We retrieve fasta sequences, gaps, annotation (RefSeq and 
#>#        :  Ensembl), genscan predicted genes and so on.
#>#        :  Last UCSC-GP version being analyzed is August, 2001.
#># JOB_PATH  annotation
#># JOB_XID   $HSAPID
#># JOB_FILE  ${LIBSTEP}/annotation.job
#># END_OF_JOB ##################################################################
@ 

<<JOBS: Sequence Analysis>>=
<<STEPS(Sequence Analysis): INITIALIZE>>
<<STEPS(Sequence Analysis): ASSEMBLY GAPS>>
<<STEPS(Sequence Analysis): ORIGINAL MASKING>>
<<STEPS(Sequence Analysis): REFSEQ>>
<<STEPS(Sequence Analysis): ENSEMBL>>
<<STEPS(Sequence Analysis): GENSCAN>>
<<STEPS(Sequence Analysis): Evaluating genscan results>>
@

\subsctn{Initialization} %%%%%%%%%%%%%%%%%%%%%%

<<Global: >>=
#
#
# HUMUS="$BASE/H.sapiens" -> .project_VARS
#
MkDirs $HUMUS/.ftp $HUMUS/.ftp/PankajAgarwal
#
@
 
<<Global: >>=
#
# Retrieving Golden path sequence names and length
#
##
## HSAP="/seq/genomes/H.sapiens/golden_path_20010806" ; # UCSC
## HSAPID="20010806";
##
HSAP="/seq/genomes/H.sapiens/golden_path_20011222" ; # UCSC
HSAPID="20011222";
HUMUS="/projects/H.sapiens/20011222.UCSCgp";
MkDirs $HUMUS
##
# 
# getfastadesc.pl must be executed after table update
#   on mySQL database (after admin_db_Hsapiens.pl)
#
$BIN/getfastadesc.pl $MySQLPAR/chrs.tbl $HSAP/chromFa \
                     > $HUMUS/seqid_list 2> $HUMUS/seqid_list.rpt ;
#
###################################################################
#
# Fixing Pankaj TBLASTX files
#
FTPATH="/projects/H.sapiens/.ftp/PankajAgarwal/MGSCv3-22dec2001GP-tbx" ;
##
ls -1 $FTPATH/ | grep -c '^chr' ;
  32232 TOTAL FILES
#
## Checking header (if it contains TBLASTX at the beginning)
ls -1 $FTPATH/ | while read n; do head -1 $n; done | sort | uniq -c | sort -nr ;
  32219	TBLASTX
      4	                       (^@ x n times)
      3	                         "       "
      1	                         "       "
      1	                         "       "
      1	....10....20....30......60....70....80....90....100%
      1	....10....30....40....50........70....80....90....100%
      1	....10....20...30....40....50....60......80....90....100%
      1	........20....30....40....50....60....70....80....90....100%
        13 FILES WITH BAD TBX HEADER !!!!
  32232 TOTAL FILES
# FILES WITH BAD TBX HEADER
chr10_107400000_100300
chr12_500000_100300
chr13_77200000_100300
chr15_46400000_100300
chr17_31400000_100300
chr18_36200000_100300
chr22_35300000_100300
chr2_58500000_100300
chr2_92300000_100300
chr4_22100000_100300
chr8_139100000_100300
chr8_82800000_100300
chrX_92200000_100300
## FIXING BAD HEADERS !!!
errsfound=0 ;
ls -1 $FTPATH/ | grep '^chr' | \
  while read n ; 
    do {
      head -1 $FTPATH/$n | \
        gawk 'BEGIN{ fl=ARGV[1]; ARGV[1]="" }
              $1 !~ "TBLASTX" {print fl}' $n - ;
    } ;
  done > $FTPATH.bad_header_files ;
cat $FTPATH.bad_header_files | \
  while read m ;
    do {
      errsfound=`expr $errsfound + 1` ;
      perl -e ' use strict;
my $ifile = shift @ARGV;
my $fl = "";
($ifile =~ m%/([^/]*)$%o) && ($fl = $1);
print STDERR "# Working on $ifile --> $fl \n";
#
open(TBX,"< $ifile") || die("### CANNOT OPEN FILE $ifile $!");
my $prt = 0;
while (<TBX>) {
    $prt && do { print STDOUT $_ };
    $_ =~ /^Sequences producing High-scoring Segment Pairs:/io && do {
        $prt = 1;
        &prthead($fl);
        print STDOUT $_;
    };
}; # while TBX
close(TBX);
exit(0);
#
sub prthead() {
    my $query = shift;
    print STDOUT <<"+++EOT+++" 
TBLASTX 2.0MP-WashU [13-Dec-2000] [decunix4.0-ev5-L64 09:44:13 06-Sep-2001]

Copyright (C) 1996-2000 Washington University, Saint Louis, Missouri USA.
All Rights Reserved.

Reference:  Gish, W. (1996-2000) http://blast.wustl.edu

Notice:  statistical significance is estimated under the assumption that the
equivalent of one entire reading frame of the query sequence and one entire
reading frame of the database code for protein and that significant alignments
will only involve coding reading frames.

Query=  $query
        (100,300 letters)

  Translating both strands of query sequence in all 6 reading frames

Database:  MGSCv3Asm
           27,280 sequences; 2,735,012,454 total letters.
Searching....10....20....30....40....50....60....70....80....90....100% done

                                                                     Smallest
                                                                       Sum
                                                     Reading  High  Probability
+++EOT+++
} # prthead
      ' $IDIR/$m > $IDIR/$m.tmp ;
      mv -v $IDIR/$m.tmp $IDIR/$m ;
    } ;
  done ; 
echo "### BAD TBLASTX FILE HEADERS FOUND FOR $errsfound FILES..." ;
#
@

<<HIDE: Global: >>=
perl -e ' # making directories for chrs.... (OBSOLETE)
  use strict;
  use global qw( :ExitStatus );
  my %chr = ();
  my ($idir,$ifile) = @ARGV;
  $idir =~ s%/$%%o;
  open(FI,"< $ifile");
  while (<FI>) {
      my @l;
      next if /^[#>]/o;
      next if /^\s*$/o;
      s/^\s*//o;
      @l = split /\s+/o, $_, 2;
      $chr{$l[0]} .= $l[1];
  };
  close(FI);

  my @dirs = qw( annotation fasta masking tblastx geneid sgp );
  foreach my $l (keys %chr) {
      my $odir = "$idir/chr$l";
      &check_dirs($odir,$l) || next;
      foreach my $pd (@dirs) {
          &check_dirs("$odir/$pd",$l);
      };
      open(FO,"> $odir/seqid_list");
      print FO $chr{$l};
      close(FO);
  };

  exit(0);

  sub check_dirs() {
      my ($odir,$chr) = @_;
      ( -e $odir && -d _ ) || do {
          print STDERR "# Making chr $chr directory: $odir\n";
          (mkdir $odir) || do {
              print STDERR "# Error making directory \"$odir\" ".
                           "for chr $chr : SKIPPING !!!\n";
              return 0;
          };
          return 1;
      };
      print STDERR "# Directory \"$odir\" for chr $chr ALREADY EXIST...\n".
      return 1;
  } # check_dirs
' $HUMUS $HUMUS/seqid_list ;
#
@ 

\subsctn{Sequence analysis: \textit{H.sapiens}}

<<HIDE: >>=
#
# NOT filtering overlapping genes (gp2gff '--no-overlap' option)...
#
### 679 genes for chr22 were found in 
    "/seq/genomes/H.sapiens/golden_path_20010806/database/ensGene.txt".
### 816 genes for chr22 were found in 
    "/seq/genomes/H.sapiens/golden_path_20010806/database/genscan.txt".
### 343 genes for chr22 were found in 
    "/seq/genomes/H.sapiens/golden_path_20010806/database/refGene.txt".
#
# Filtering overlapping genes (gp2gff '--no-overlap' option)...
#
### 575 genes for chr22 were found in 
    "/seq/genomes/H.sapiens/golden_path_20010806/database/ensGene.txt".
### 816 genes for chr22 were found in 
    "/seq/genomes/H.sapiens/golden_path_20010806/database/genscan.txt".
### 318 genes for chr22 were found in 
    "/seq/genomes/H.sapiens/golden_path_20010806/database/refGene.txt".
@
 
<<STEPS(Sequence Analysis): INITIALIZE>>=
####>#########>#######################<########################################<#
#># STEP_ID   HSAP_GP_INITIALIZE
#># STEP_DESC Preparing files for current chromosome.
#># STEP_PATH .
#># STEP_XID  $<JOB{.}{JOB_XID}>
#># STEP_IDIR $HUMUS
#># STEP_ODIR $JOBDIR
#># STEP_EDIR $JOBDIR
#># STEP_CODE   --------------------------------------------------------------#<#
CheckFile R $IDIR/seqid_list ;
gawk 'BEGIN{ chrom="\^"ARGV[1]"\$"; ARGV[1]=""; }
      $1 ~ chrom { print $0; }
     ' $CHR $IDIR/seqid_list > $ODIR/desc || TheEnd GAWKKO ;
gawk '{ print $2, $3; }' $ODIR/desc > $ODIR/length || TheEnd GAWKKO ;
gawk 'BEGIN{ OFS="\t"; ofile=ARGV[1]; s="Sequence"; d="." }
      { print $1,s,s,1,$2,d,d,d,1 > ofile"."$1".gff"; }
     ' $ODIR/length || TheEnd GAWKKO ;
#
#># END_OF_STEP --------------------------------------------------------------#<#
@

\subsubsctn{Retrieving annotations from Golden Path}

<<STEPS(Sequence Analysis): REFSEQ>>=
####>#########>#######################<########################################<#
#># STEP_ID   HSAP_GP_REFSEQ
#># STEP_DESC Retrieving RefSeq annotated genes for current 
#>#         : H. sapiens Golden Path sequence.
#># STEP_PATH refseq
#># STEP_XID  $<JOB{.}{JOB_XID}>
#># STEP_IDIR $HSAP/database
#># STEP_ODIR $JOBDIR/$<STEP{.}{.}{STEP_PATH}>
#># STEP_EDIR $JOBDIR/$<STEP{.}{.}{STEP_PATH}>
#># STEP_CODE   --------------------------------------------------------------#<#
#
#<# IDIR="$HSAP/database" ;
#<# ODIR="$HUMUS/$NCHR/annotation/$HSAPID/refseq" ;
#<# MkDirs $ODIR $EDIR ;
CheckFile R $IDIR/refGene.txt ;
# ALL features
$BIN/gp2gff.pl --exonori-nuclfix 1 -- \
               $SEQ refseq $IDIR/refGene.txt \
             > $ODIR/$SEQ.fullgff 2> $EDIR/$SEQ.report ;
gawk '$3~/^(Single|First|Internal|Terminal)$/ {print $0}' \
               $ODIR/$SEQ.fullgff > $ODIR/$SEQ.gff || TheEnd GAWKKO ;
# Avoiding overlap hack for evaluation program...
$BIN/gp2gff.pl --no-overlap --exonori-nuclfix 1 -- \
               $SEQ refseq $IDIR/refGene.txt \
             > $ODIR/$SEQ.eval.fullgff 2> $EDIR/$SEQ.eval.report ;
gawk '$3~/^(Single|First|Internal|Terminal)$/ {print $0}' \
               $ODIR/$SEQ.eval.fullgff > $ODIR/$SEQ.eval.gff || TheEnd GAWKKO ;
$BIN/gffsplitstrand.pl -l $<STEP{.}{HSAP_GP_INITIALIZE}{STEP_ODIR}>/length.$SEQ.gff \
                       $ODIR/$SEQ.eval.gff ;
#
#># END_OF_STEP --------------------------------------------------------------#<#
@ 

<<STEPS(Sequence Analysis): ENSEMBL>>=
####>#########>#######################<########################################<#
#># STEP_ID   HSAP_GP_ENSEMBL
#># STEP_DESC Retrieving Ensembl annotated genes for current 
#>#         : H. sapiens Golden Path sequence.
#># STEP_PATH ensembl
#># STEP_XID  $<JOB{.}{JOB_XID}>
#># STEP_IDIR $HSAP/database
#># STEP_ODIR $JOBDIR/$<STEP{.}{.}{STEP_PATH}>
#># STEP_EDIR $JOBDIR/$<STEP{.}{.}{STEP_PATH}>
#># STEP_CODE   --------------------------------------------------------------#<#
#
#<# IDIR="$HSAP/database" ;
#<# ODIR="$HUMUS/$NCHR/annotation/$HSAPID" ;
#<# MkDirs $ODIR $EDIR ;
CheckFile R $IDIR/ensGene.txt ;
# ALL features
$BIN/gp2gff.pl --exonori-nuclfix 1 -- \
               $SEQ ensembl $IDIR/ensGene.txt \
             > $ODIR/$SEQ.fullgff 2> $EDIR/$SEQ.report ;
gawk '$3~/^(Single|First|Internal|Terminal)$/ {print $0}' \
               $ODIR/$SEQ.fullgff > $ODIR/$SEQ.gff || TheEnd GAWKKO ;
# Avoiding overlap hack for evaluation program...
$BIN/gp2gff.pl --no-overlap --exonori-nuclfix 1 -- \
               $SEQ ensembl $IDIR/ensGene.txt \
             > $ODIR/$SEQ.eval.fullgff 2> $EDIR/$SEQ.eval.report ;
gawk '$3~/^(Single|First|Internal|Terminal)$/ {print $0}' \
               $ODIR/$SEQ.eval.fullgff > $ODIR/$SEQ.eval.gff || TheEnd GAWKKO ;
$BIN/gffsplitstrand.pl -l $<STEP{.}{HSAP_GP_INITIALIZE}{STEP_ODIR}>/length.$SEQ.gff \
                       $ODIR/$SEQ.eval.gff ;
#
#># END_OF_STEP --------------------------------------------------------------#<#
@ 

\chklst{
\item Annotations for {\refseq} and {\ens} genes.
}


\subsubsctn{Preparing annotation files for evaluation}

<<Sequence: >>=
#
# TO BE redefined................ include frame0-mapping too
function pre_eval {
  gawk 'BEGIN{
          src = ARGV[1]; len = ARGV[2]; ARGV[1] = ARGV[2] = ""; 
          print "chr22\t"src"\tsequence\t1\t"len"\t.\t.\t."
       }' $n $lenaug > $TDIR/${HSAPIDaug}_seqlength.gff ;
  sort +3n -5 $TDIR/${HSAPIDaug}_$n.gff > $TDIR/${HSAPIDaug}.tmp ;
  cat $TDIR/${HSAPIDaug}_seqlength.gff > $TDIR/${HSAPIDaug}_${n}_fwd.gff ;
  gawk '$7 == "+" {print $0}' $TDIR/${HSAPIDaug}.tmp \
                           >> $TDIR/${HSAPIDaug}_${n}_fwd.gff ;
  cat $TDIR/${HSAPIDaug}_seqlength.gff > $TDIR/${HSAPIDaug}_${n}_rev.gff ;
  gawk '$7 == "-" {print $0}' $TDIR/${HSAPIDaug}.tmp \
                           >> $TDIR/${HSAPIDaug}_${n}_rev.gff ;
  /bin/rm -v $TDIR/${HSAPIDaug}.tmp ;
} ;
#
@ 

\chklst{
\item Evaluation files for {\refseq} and {\ens} genes: SR projection of features when mapping all frames to 0, and forward/reverse selection of non-overlapping genes.
}


\subsubsctn{Retrieving gaps and masked regions from annotated sequences}

<<STEPS(Sequence Analysis): ASSEMBLY GAPS>>=
####>#########>#######################<########################################<#
#># STEP_ID   HSAP_GP_ASSEMBLY_GAPS
#># STEP_DESC Retrieving assembly gaps coords for current 
#>#         : H. sapiens Golden Path sequence (masked with N's).
#># STEP_PATH gaps
#># STEP_XID  $<JOB{.}{JOB_XID}>
#># STEP_IDIR $HSAP/database
#># STEP_ODIR $JOBDIR/$<STEP{.}{.}{STEP_PATH}>
#># STEP_EDIR $JOBDIR/$<STEP{.}{.}{STEP_PATH}>
#># STEP_CODE   --------------------------------------------------------------#<#
#
#<# IDIR="$HSAP/database" ;
#<# ODIR="$HUMUS/$NCHR/annotation/$HSAPID/gaps" ;
#<# MkDirs $ODIR ;
CheckFile R $IDIR/${SEQ}_gap.txt ;
perl -e '
  ($seq,$ori,$end,$char,$size,$type) = (1,2,3,5,6,7);
  $n = 1;
  while (<STDIN>) {
      next if /^#/o;
      next if /^\s*$/o;
      chomp;
      @l = split /\s+/og, $_;
      defined($l[$type]) || ($l[$type] = "gap");
      print STDOUT join("\t", $l[$seq],"sequence","gap",
                              @l[$ori,$end],".",".",".",
            $l[$type].".".($n++)." # $l[$type]\: $l[$size]bp ($l[$char])\n");
  }; # while   
  ' < $IDIR/${SEQ}_gap.txt \
    > $ODIR/${SEQ}.gff || TheEnd PERLKO ;
#
#># END_OF_STEP --------------------------------------------------------------#<#
@

<<STEPS(Sequence Analysis): ORIGINAL MASKING>>=
####>#########>#######################<########################################<#
#># STEP_ID   HSAP_GP_ORI_MASKED
#># STEP_DESC Retrieving masked regions coords for current H. sapiens Golden
#>#         : Path sequence (original masking of repetitive regions).
#># STEP_PATH repeats
#># STEP_XID  $<JOB{.}{JOB_XID}>
#># STEP_IDIR $HSAP/database
#># STEP_ODIR $JOBDIR/$<STEP{.}{.}{STEP_PATH}>
#># STEP_EDIR $JOBDIR/$<STEP{.}{.}{STEP_PATH}>
#># STEP_CODE   --------------------------------------------------------------#<#
#
#<# IDIR="$HSAP/database" ;
#<# ODIR="$HUMUS/$NCHR/annotation/$HSAPID/repeats" ;
#<# MkDirs $ODIR ;
CheckFile R $IDIR/${SEQ}_rmsk.txt ;
perl -e '
  ($sco,$seq,$ori,$end,$str,$name,$class,$fam) = (1,5,6,7,9,10,11,12);
  $n = 1;
  while (<STDIN>) {
      next if /^#/o;
      next if /^\s*$/o;
      chomp;
      @l = split /\s+/og, $_;
      print STDOUT join("\t", $l[$seq],"repeatmasker","repeat",
                              @l[$ori,$end,$sco,$str],".",
                              $l[$class].".".($n++))." # @l[$name,$fam]\n";
  }; # while 
  ' < $IDIR/${SEQ}_rmsk.txt \
    > $ODIR/${SEQ}.gff || TheEnd PERLKO ;
#
#># END_OF_STEP --------------------------------------------------------------#<#
@

\subsubsctn{Retrieving gene prediction results from Golden Path ({\gnsc})}

<<STEPS(Sequence Analysis): GENSCAN>>=
####>#########>#######################<########################################<#
#># STEP_ID   HSAP_GP_GENSCAN
#># STEP_DESC Retrieving genscan predicted genes for current 
#>#         : H. sapiens Golden Path sequence.
#># STEP_PATH genscan
#># STEP_XID  $<JOB{.}{JOB_XID}>
#># STEP_IDIR $HSAP/database
#># STEP_ODIR $JOBDIR/$<STEP{.}{.}{STEP_PATH}>
#># STEP_EDIR $JOBDIR/$<STEP{.}{.}{STEP_PATH}>
#># STEP_CODE   --------------------------------------------------------------#<#
#
#<# IDIR="$HSAP/database" ;
#<# ODIR="$HUMUS/$NCHR/annotation/$HSAPID/genscan" ;
#<# MkDirs $ODIR ;
CheckFile R $IDIR/genscan.txt ;
# ALL features
$BIN/gp2gff.pl --exonori-nuclfix 1 -- \
               $SEQ genscan $IDIR/genscan.txt \
             > $ODIR/$SEQ.fullgff 2> $EDIR/$SEQ.report ;
gawk '$3~/^(Single|First|Internal|Terminal)$/ {print $0}' \
               $ODIR/$SEQ.fullgff > $ODIR/$SEQ.gff || TheEnd GAWKKO ;
#
#># END_OF_STEP --------------------------------------------------------------#<#
@ 

\chklst{
\item Annotations for {\gnsc} genes.
}


\subsubsctn{Evaluating {\gnsc} results from Golden Path versus annotation}

<<STEPS(Sequence Analysis): Evaluating genscan results>>=
####>#########>#######################<########################################<#
#># STEP_ID   HSAP_GP_GENSCAN_EVAL
#># STEP_DESC Evaluation of genscan predictions as they were provided
#>#         : accompanying H. sapiens Golden Path sequence.
#># STEP_PATH eval
#># STEP_XID  $<JOB{.}{JOB_XID}>
#># STEP_IDIR $JOBDIR/$<STEP{.}{HSAP_GP_GENSCAN}{STEP_PATH}>
#># STEP_ODIR $JOBDIR/$<STEP{.}{HSAP_GP_GENSCAN}{STEP_PATH}>/$<STEP{.}{.}{STEP_PATH}>
#># STEP_EDIR $JOBDIR/$<STEP{.}{HSAP_GP_GENSCAN}{STEP_PATH}>/$<STEP{.}{.}{STEP_PATH}>
#># STEP_CODE   --------------------------------------------------------------#<#
#
# Avoiding overlap hack for evaluation program...
IFILE="$<STEP{.}{HSAP_GP_GENSCAN}{STEP_IDIR}>/genscan.txt" ;
CheckFile R $IFILE ;
$BIN/gp2gff.pl --no-overlap --exonori-nuclfix 1 -- \
               $SEQ genscan $IFILE \
             > $ODIR/$SEQ.eval.fullgff 2> $EDIR/$SEQ.eval.report ;
gawk '$3~/^(Single|First|Internal|Terminal)$/ {print $0}' \
               $ODIR/$SEQ.eval.fullgff > $ODIR/$SEQ.eval.gff || TheEnd GAWKKO ;
$BIN/gffsplitstrand.pl $ODIR/$SEQ.eval.gff ; # no sequence length record required here
#
A_REFSEQ="$CHRDIR/$<JOB{HSAP_GP_ANNOTATION}{JOB_PATH}>/$<JOB{HSAP_GP_ANNOTATION}{JOB_XID}>/$<STEP{HSAP_GP_ANNOTATION}{HSAP_GP_REFSEQ}{STEP_PATH}>/$SEQ.eval" ;
A_ENSEMBL="$CHRDIR/$<JOB{HSAP_GP_ANNOTATION}{JOB_PATH}>/$<JOB{HSAP_GP_ANNOTATION}{JOB_XID}>/$<STEP{HSAP_GP_ANNOTATION}{HSAP_GP_ENSEMBL}{STEP_PATH}>/$SEQ.eval" ;
cat > $ODIR/${SEQ}.summary <<EOT ;
#
# Evaluation summary results for genscan on CHROM[$CHR] - SEQ[$SEQ]
#
EOT
#
CheckFile R $A_REFSEQ.fwd.gff  $A_REFSEQ.rev.gff  \
            $A_ENSEMBL.fwd.gff $A_ENSEMBL.rev.gff ;
#
$BIN/runeval.pl $A_REFSEQ.fwd.gff $ODIR/$SEQ.eval.fwd.gff                      \
           "${CHR}::${HSAPID}x${MMUSID}::REFSEQ::FWD::GENSCAN::genscan_GP::."  \
           >> $ODIR/${SEQ}.summary 2> $ODIR/${SEQ}.genscan_refseq.fwd ;
$BIN/runeval.pl $A_REFSEQ.rev.gff $ODIR/$SEQ.eval.rev.gff                      \
           "${CHR}::${HSAPID}x${MMUSID}::REFSEQ::REV::GENSCAN::genscan_GP::."  \
           >> $ODIR/${SEQ}.summary 2> $ODIR/${SEQ}.genscan_refseq.rev ;
$BIN/runeval.pl $A_ENSEMBL.fwd.gff $ODIR/$SEQ.eval.fwd.gff                     \
           "${CHR}::${HSAPID}x${MMUSID}::ENSEMBL::FWD::GENSCAN::genscan_GP::." \
            >> $ODIR/${SEQ}.summary 2> $ODIR/${SEQ}.genscan_ensembl.fwd ;
$BIN/runeval.pl $A_ENSEMBL.rev.gff $ODIR/$SEQ.eval.rev.gff                     \
           "${CHR}::${HSAPID}x${MMUSID}::ENSEMBL::REV::GENSCAN::genscan_GP::." \
           >> $ODIR/${SEQ}.summary 2> $ODIR/${SEQ}.genscan_ensembl.rev ;
#
#># END_OF_STEP --------------------------------------------------------------#<#
@ 

\chklst{
\item Evaluation records (extended and brief) for each seq and for each chromosome.
\item ...
}


\subsctn{Sequence analysis: \textit{M.musculus}}

<<Sequence: M.musculus>>=
#
# 
#
MMUS="/seq/genomes/M.musculus/sanger_phusion_20011109" ;
MMUSID="20011109"
ODIR="" ;
#
#

@ 

\chklst{
\item ...
}


\newpage %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\sctn{Masking sequences} %%%%%%%%%%%%%%%%%%%%%%

\begin{center}
% \fbox{
  \begin{minipage}{0.95\linewidth}
   \textbf{What to do here:}
   \begin{itemize}
    \item Human genome assembly from UCSC Golden Path August release (20010806).
    \item Pankaj run {\rptm} with the following parameters:\\[-3ex]
\begin{small}
\begin{verbatim}
###
I used the masked sequence from UCSC and masked it again. I used -s
"slow" option. We actually used RepeatBlaster and not Repeatmasker. RB
is faster version of RM that uses Blast instead of crossmatch.
\end{verbatim}
\end{small}
   \end{itemize}
  \end{minipage}
% } % fbox
\end{center}


\newpage %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\sctn{Gene Prediction: {\gnid}} %%%%%%%%%%%%%%%%%%%%%%

\whtlst{
\item Run {\gnid} without homology, then evaluate results.
\item Remember to run [[/usr/local/share/molbio/sgp/src/geneid_v1.1]] (formerly located at [[/projects/sgp/src/geneid_v1.1]]).
\item ...
}

<<JOBheader: Running GENEID standard>>=
####>#########>#######################<########################################<#
#># JOB_ID    GENEID_STD
#># JOB_DESC  Running "geneid" on unmasked H.sapiens UCSC Golden Path 
#>#        :  assembly sequences.
#># JOB_PATH  geneid
#># JOB_XID   $HSAPID
#># JOB_FILE  ${LIBSTEP}/geneid.job
#># END_OF_JOB ##################################################################
@ 

<<JOBS: Running GENEID standard>>=
<<STEPS(geneid): Initialization>>
<<STEPS(geneid std): Running geneid on raw sequences>>
<<STEPS(geneid std): Processing geneid output>>
<<STEPS(geneid std): Evaluating geneid results>>
@ 

\subsctn{Initialization}

<<STEPS(geneid): Initialization>>=
####>#########>#######################<########################################<#
#># STEP_ID   GENEID_INITIALIZE
#># STEP_DESC Preparing subdirectories for geneid results.
#># STEP_PATH .
#># STEP_XID  $<JOB{.}{JOB_XID}>
#># STEP_IDIR .
#># STEP_ODIR $JOBDIR
#># STEP_EDIR $JOBDIR
#># STEP_CODE   --------------------------------------------------------------#<
#
#<# ODIR="$HUMUS/$NCHR/geneid/$XID" ; MkDirs $ODIR ;
#
( for c in out gff gtf2 cds prot logs tmp ;
    do {
      MkDirs $ODIR/$c ;
      } ;
    done ) || TheEnd BASHKO ;
#
#># END_OF_STEP --------------------------------------------------------------#<#
@

\subsubsctn{Running {\gnid} (without homology)}


<<STEPS(geneid std): Running geneid on raw sequences>>=
####>#########>#######################<########################################<#
#># STEP_ID   RUNNING_GENEID
#># STEP_DESC Running geneid (without homology) on Hsapiens sequences from
#>#         : Golden Path assembly.
#># STEP_PATH out
#># STEP_XID  $<JOB{.}{JOB_XID}>
#># STEP_IDIR $HUMUS/$NCHR/$<JOB{.}{JOB_PATH}>/$XID
#># STEP_ODIR $JOBDIR/$<STEP{.}{.}{STEP_PATH}>
#># STEP_EDIR $JOBDIR/logs
#># STEP_CODE   --------------------------------------------------------------#<#
#<# 
GENEID="$SRC/geneid_v1.1/bin/geneid" ; # geneid v1.1
PARAM="$SRC/geneid_v1.1/param/human3iso.param" ;
EW=0 ; # add to exon weigth
#
#<# ISEQ="$HSAP/chromFaMasked/$CHRNUM/$SEQ.fa.masked" ; 
#<# IDIR="$HUMUS/$NCHR/geneid/$XID/" ;
#<# ODIR="$HUMUS/$NCHR/geneid/$XID/out" ;
#--> we do not run geneid on masked sequences at this moment
#--> we are using original un-masked fasta sequences from GP
ISEQ="$HSEQ/$SEQ.fa" ; # this must be changed to masked fasta files
#
CheckFile R $PARAM $ISEQ ;
#
GENEID_CMDLN="-v -DE $EW -P $PARAM $ISEQ" ;
echo "$GENEID $GENEID_CMDLN 2> $EDIR/$SEQ.geneid" 1>&2 ;
( $GENEID $GENEID_CMDLN 2> $EDIR/$SEQ.geneid || TheEnd CKO ) \
           | grep -v 'evidence' > $ODIR/$SEQ ;
#
( cat $EDIR/$SEQ.geneid 1>&2 ) || TheEnd CMDKO ;
#
#># END_OF_STEP --------------------------------------------------------------#<#
@ 

\chklst{
\item ...
}

\subsubsctn{Processing output for {\gnid} (without homology)}

<<STEPS(geneid std): Processing geneid output>>=
####>#########>#######################<########################################<#
#># STEP_ID   GENEID_OUTPUT
#># STEP_DESC Processing geneid format from geneid output (without homology).
#># STEP_PATH gff
#># STEP_XID  $<JOB{.}{JOB_XID}>
#># STEP_IDIR $HUMUS/$NCHR/$<JOB{.}{JOB_PATH}>/$XID
#># STEP_ODIR $JOBDIR/$<STEP{.}{.}{STEP_PATH}>
#># STEP_EDIR $JOBDIR/$<STEP{.}{.}{STEP_PATH}>
#># STEP_CODE   --------------------------------------------------------------#<#
#
#<# IDIR="$HUMUS/$NCHR/geneid/$XID" ;
#
CheckFile R $IDIR/out/$SEQ ;
#
$BIN/geneid_raw2GFF.pl $SEQ $IDIR $IDIR/out/$SEQ ;
#
( ls -1 $IDIR/gff/$SEQ.sg/ | egrep "^$SEQ" | \
    while read n;
      do {
        cat $IDIR/gff/$SEQ.sg/$n;
        };
      done | sort +3n +4n -5 - > $IDIR/gff/$SEQ ) || TheEnd BASHKO ;
#
get_geneid_genes $IDIR/gff/$SEQ > $IDIR/$SEQ.gene_list || TheEnd FUNCKO ;
#
#># END_OF_STEP --------------------------------------------------------------#<#
@
%$

\chklst{
\item Number of genes, average length, average exon number, exon/intron length ratio...
\item ...
}

\subsubsctn{Evaluation of {\gnid} predictions (without homology)}

<<STEPS(geneid std): Evaluating geneid results>>=
####>#########>#######################<########################################<#
#># STEP_ID   GENEID_EVALUATION
#># STEP_DESC Evaluation of geneid predictions (without homology).
#># STEP_PATH eval
#># STEP_XID  $<JOB{.}{JOB_XID}>
#># STEP_IDIR $JOBDIR/$<STEP{.}{GENEID_OUTPUT}{STEP_PATH}>
#># STEP_ODIR $JOBDIR/$<STEP{.}{.}{STEP_PATH}>
#># STEP_EDIR $JOBDIR/$<STEP{.}{.}{STEP_PATH}>
#># STEP_CODE   --------------------------------------------------------------#<#
#
#<# IDIR="$HUMUS/$NCHR/geneid/$XID" ;
CheckFile R $IDIR/$SEQ ;
gawk '$3~/^(Single|First|Internal|Terminal)$/ {print $0}' \
               $IDIR/$SEQ > $ODIR/$SEQ.eval.gff || TheEnd GAWKKO ;
$BIN/gffsplitstrand.pl $ODIR/$SEQ.eval.gff ; # no sequence length record required here
#
A_REFSEQ="$CHRDIR/$<JOB{HSAP_GP_ANNOTATION}{JOB_PATH}>/$<JOB{HSAP_GP_ANNOTATION}{JOB_XID}>/$<STEP{HSAP_GP_ANNOTATION}{HSAP_GP_REFSEQ}{STEP_PATH}>/$SEQ.eval" ;
A_ENSEMBL="$CHRDIR/$<JOB{HSAP_GP_ANNOTATION}{JOB_PATH}>/$<JOB{HSAP_GP_ANNOTATION}{JOB_XID}>/$<STEP{HSAP_GP_ANNOTATION}{HSAP_GP_ENSEMBL}{STEP_PATH}>/$SEQ.eval" ;
cat > $ODIR/${SEQ}.summary <<EOT ;
#
# Evaluation summary results for geneid on CHROM[$CHR] - SEQ[$SEQ]
#
EOT
#
CheckFile R $A_REFSEQ.fwd.gff  $A_REFSEQ.rev.gff  \
            $A_ENSEMBL.fwd.gff $A_ENSEMBL.rev.gff ;
#
$BIN/runeval.pl $A_REFSEQ.fwd.gff $ODIR/$SEQ.eval.fwd.gff      \
    "${CHR}::${HSAPID}x${MMUSID}::REFSEQ::FWD::GENEID::1.1::." \
    >> $ODIR/${SEQ}.summary 2> $ODIR/${SEQ}.geneid_refseq.fwd ;
$BIN/runeval.pl $A_REFSEQ.rev.gff $ODIR/$SEQ.eval.rev.gff      \
    "${CHR}::${HSAPID}x${MMUSID}::REFSEQ::REV::GENEID::1.1::." \
    >> $ODIR/${SEQ}.summary 2> $ODIR/${SEQ}.geneid_refseq.rev ;
$BIN/runeval.pl $A_ENSEMBL.fwd.gff $ODIR/$SEQ.eval.fwd.gff      \
    "${CHR}::${HSAPID}x${MMUSID}::ENSEMBL::FWD::GENEID::1.1::." \
    >> $ODIR/${SEQ}.summary 2> $ODIR/${SEQ}.geneid_ensembl.fwd ;
$BIN/runeval.pl $A_ENSEMBL.rev.gff $ODIR/$SEQ.eval.rev.gff      \
    "${CHR}::${HSAPID}x${MMUSID}::ENSEMBL::REV::GENEID::1.1::." \
    >> $ODIR/${SEQ}.summary 2> $ODIR/${SEQ}.geneid_ensembl.rev ;
#
#># END_OF_STEP --------------------------------------------------------------#<#
@

\chklst{
\item ...
}


\newpage %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\sctn{Processing {\tbx} results from human and mouse genome comparison} %%%%%%

\begin{comment}
Ensembl:
	http://www.ensembl.org/Homo_sapiens/
	http://www.ensembl.org/Mus_musculus/
Ensembl mouse assembly v1.0
Sanger Institute Phusion Nov 6 Assembly
Whitehead Arachne Oct 26 Assembly
\end{comment}
\begin{center}
% \fbox{
  \begin{minipage}{0.95\linewidth}
   \textbf{What to do here:}
   \begin{itemize}
 \item Process {\tbx} results from Pankaj:
  \begin{itemize}
   \item Human genome assembly from UCSC Golden Path August release (20010806).
   \item Mouse genome assembly from Mouse Genome Sequencing Consortium v3 assembly (20020411).\\[-3ex]
\begin{verbatim}
########################################### UPDATE THIS....
# Database:  /bioinfo/gapdb/blastdb/MusPhusion
# Title:  MusPhusion
# # of letters in database:  2,374,690,634  (Z = 3000000000)
# # of sequences in database:  431,480
# Format:  XDF-1
# Created:  5:32:13 PM EST Dec 10, 2001
# Posted:  5:32:14 PM EST Dec 10, 2001
\end{verbatim}
   \item {\tbx} was run with the following parameters:\\[-3ex]
%	   \begin{center}
%	   \begin{minipage}[c]{0.75\linewidth}
\begin{verbatim}
########################################### UPDATE THIS....
W=5  Z=3000000000
matrix=blosum62mod  filter=xnu+seg
nogaps  hspmax=500  topcomboN=100
B=9000  V=9000  E=0.01  E2=0.01  S2=80
warnings  cpus=4  ctxfactor=36.0
\end{verbatim}
% tail -54 ori/chr22_* | sort | uniq -c | sort +0nr | more
%	   \end{minipage}
%	   \end{center}
  \end{itemize}
\item Get HSPs $\Rightarrow$ SRs $\Rightarrow$ HSP-SRs
   \end{itemize}
  \end{minipage}
% } % fbox
 \end{center}


<<JOBheader: HsapGPa x MGSCv3 WUTBLASTX>>=
####>#########>#######################<########################################<#
#># JOB_ID    HSAPgpa_MGSCv3_WUTBLASTX
#># JOB_DESC  Homology search by WU-TBLASTX for H.sapiens UCSC Golden Path 
#>#        :  assembly against Mouse Genome Sequencing Consortium assembly, 
#>#        :  from now on MGSC, 20020411-v3
#>#        :  (TBLASTX results obtained by Pankaj Agarwal,  
#>#        :   last update was apr 25, 2002, downladed from GSBP).
#># JOB_PATH  tblastx
#># JOB_XID   $FTPTBXID
#># JOB_FILE  ${LIBSTEP}/tblastx.job
#># END_OF_JOB ##################################################################
@ 

<<JOBS: HsapGPa x MGSCv3 WUTBLASTX>>=
<<STEPS(HsGPa*MGSCv3a WUTBLASTX): retrieve blast output>>
<<STEPS(HsGPa*MGSCv3a WUTBLASTX): parsing blast output>>
<<STEPS(HsGPa*MGSCv3a WUTBLASTX): project HSPs into SRs>>
<<STEPS(HsGPa*MGSCv3a WUTBLASTX): evaluating SRs>>
@ 

\subsctn{Initialization} %%%%%%%%%%%%%%%%%%%%%%

\subsctn{Unpacking {\tbx} results obtained by Pankaj}

<<STEPS(HsGPa*MGSCv3a WUTBLASTX): retrieve blast output>>=
####>#########>#######################<########################################<#
#># STEP_ID   TBLASTX_OUTPUT
#># STEP_DESC Unpacking TBLASTX results obtained by Pankaj Agarwal
#>#         : (Hsapiens GP assembly against MGSC v3 assembly).
#># STEP_PATH ori
#># STEP_XID  $<JOB{.}{JOB_XID}>
#># STEP_IDIR $FTPTBX
#># STEP_ODIR $JOBDIR/$<STEP{.}{.}{STEP_PATH}>
#># STEP_EDIR $JOBDIR/$<STEP{.}{.}{STEP_PATH}>
#># STEP_CODE   --------------------------------------------------------------#<#
#
#<# IDIR="$HUMUS/.ftp/PankajAgarwal/20020111.tbxPhusion" ;
#<# IDIR="$HUMUS/.ftp/PankajAgarwal/20020111.tbxPhusion" ;
#<# ODIR="$HUMUS/$NCHR/tblastx/$XID/ori" ;
#<# MkDirs $ODIR ;
MkDirs $ODIR/$SEQ ;
( mega "cp -v" $IDIR '^'$SEQ'_[0-9]' $ODIR/$SEQ 1>&2 ) || TheEnd FUNCKO ;
# exit status has been implemented on sbp_checkblastout.pl
$BIN/sbp_checkblastout.pl $SEQ $ODIR/$SEQ > $ODIR/$SEQ.report ; 
#
#># END_OF_STEP --------------------------------------------------------------#<#
@ 

\chklst{
\item get number of sequences from DB matching each chromosome fragment.
\item do the regions without HSPs correspond to N regions at original sequences (being gaps or masked) ? (maybe using [[evaluation]])
}

\subsctn{Retrieving {\tbx} results by chromosome}

\begin{figure}[!t]
\begin{center}
 \input psfigures/blast_frames.tex
\end{center}
\end{figure}

We had to deal with the frame issue of the HSPs fragments; once the HSP coords were mapped to the chromosome, frames also must be recomputed taking into account if HSP was in forward or in reverse strand (see figure~\ref{fig:blastframes}).

<<STEPS(HsGPa*MGSCv3a WUTBLASTX): parsing blast output>>=
####>#########>#######################<########################################<#
#># STEP_ID   PARSING_TBLASTX
#># STEP_DESC Retrieving HSPs from raw TBLASTX output
#>#         : (Hsapiens GP assembly against MGSC v3 assembly).
#># STEP_PATH hsp
#># STEP_XID  $<JOB{.}{JOB_XID}>
#># STEP_IDIR $JOBDIR/$<STEP{.}{TBLASTX_OUTPUT}{STEP_PATH}>
#># STEP_ODIR $JOBDIR/$<STEP{.}{.}{STEP_PATH}>
#># STEP_EDIR $JOBDIR/$<STEP{.}{.}{STEP_PATH}>
#># STEP_CODE   --------------------------------------------------------------#<#
#
#<# IDIR="$HUMUS/$NCHR/tblastx/$XID/ori" ;
#<# ODIR="$HUMUS/$NCHR/tblastx/$XID/hsp" ;
#<# MkDirs $ODIR ;
#<# LEN="$HUMUS/$NCHR/annotation/$HSAPID/length" ;
LEN="$CHRDIR/$<JOB{HSAP_GP_ANNOTATION}{JOB_PATH}>/$<JOB{HSAP_GP_ANNOTATION}{JOB_XID}>/length" ;
# exit status has been implemented on sbp_blast2gff.pl
/bin/rm -vf $IDIR/$SEQ.parseblast.err 1>&2 ;
$BIN/sbp_blast2gff.pl $SEQ $LEN $IDIR/$SEQ $IDIR/$SEQ.report \
         > $ODIR/$SEQ.fullgff 2> $EDIR/$SEQ.report ;
#
( perl -ne '/^#/o && next;
          /^\s+$/o && next; 
          $_ =~ s/;\s+Strand//o; 
          $_ =~ s/;\s+Frame//o; 
          $_ =~ s/;\s+E_value.*$//o;
          print STDOUT $_;' $ODIR/$SEQ.fullgff | \
          sort +3n -6 +6 -7 - > $ODIR/$SEQ.gff ) || TheEnd PERLKO ;
#
#># END_OF_STEP --------------------------------------------------------------#<#
@ 

\chklst{
\item find number of HSPs per fragment and total per chromosome.
}

\subsubsctn{Projecting HSPs into SRs}

<<STEPS(HsGPa*MGSCv3a WUTBLASTX): project HSPs into SRs>>=
####>#########>#######################<########################################<#
#># STEP_ID   PROJECTING_HSPs
#># STEP_DESC Projecting HSPs into SRs
#>#         : (Hsapiens GP assembly against MGSC v3 assembly).
#># STEP_PATH sr
#># STEP_XID  $<STEP{.}{PARSING_TBLASTX}{STEP_XID}>
#># STEP_IDIR $JOBDIR/$<STEP{.}{PARSING_TBLASTX}{STEP_PATH}>
#># STEP_ODIR $JOBDIR/$<STEP{.}{.}{STEP_PATH}>
#># STEP_EDIR $JOBDIR/$<STEP{.}{.}{STEP_PATH}>
#># STEP_CODE   --------------------------------------------------------------#<#
#
#<# IDIR="$HUMUS/$NCHR/tblastx/$XID/hsp" ;
#<# ODIR="$HUMUS/$NCHR/tblastx/$XID/sr" ;
#<# MkDirs $ODIR ;
CheckFile R $IDIR/$SEQ.gff ;
$BIN/blast2gff -vg $IDIR/$SEQ.gff > $ODIR/$SEQ.gff || TheEnd CKO ;
#
gawk '
  BEGIN{ chr=ARGV[1]; ARGV[1]=""; t=b["+"]=b["-"]=b["."]=0; }
  ($0 !~ /^[ \t]*$/ && $1 !~ /^\#/) { t++; a[$7,$8]++; b[$7]++; c[$8]++ }
  END{ 
    printf "# TOTAL %s SRs on %s: %s forward, %s reverse, %s without strand.\n", 
           t, chr, b["+"], b["-"], b["."];
    for (i in c) {
      printf "#\t%s : %6s\t\|\t%s : %6s\t|\t%s : %6s\n", 
             "+"i, a["+",c[i]] ? a["+",i] : 0,
             "-"i, a["-",c[i]] ? a["-",i] : 0,
             "."i, a[".",c[i]] ? a[".",i] : 0;
    };
  }
' $SEQ $ODIR/$SEQ.gff > $EDIR/$SEQ.report || TheEnd GAWKKO ;
#
#># END_OF_STEP --------------------------------------------------------------#<#
@

\chklst{
\item Get SRs number for each sequence.
\item ...
}

\subsubsctn{Evaluating SRs versus annotation}

<<STEPS(HsGPa*MGSCv3a WUTBLASTX): evaluating SRs>>=
####>#########>#######################<########################################<#
#># STEP_ID   EVALUATING_SRs
#># STEP_DESC Evaluating SRs versus different annotations
#>#         : (Hsapiens GP assembly against MGSC v3 assembly).
#># STEP_PATH eval
#># STEP_XID  $<STEP{.}{PARSING_TBLASTX}{STEP_XID}>
#># STEP_IDIR $JOBDIR/$<STEP{.}{PROJECTING_HSPs}{STEP_PATH}>
#># STEP_ODIR $JOBDIR/$<STEP{.}{.}{STEP_PATH}>
#># STEP_EDIR $JOBDIR/$<STEP{.}{.}{STEP_PATH}>
#># STEP_CODE   --------------------------------------------------------------#<#
#
#<# IDIR="$HUMUS/$NCHR/tblastx/$XID/sr" ;
#<# ODIR="$HUMUS/$NCHR/tblastx/$XID/eval" ;
CheckFile R $IDIR/$SEQ.gff ;
gawk 'BEGIN{ OFS="\t"; }
      ($0 !~ /^[ \t]*$/ && $1 !~ /^\#/ && $3 ~ "SR") { print $0,"1" }' \
               $IDIR/$SEQ.gff > $ODIR/$SEQ.eval.gff || TheEnd GAWKKO ;
$BIN/gffsplitstrand.pl $ODIR/$SEQ.eval.gff ; # no sequence length record required here
#
A_REFSEQ="$CHRDIR/$<JOB{HSAP_GP_ANNOTATION}{JOB_PATH}>/$<JOB{HSAP_GP_ANNOTATION}{JOB_XID}>/$<STEP{HSAP_GP_ANNOTATION}{HSAP_GP_REFSEQ}{STEP_PATH}>/$SEQ.eval" ;
A_ENSEMBL="$CHRDIR/$<JOB{HSAP_GP_ANNOTATION}{JOB_PATH}>/$<JOB{HSAP_GP_ANNOTATION}{JOB_XID}>/$<STEP{HSAP_GP_ANNOTATION}{HSAP_GP_ENSEMBL}{STEP_PATH}>/$SEQ.eval" ;
cat > $ODIR/${SEQ}.summary <<EOT ;
#
# Evaluation summary results for similarity regions on CHROM[$CHR] - SEQ[$SEQ]
#
EOT
#
CheckFile R $A_REFSEQ.fwd.gff  $A_REFSEQ.rev.gff  \
            $A_ENSEMBL.fwd.gff $A_ENSEMBL.rev.gff ;
#
$BIN/runeval.pl $A_REFSEQ.fwd.gff $ODIR/$SEQ.eval.fwd.gff \
    "${CHR}::${HSAPID}x${MMUSID}::REFSEQ::FWD::SRs::.::." \
    >> $ODIR/${SEQ}.summary 2> $ODIR/${SEQ}.sr_refseq.fwd ;
$BIN/runeval.pl $A_REFSEQ.rev.gff $ODIR/$SEQ.eval.rev.gff \
    "${CHR}::${HSAPID}x${MMUSID}::REFSEQ::REV::SRs::.::." \
    >> $ODIR/${SEQ}.summary 2> $ODIR/${SEQ}.sr_refseq.rev ;
$BIN/runeval.pl $A_ENSEMBL.fwd.gff $ODIR/$SEQ.eval.fwd.gff \
    "${CHR}::${HSAPID}x${MMUSID}::ENSEMBL::FWD::SRs::.::." \
    >> $ODIR/${SEQ}.summary 2> $ODIR/${SEQ}.sr_ensembl.fwd ;
$BIN/runeval.pl $A_ENSEMBL.rev.gff $ODIR/$SEQ.eval.rev.gff \
    "${CHR}::${HSAPID}x${MMUSID}::ENSEMBL::REV::SRs::.::." \
    >> $ODIR/${SEQ}.summary 2> $ODIR/${SEQ}.sr_ensembl.rev ;
#
#># END_OF_STEP --------------------------------------------------------------#<#
@

\chklst{
\item Evaluation records (extended and brief) for each seq and for each chromosome.
\item ...
}


\newpage %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\sctn{Gene Prediction: {\sgp} (I)} %%%%%%%%%%%%%%%%%%%%%%

\subsctn{Homology taken from {\mmus} MGSCv3 assembly} %%%%%%%%%%%%%%%%%%%%%%

\whtlst{
\item Re-score similarity regions: SRs to HSP-SRs.
\item Initialize any auxiliarly file (like those [[*.termini]]).
\item Run {\sgp} with homology, then evaluate results.
\item TODO -> Run {\sgp} with homology plus evidences, then evaluate results.
}

<<JOBheader: SGP with HSAPgpa x MGSCv3 homology>>=
####>#########>#######################<########################################<#
#># JOB_ID    SGP_HSAPgpa_MGSCv3_TBX
#># JOB_DESC  Running "SGP" on unmasked H.sapiens UCSC Golden Path 
#>#        :  assembly sequences, using TBLASTX homology results as
#>#        :  homology evidences once they have been projected into SRs.
#># JOB_PATH  sgp
#># JOB_XID   ${HSAPSTR}-${MMUSSTR}
#># JOB_FILE  ${LIBSTEP}/sgp.job
#># END_OF_JOB ##################################################################
@ 

<<JOBS: SGP with HSAPgpa x MGSCv3 homology>>=
<<STEPS(SGP): Initialization>>
<<STEPS(SGP HSAPgpa x MGSCv3): Auxiliarly files>>
<<STEPS(SGP HSAPgpa x MGSCv3): Re-scoring SRs>>
<<STEPS(SGP HSAPgpa x MGSCv3): Running SGP>>
<<STEPS(SGP HSAPgpa x MGSCv3): Processing SGP results>>
<<STEPS(SGP HSAPgpa x MGSCv3): Evaluating SGP results>>
@ 

<<STEPS(SGP): Initialization>>=
####>#########>#######################<########################################<#
#># STEP_ID   SGP_INITIALIZE
#># STEP_DESC Preparing subdirectories for sgp results.
#># STEP_PATH .
#># STEP_XID  $<JOB{.}{JOB_XID}>
#># STEP_IDIR .
#># STEP_ODIR $JOBDIR
#># STEP_EDIR $JOBDIR
#># STEP_CODE   --------------------------------------------------------------#<
#
#<# ODIR="$HUMUS/$NCHR/sgp/$XID" ; MkDirs $ODIR ;
#
( for c in out gff gtf2 cds prot hsp-sr logs tmp ;
    do { 
      MkDirs $ODIR/$c ;
      } ;
    done ) || TheEnd BASHKO ;
#
#># END_OF_STEP --------------------------------------------------------------#<#
@

\subsubsctn{Re-scoring SRs}

<<STEPS(SGP HSAPgpa x MGSCv3): Re-scoring SRs>>=
####>#########>#######################<########################################<#
#># STEP_ID   RE-SCORING_SRs
#># STEP_DESC Re-scoring SRs to produce HSP-SRs
#>#         : (Hsapiens GP assembly against MGSC v3 assembly).
#># STEP_PATH hsp-sr
#># STEP_XID  $<JOB{.}{JOB_XID}>
#># STEP_IDIR $HUMUS/$NCHR/$<JOB{HSAPgpa_MGSCv3_WUTBLASTX}{JOB_PATH}>/$<JOB{HSAPgpa_MGSCv3_WUTBLASTX}{JOB_XID}>/$<JOB{HSAPgpa_MGSCv3_WUTBLASTX}{PROJECTING_HSPs}{STEP_PATH}>
#># STEP_ODIR $JOBDIR/$<STEP{.}{.}{STEP_PATH}>
#># STEP_EDIR $JOBDIR/$<STEP{.}{.}{STEP_PATH}>
#># STEP_CODE   --------------------------------------------------------------#<#
#
#<# IDIR="$HUMUS/$NCHR/$<JOB{HSAPgpa_MGSCv3_WUTBLASTX}{JOB_PATH}>/$XID/sr" ;
#<# ODIR="$HUMUS/$NCHR/sgp/$XID/hsp-sr" ;
#
CheckFile R $IDIR/$SEQ.gff ;
$BIN/getHSPSR.pl $SEQ < $IDIR/$SEQ.gff \
                      > $ODIR/$SEQ.gff 2> $EDIR/$SEQ.report || TheEnd PERLKO ;
#
#># END_OF_STEP --------------------------------------------------------------#<#
@
%$

\chklst{
\item ...
}

\subsubsctn{Preparing auxiliarly files}

<<STEPS(SGP HSAPgpa x MGSCv3): Auxiliarly files>>=
####>#########>#######################<########################################<#
#># STEP_ID   AUX_FILES
#># STEP_DESC Preparing auxiliarly files: CHR.termini
#># STEP_PATH tmp
#># STEP_XID  $<JOB{.}{JOB_XID}>
#># STEP_IDIR .
#># STEP_ODIR $JOBDIR/$<STEP{.}{.}{STEP_PATH}>
#># STEP_EDIR $JOBDIR/$<STEP{.}{.}{STEP_PATH}>
#># STEP_CODE   --------------------------------------------------------------#<#
#
#<# ODIR="$HUMUS/$NCHR/sgp/$XID/tmp" ;
#<# LEN="$HUMUS/$NCHR/annotation/$HSAPID/length" ;
LEN="$CHRDIR/$<JOB{HSAP_GP_ANNOTATION}{JOB_PATH}>/$<JOB{HSAP_GP_ANNOTATION}{JOB_XID}>/length" ;
#
CheckFile R $LEN ;
#
perl -e '
  use strict;
  my $chr = shift @ARGV;
  my %SEQlen;
  my $seqln = shift @ARGV;
  open(FRGLEN, "< $seqln");
  while (<FRGLEN>) {
      next if /^#/o;
      next if /^\s*$/o;
      chomp;
      my @l = split /\s+/og, $_;
      $SEQlen{$l[0]} = $l[1];
  }; # while
  close(FRGLEN);
  print STDOUT join("\t", $chr, qw/ force cap  -2  0 . + 0 / )."\n";
  print STDOUT join("\t", $chr, qw/ force poly /,
                        ($SEQlen{$chr} - 1) x 2, qw/ . + 0/ )."\n";
' $SEQ $LEN > $ODIR/$SEQ.termini || TheEnd PERLKO ;
#
#># END_OF_STEP --------------------------------------------------------------#<#
@
%$

\chklst{
\item ...
}

\subsubsctn{Running {\sgp} ({\gnid} with homology)}

<<STEPS(SGP HSAPgpa x MGSCv3): Running SGP>>=
####>#########>#######################<########################################<#
#># STEP_ID   SGP_HSAPgpa_MGSCv3
#># STEP_DESC Running geneid on Hsapiens sequences from Golden Path assembly
#>#         : with homology evidences taken from MGSC v3 assembly.
#># STEP_PATH out
#># STEP_XID  $<JOB{.}{JOB_XID}>
#># STEP_IDIR $HUMUS/$NCHR/$<JOB{.}{JOB_PATH}>/$XID
#># STEP_ODIR $JOBDIR/$<STEP{.}{.}{STEP_PATH}>
#># STEP_EDIR $JOBDIR/logs
#># STEP_CODE   --------------------------------------------------------------#<#
#
#<# 
#
GENEID="$SRC/geneid_v1.1-sgp/bin/geneid" ; # geneid v1.1-sgp
PARAM="$SRC/geneid_v1.1-sgp/param/human3iso.param.sgp" ;
EW=0 ; # add to exon weigth
#
#<# ISEQ="$HSAP/chromFaMasked/$CHRNUM/$SEQ.fa.masked" ; 
#<# IDIR="$HUMUS/$NCHR/sgp/$XID/" ;
#<# ODIR="$HUMUS/$NCHR/sgp/$XID/out" ;
#--> we do not run geneid on masked sequences at this moment
#--> we are using original un-masked fasta sequences from GP
ISEQ="$HSEQ/$SEQ.fa" ;
#
HOMOLOGY="$HUMUS/$NCHR/sgp/$XID/hsp-sr/$SEQ.gff" ;
if [ -f "$HOMOLOGY" ] ;
  then
    echo "### Using homology data from: $HOMOLOGY" 1>&2 ;
    HOMOLOGY_PAR="-S $HOMOLOGY" ;
  else
    echo "### Homology file NOT found: $HOMOLOGY" 1>&2 ;
    HOMOLOGY_PAR="" ;
  fi ;
#
TERMINI="$IDIR/tmp/$SEQ.termini" ;
if [ -f "$TERMINI" ] ;
  then
    echo "### Using termini file: $TERMINI" 1>&2 ;
    TERMINI_PAR="-R $TERMINI" ;
  else
    TERMINI_PAR="" ;
  fi ;
#
CheckFile R $PARAM $ISEQ ;
#
GENEID_CMDLN="-v -DE $EW -P $PARAM $HOMOLOGY_PAR $TERMINI_PAR $ISEQ" ;
echo "$GENEID $GENEID_CMDLN 2> $EDIR/$SEQ.sgp" 1>&2 ;
( $GENEID $GENEID_CMDLN 2> $EDIR/$SEQ.sgp || TheEnd CKO ) \
           | grep -v 'evidence' > $ODIR/$SEQ ;
#
( cat $EDIR/$SEQ.sgp 1>&2 ) || TheEnd CMDKO ;
#
#># END_OF_STEP --------------------------------------------------------------#<#
@ 

\chklst{
\item ...
}

\subsubsctn{Processing output for {\sgp} (with homology)}

<<STEPS(SGP HSAPgpa x MGSCv3): Processing SGP results>>=
####>#########>#######################<########################################<#
#># STEP_ID   SGP_OUTPUT
#># STEP_DESC Processing geneid format from sgp output (with homology).
#># STEP_PATH gff
#># STEP_XID  $<JOB{.}{JOB_XID}>
#># STEP_IDIR $HUMUS/$NCHR/$<JOB{.}{JOB_PATH}>/$XID
#># STEP_ODIR $JOBDIR/$<STEP{.}{.}{STEP_PATH}>
#># STEP_EDIR $JOBDIR/$<STEP{.}{.}{STEP_PATH}>
#># STEP_CODE   --------------------------------------------------------------#<#
#
#<# IDIR="$HUMUS/$NCHR/sgp/$XID" ;
#
CheckFile R $IDIR/out/$SEQ ;
#
$BIN/geneid_raw2GFF.pl $SEQ $IDIR $IDIR/out/$SEQ ;
#
( ls -1 $IDIR/gff/$SEQ.sg/ | egrep "^$SEQ" | \
    while read n;
      do {
        cat $IDIR/gff/$SEQ.sg/$n;
        };
      done | sort +3n +4n -5 - > $IDIR/gff/$SEQ ) || TheEnd BASHKO ;
#
get_geneid_genes $IDIR/gff/$SEQ > $IDIR/$SEQ.gene_list || TheEnd FUNCKO ;
#
#># END_OF_STEP --------------------------------------------------------------#<#
@
%$

\chklst{
\item Number of genes, average length, average exon number, exon/intron length ratio...
\item ...
}

\subsubsctn{Evaluation of {\sgp} predictions (with homology)}

<<STEPS(SGP HSAPgpa x MGSCv3): Evaluating SGP results>>=
####>#########>#######################<########################################<#
#># STEP_ID   SGP_EVALUATION
#># STEP_DESC Evaluation of SGP predictions (geneid with homology).
#># STEP_PATH eval
#># STEP_XID  $<JOB{.}{JOB_XID}>
#># STEP_IDIR $JOBDIR/$<STEP{.}{SGP_OUTPUT}{STEP_PATH}>
#># STEP_ODIR $JOBDIR/$<STEP{.}{.}{STEP_PATH}>
#># STEP_EDIR $JOBDIR/$<STEP{.}{.}{STEP_PATH}>
#># STEP_CODE   --------------------------------------------------------------#<#
#
#<# IDIR="$HUMUS/$NCHR/sgp/$XID" ;
CheckFile R $IDIR/$SEQ ;
gawk '$3~/^(Single|First|Internal|Terminal)$/ {print $0}' \
               $IDIR/$SEQ > $ODIR/$SEQ.eval.gff || TheEnd GAWKKO ;
$BIN/gffsplitstrand.pl $ODIR/$SEQ.eval.gff ; # no sequence length record required here
#
A_REFSEQ="$CHRDIR/$<JOB{HSAP_GP_ANNOTATION}{JOB_PATH}>/$<JOB{HSAP_GP_ANNOTATION}{JOB_XID}>/$<STEP{HSAP_GP_ANNOTATION}{HSAP_GP_REFSEQ}{STEP_PATH}>/$SEQ.eval" ;
A_ENSEMBL="$CHRDIR/$<JOB{HSAP_GP_ANNOTATION}{JOB_PATH}>/$<JOB{HSAP_GP_ANNOTATION}{JOB_XID}>/$<STEP{HSAP_GP_ANNOTATION}{HSAP_GP_ENSEMBL}{STEP_PATH}>/$SEQ.eval" ;
cat > $ODIR/${SEQ}.summary <<EOT ;
#
# Evaluation summary results for SGP on CHROM[$CHR] - SEQ[$SEQ]
#
EOT
#
CheckFile R $A_REFSEQ.fwd.gff  $A_REFSEQ.rev.gff  \
            $A_ENSEMBL.fwd.gff $A_ENSEMBL.rev.gff ;
#
$BIN/runeval.pl $A_REFSEQ.fwd.gff $ODIR/$SEQ.eval.fwd.gff                 \
    "${CHR}::${HSAPID}x${MMUSID}::REFSEQ::FWD::SGP-MGSCv3::geneid_1.1::." \
    >> $ODIR/${SEQ}.summary 2> $ODIR/${SEQ}.sgp_refseq.fwd ;
$BIN/runeval.pl $A_REFSEQ.rev.gff $ODIR/$SEQ.eval.rev.gff                 \
    "${CHR}::${HSAPID}x${MMUSID}::REFSEQ::REV::SGP-MGSCv3::geneid_1.1::." \
    >> $ODIR/${SEQ}.summary 2> $ODIR/${SEQ}.sgp_refseq.rev ;
$BIN/runeval.pl $A_ENSEMBL.fwd.gff $ODIR/$SEQ.eval.fwd.gff                 \
    "${CHR}::${HSAPID}x${MMUSID}::ENSEMBL::FWD::SGP-MGSCv3::geneid_1.1::." \
    >> $ODIR/${SEQ}.summary 2> $ODIR/${SEQ}.sgp_ensembl.fwd ;
$BIN/runeval.pl $A_ENSEMBL.rev.gff $ODIR/$SEQ.eval.rev.gff                 \
    "${CHR}::${HSAPID}x${MMUSID}::ENSEMBL::REV::SGP-MGSCv3::geneid_1.1::." \
    >> $ODIR/${SEQ}.summary 2> $ODIR/${SEQ}.sgp_ensembl.rev ;
#
#># END_OF_STEP --------------------------------------------------------------#<#
@

\chklst{
\item ...
}


\newpage %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\sctn{Processing {\tbx} results from human genome vs mouse RIKEN cDNAs} %%%%%%

\begin{comment}
RIKEN cDNAs
  http://hgwdev-mgsc.cse.ucsc.edu/jk/files/
\end{comment}
\begin{center}
% \fbox{
  \begin{minipage}{0.95\linewidth}
   \textbf{What to do here:}
   \begin{itemize}
 \item Process {\tbx} results from Gen\'{\i}s:
  \begin{itemize}
   \item Human genome assembly from UCSC Golden Path August release (20011222).
   \item Mouse cDNAs from RIKEN DataBase (???).\\[-3ex]
\begin{verbatim}
# Database:  /home/ug/gparra/Research/sgp/chr22_tbxRIKEN/blastdb/RIKEN.cdna
# Title:  /home/ug/rguigo/riken/hgwdev-mgsc.cse.ucsc.edu/jk/files/matrics.fasta
# # of letters in database:  515,210,215,105,232,895  (Z = 3000000000)
# # of sequences in database:  60,770
# Created:  2:19:28 PM CEST May 02, 2002
# Format:  XDF-1
# Posted:  2:17:22 PM CEST May 02, 2002
\end{verbatim}
   \item {\tbx} was run with the following parameters:\\[-3ex]
%	   \begin{center}
%	   \begin{minipage}[c]{0.75\linewidth}
\begin{verbatim}
W=5  Z=3000000000
matrix=blosum62mod  filter=xnu+seg
nogaps  hspmax=500  topcomboN=100
B=9000  V=9000  E=0.01  E2=0.01  S2=80
warnings
-------------------------------------- for chr22 ???
     93	  ctxfactor=35.5
     92	  ctxfactor=35.4
     88	  ctxfactor=35.3
     87	  ctxfactor=35.6
     74	  ctxfactor=35.7
     68	  ctxfactor=35.2
     39	  ctxfactor=35.1
     32	  ctxfactor=35.0
     25	  ctxfactor=35.8
     23	  ctxfactor=34.9
      7	  ctxfactor=34.5
      7	  ctxfactor=34.6
      7	  ctxfactor=34.7
      7	  ctxfactor=34.8
      6	  ctxfactor=35.9
      5	  ctxfactor=34.1
      4	  ctxfactor=34.3
      4	  ctxfactor=34.4
      3	  ctxfactor=33.8
      3	  ctxfactor=34.0
      3	  ctxfactor=34.2
      2	  ctxfactor=32.8
      2	  ctxfactor=33.6
      1	  ctxfactor=30.0
      1	  ctxfactor=33.0
      1	  ctxfactor=33.3
      1	  ctxfactor=33.5
\end{verbatim}
% tail -54 ~gparra/Research/sgp/chr22_tbxRIKEN/blast/chr22* | sort | uniq -c | sort +0nr | more
%	   \end{minipage}
%	   \end{center}
  \end{itemize}
\item Get HSPs $\Rightarrow$ SRs $\Rightarrow$ HSP-SRs
   \end{itemize}
  \end{minipage}
% } % fbox
 \end{center}


<<JOBheader: HsapGPa x MmusRIKENcDNA WUTBLASTX>>=
####>#########>#######################<########################################<#
#># JOB_ID    HSAPgp_MMUScDNA_WUTBLASTX
#># JOB_DESC  Homology search by WU-TBLASTX for H.sapiens UCSC Golden Path 
#>#        :  assembly against M.musculus RIKEN cDNAs dataset 
#>#        :  (current tblastx from Genis).
#>#        :  # (TBLASTX results obtained by Pankaj Agarwal,  
#>#        :     last update was jan 11, 2002, downladed from GSBP).
#># JOB_PATH  tblastx
#># JOB_XID   $RIKENID
#># JOB_FILE  ${LIBSTEP}/tblastx-riken.job
#># END_OF_JOB ##################################################################
@ 

<<JOBS: HsapGPa x MmusRIKENcDNA WUTBLASTX>>=
<<STEPS(HsGPa*MmRKNcDNA WUTBLASTX): retrieve blast output>>
<<STEPS(HsGPa*MmRKNcDNA WUTBLASTX): parsing blast output>>
<<STEPS(HsGPa*MmRKNcDNA WUTBLASTX): project HSPs into SRs>>
<<STEPS(HsGPa*MmRKNcDNA WUTBLASTX): evaluating SRs>>
@ 

\subsctn{Unpacking {\tbx} results}

<<STEPS(HsGPa*MmRKNcDNA WUTBLASTX): retrieve blast output>>=
####>#########>#######################<########################################<#
#># STEP_ID   TBLASTX_OUTPUT
#># STEP_DESC Unpacking TBLASTX results obtained by Genis...
#>#         : (Hsapiens GP assembly against Mmusculus RIKEN cDNAs dataset).
#># STEP_PATH ori
#># STEP_XID  $<JOB{.}{JOB_XID}>
#># STEP_IDIR $RIKENTBX
#># STEP_ODIR $JOBDIR/$<STEP{.}{.}{STEP_PATH}>
#># STEP_EDIR $JOBDIR/$<STEP{.}{.}{STEP_PATH}>
#># STEP_CODE   --------------------------------------------------------------#<#
#
MkDirs $ODIR/$SEQ ;
( mega "cp -v" $IDIR '^'$SEQ'_[0-9]' $ODIR/$SEQ 1>&2 ) || TheEnd FUNCKO ;
# exit status has been implemented on sbp_checkblastout.pl
$BIN/sbp_checkblastout.pl $SEQ $ODIR/$SEQ > $ODIR/$SEQ.report ; 
#
#># END_OF_STEP --------------------------------------------------------------#<#
@ 

\chklst{
\item get number of sequences from DB matching each chromosome fragment.
\item do the regions without HSPs correspond to N regions at original sequences (being gaps or masked) ? (maybe using [[evaluation]]). [[sbp_checkblastout.pl]] already report errors in tbx files...
}

\subsctn{Retrieving {\tbx} results by chromosome}

\begin{figure}[!t]
\begin{center}
 \input psfigures/blast_frames.tex
\end{center}
\end{figure}

We had to deal with the frame issue of the HSPs fragments; once the HSP coords were mapped to the chromosome, frames also must be recomputed taking into account if HSP was in forward or in reverse strand (see figure~\ref{fig:blastframes}).

<<STEPS(HsGPa*MmRKNcDNA WUTBLASTX): parsing blast output>>=
####>#########>#######################<########################################<#
#># STEP_ID   PARSING_TBLASTX
#># STEP_DESC Retrieving HSPs from raw TBLASTX output
#>#         : (Hsapiens GP assembly against Mmusculus RIKEN cDNAs dataset).
#># STEP_PATH hsp
#># STEP_XID  $<JOB{.}{JOB_XID}>
#># STEP_IDIR $JOBDIR/$<STEP{.}{TBLASTX_OUTPUT}{STEP_PATH}>
#># STEP_ODIR $JOBDIR/$<STEP{.}{.}{STEP_PATH}>
#># STEP_EDIR $JOBDIR/$<STEP{.}{.}{STEP_PATH}>
#># STEP_CODE   --------------------------------------------------------------#<#
#
LEN="$CHRDIR/$<JOB{HSAP_GP_ANNOTATION}{JOB_PATH}>/$<JOB{HSAP_GP_ANNOTATION}{JOB_XID}>/length" ;
# exit status has been implemented on sbp_blast2gff.pl
/bin/rm -vf $IDIR/$SEQ.parseblast.err 1>&2 ;
$BIN/sbp_blast2gff.pl $SEQ $LEN $IDIR/$SEQ $IDIR/$SEQ.report \
         > $ODIR/$SEQ.fullgff 2> $EDIR/$SEQ.report ;
#
( perl -ne '/^#/o && next;
          /^\s+$/o && next; 
          $_ =~ s/;\s+Strand//o; 
          $_ =~ s/;\s+Frame//o; 
          $_ =~ s/;\s+E_value.*$//o;
          print STDOUT $_;' $ODIR/$SEQ.fullgff | \
          sort +3n -6 +6 -7 - > $ODIR/$SEQ.gff ) || TheEnd PERLKO ;
#
#># END_OF_STEP --------------------------------------------------------------#<#
@ 

\chklst{
\item find number of HSPs per fragment and total per chromosome (implemented on [[sbp_blast2gff.pl]]).
}

\subsubsctn{Projecting HSPs into SRs}

<<STEPS(HsGPa*MmRKNcDNA WUTBLASTX): project HSPs into SRs>>=
####>#########>#######################<########################################<#
#># STEP_ID   PROJECTING_HSPs
#># STEP_DESC Projecting HSPs into SRs
#>#         : (Hsapiens GP assembly against Mmusculus RIKEN cDNAs dataset).
#># STEP_PATH sr
#># STEP_XID  $<STEP{.}{PARSING_TBLASTX}{STEP_XID}>
#># STEP_IDIR $JOBDIR/$<STEP{.}{PARSING_TBLASTX}{STEP_PATH}>
#># STEP_ODIR $JOBDIR/$<STEP{.}{.}{STEP_PATH}>
#># STEP_EDIR $JOBDIR/$<STEP{.}{.}{STEP_PATH}>
#># STEP_CODE   --------------------------------------------------------------#<#
#
#<# IDIR="$HUMUS/$NCHR/tblastx/$XID/hsp" ;
#<# ODIR="$HUMUS/$NCHR/tblastx/$XID/sr" ;
#<# MkDirs $ODIR ;
CheckFile R $IDIR/$SEQ.gff ;
$BIN/blast2gff -vg $IDIR/$SEQ.gff > $ODIR/$SEQ.gff || TheEnd CKO ;
#
gawk '
  BEGIN{ chr=ARGV[1]; ARGV[1]=""; t=b["+"]=b["-"]=b["."]=0; }
  ($0 !~ /^[ \t]*$/ && $1 !~ /^\#/) { t++; a[$7,$8]++; b[$7]++; c[$8]++ }
  END{ 
    printf "# TOTAL %s SRs on %s: %s forward, %s reverse, %s without strand.\n", 
           t, chr, b["+"], b["-"], b["."];
    for (i in c) {
      printf "#\t%s : %6s\t\|\t%s : %6s\t|\t%s : %6s\n", 
             "+"i, a["+",c[i]] ? a["+",i] : 0,
             "-"i, a["-",c[i]] ? a["-",i] : 0,
             "."i, a[".",c[i]] ? a[".",i] : 0;
    };
  }
' $SEQ $ODIR/$SEQ.gff > $EDIR/$SEQ.report || TheEnd GAWKKO ;
#
#># END_OF_STEP --------------------------------------------------------------#<#
@

\chklst{
\item Get SRs number for each sequence (done by [[gawk]] script after [[blast2gff]] execution).
\item ...
}

\subsubsctn{Evaluating SRs versus annotation}

<<STEPS(HsGPa*MmRKNcDNA WUTBLASTX): evaluating SRs>>=
####>#########>#######################<########################################<#
#># STEP_ID   EVALUATING_SRs
#># STEP_DESC Evaluating SRs versus different annotations
#>#         : (Hsapiens GP assembly against Mmusculus RIKEN cDNAs dataset).
#># STEP_PATH eval
#># STEP_XID  $<STEP{.}{PARSING_TBLASTX}{STEP_XID}>
#># STEP_IDIR $JOBDIR/$<STEP{.}{PROJECTING_HSPs}{STEP_PATH}>
#># STEP_ODIR $JOBDIR/$<STEP{.}{.}{STEP_PATH}>
#># STEP_EDIR $JOBDIR/$<STEP{.}{.}{STEP_PATH}>
#># STEP_CODE   --------------------------------------------------------------#<#
#
CheckFile R $IDIR/$SEQ.gff ;
gawk 'BEGIN{ OFS="\t"; }
      ($0 !~ /^[ \t]*$/ && $1 !~ /^\#/ && $3 ~ "SR") { print $0,"1" }' \
               $IDIR/$SEQ.gff > $ODIR/$SEQ.eval.gff || TheEnd GAWKKO ;
$BIN/gffsplitstrand.pl $ODIR/$SEQ.eval.gff ; # no sequence length record required here
#
A_REFSEQ="$CHRDIR/$<JOB{HSAP_GP_ANNOTATION}{JOB_PATH}>/$<JOB{HSAP_GP_ANNOTATION}{JOB_XID}>/$<STEP{HSAP_GP_ANNOTATION}{HSAP_GP_REFSEQ}{STEP_PATH}>/$SEQ.eval" ;
A_ENSEMBL="$CHRDIR/$<JOB{HSAP_GP_ANNOTATION}{JOB_PATH}>/$<JOB{HSAP_GP_ANNOTATION}{JOB_XID}>/$<STEP{HSAP_GP_ANNOTATION}{HSAP_GP_ENSEMBL}{STEP_PATH}>/$SEQ.eval" ;
cat > $ODIR/${SEQ}.summary <<EOT ;
#
# Evaluation summary results for similarity regions on CHROM[$CHR] - SEQ[$SEQ]
#
EOT
#
CheckFile R $A_REFSEQ.fwd.gff  $A_REFSEQ.rev.gff  \
            $A_ENSEMBL.fwd.gff $A_ENSEMBL.rev.gff ;
#
$BIN/runeval.pl $A_REFSEQ.fwd.gff $ODIR/$SEQ.eval.fwd.gff                     \
    "${CHR}::${HSAPID}x${RIKENID}::REFSEQ::FWD::RIKEN-SRs::blast2gff_v???::." \
    >> $ODIR/${SEQ}.summary 2> $ODIR/${SEQ}.sr_refseq.fwd ;
$BIN/runeval.pl $A_REFSEQ.rev.gff $ODIR/$SEQ.eval.rev.gff                     \
    "${CHR}::${HSAPID}x${RIKENID}::REFSEQ::REV::RIKEN-SRs::blast2gff_v???::." \
    >> $ODIR/${SEQ}.summary 2> $ODIR/${SEQ}.sr_refseq.rev ;
$BIN/runeval.pl $A_ENSEMBL.fwd.gff $ODIR/$SEQ.eval.fwd.gff                     \
    "${CHR}::${HSAPID}x${RIKENID}::ENSEMBL::FWD::RIKEN-SRs::blast2gff_v???::." \
    >> $ODIR/${SEQ}.summary 2> $ODIR/${SEQ}.sr_ensembl.fwd ;
$BIN/runeval.pl $A_ENSEMBL.rev.gff $ODIR/$SEQ.eval.rev.gff                     \
    "${CHR}::${HSAPID}x${RIKENID}::ENSEMBL::REV::RIKEN-SRs::blast2gff_v???::." \
    >> $ODIR/${SEQ}.summary 2> $ODIR/${SEQ}.sr_ensembl.rev ;
#
#># END_OF_STEP --------------------------------------------------------------#<#
@

\chklst{
\item Evaluation records (extended and brief) for each seq and for each chromosome.
\item ...
}



\newpage %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\sctn{Gene Prediction: {\sgp} (II)} %%%%%%%%%%%%%%%%%%%%%%

\subsctn{Homology taken from {\mmus} RIKEN cDNAs library} %%%%%%%%%%%%%%%%%%%%%%

\whtlst{
\item Re-score similarity regions: SRs to HSP-SRs.
\item Initialize any auxiliarly file (like those [[*.termini]]).
\item Run {\sgp} with homology, then evaluate results.
\item TODO -> Run {\sgp} with homology plus evidences, then evaluate results.
}

<<JOBheader: SGP with HSAPgpa x MmusRIKENcDNA homology>>=
####>#########>#######################<########################################<#
#># JOB_ID    SGP_HSAPgpa_RKNcDNA_TBX
#># JOB_DESC  Running "SGP" on unmasked H.sapiens UCSC Golden Path 
#>#        :  assembly sequences, using TBLASTX homology results (human against 
#>#        :  RIKEN cDNAs) as evidences once they have been projected into SRs.
#># JOB_PATH  sgp
#># JOB_XID   ${HSAPSTR}-${RIKENID}
#># JOB_FILE  ${LIBSTEP}/sgp-riken.job
#># END_OF_JOB ##################################################################
@ 

<<JOBS: SGP with HSAPgpa x MmusRIKENcDNA homology>>=
<<STEPS(SGP): Initialization>>
<<STEPS(SGP HSAPgpa x MmusRKNcDNA): Auxiliarly files>>
<<STEPS(SGP HSAPgpa x MmusRKNcDNA): Re-scoring SRs>>
<<STEPS(SGP HSAPgpa x MmusRKNcDNA): Running SGP>>
<<STEPS(SGP HSAPgpa x MmusRKNcDNA): Processing SGP results>>
<<STEPS(SGP HSAPgpa x MmusRKNcDNA): Evaluating SGP results>>
@ 

<<STEPS(SGP): Initialization>>=
####>#########>#######################<########################################<#
#># STEP_ID   SGP_INITIALIZE
#># STEP_DESC Preparing subdirectories for sgp results.
#># STEP_PATH .
#># STEP_XID  $<JOB{.}{JOB_XID}>
#># STEP_IDIR .
#># STEP_ODIR $JOBDIR
#># STEP_EDIR $JOBDIR
#># STEP_CODE   --------------------------------------------------------------#<
#
#<# ODIR="$HUMUS/$NCHR/sgp/$XID" ; MkDirs $ODIR ;
#
( for c in out gff gtf2 cds prot hsp-sr logs tmp ;
    do { 
      MkDirs $ODIR/$c ;
      } ;
    done ) || TheEnd BASHKO ;
#
#># END_OF_STEP --------------------------------------------------------------#<#
@

\subsubsctn{Re-scoring SRs}

<<STEPS(SGP HSAPgpa x MmusRKNcDNA): Re-scoring SRs>>=
####>#########>#######################<########################################<#
#># STEP_ID   RE-SCORING_SRs
#># STEP_DESC Re-scoring SRs to produce HSP-SRs
#>#         : (Hsapiens GP assembly against MGSC v3 assembly).
#># STEP_PATH hsp-sr
#># STEP_XID  $<JOB{.}{JOB_XID}>
#># STEP_IDIR $HUMUS/$NCHR/$<JOB{HSAPgp_MMUScDNA_WUTBLASTX}{JOB_PATH}>/$<JOB{HSAPgp_MMUScDNA_WUTBLASTX}{JOB_XID}>/$<JOB{HSAPgp_MMUScDNA_WUTBLASTX}{PROJECTING_HSPs}{STEP_PATH}>
#># STEP_ODIR $JOBDIR/$<STEP{.}{.}{STEP_PATH}>
#># STEP_EDIR $JOBDIR/$<STEP{.}{.}{STEP_PATH}>
#># STEP_CODE   --------------------------------------------------------------#<#
#
#<# IDIR="$HUMUS/$NCHR/$<JOB{HSAPgp_MMUScDNA_WUTBLASTX}{JOB_PATH}>/$XID/sr" ;
#<# ODIR="$HUMUS/$NCHR/sgp/$XID/hsp-sr" ;
#
CheckFile R $IDIR/$SEQ.gff ;
$BIN/getHSPSR.pl $SEQ < $IDIR/$SEQ.gff \
                      > $ODIR/$SEQ.gff 2> $EDIR/$SEQ.report || TheEnd PERLKO ;
#
#># END_OF_STEP --------------------------------------------------------------#<#
@
%$

\chklst{
\item ...
}

\subsubsctn{Preparing auxiliarly files}

<<STEPS(SGP HSAPgpa x MmusRKNcDNA): Auxiliarly files>>=
####>#########>#######################<########################################<#
#># STEP_ID   AUX_FILES
#># STEP_DESC Preparing auxiliarly files: CHR.termini
#># STEP_PATH tmp
#># STEP_XID  $<JOB{.}{JOB_XID}>
#># STEP_IDIR .
#># STEP_ODIR $JOBDIR/$<STEP{.}{.}{STEP_PATH}>
#># STEP_EDIR $JOBDIR/$<STEP{.}{.}{STEP_PATH}>
#># STEP_CODE   --------------------------------------------------------------#<#
#
#<# ODIR="$HUMUS/$NCHR/sgp/$XID/tmp" ;
#<# LEN="$HUMUS/$NCHR/annotation/$HSAPID/length" ;
LEN="$CHRDIR/$<JOB{HSAP_GP_ANNOTATION}{JOB_PATH}>/$<JOB{HSAP_GP_ANNOTATION}{JOB_XID}>/length" ;
#
CheckFile R $LEN ;
#
perl -e '
  use strict;
  my $chr = shift @ARGV;
  my %SEQlen;
  my $seqln = shift @ARGV;
  open(FRGLEN, "< $seqln");
  while (<FRGLEN>) {
      next if /^#/o;
      next if /^\s*$/o;
      chomp;
      my @l = split /\s+/og, $_;
      $SEQlen{$l[0]} = $l[1];
  }; # while
  close(FRGLEN);
  print STDOUT join("\t", $chr, qw/ force cap  -2  0 . + 0 / )."\n";
  print STDOUT join("\t", $chr, qw/ force poly /,
                        ($SEQlen{$chr} - 1) x 2, qw/ . + 0/ )."\n";
' $SEQ $LEN > $ODIR/$SEQ.termini || TheEnd PERLKO ;
#
#># END_OF_STEP --------------------------------------------------------------#<#
@
%$

\chklst{
\item ...
}

\subsubsctn{Running {\sgp} ({\gnid} with homology)}

<<STEPS(SGP HSAPgpa x MmusRKNcDNA): Running SGP>>=
####>#########>#######################<########################################<#
#># STEP_ID   SGP_HSAPgpa_MGSCv3
#># STEP_DESC Running geneid on Hsapiens sequences from Golden Path assembly
#>#         : with homology evidences taken from MGSC v3 assembly.
#># STEP_PATH out
#># STEP_XID  $<JOB{.}{JOB_XID}>
#># STEP_IDIR $HUMUS/$NCHR/$<JOB{.}{JOB_PATH}>/$XID
#># STEP_ODIR $JOBDIR/$<STEP{.}{.}{STEP_PATH}>
#># STEP_EDIR $JOBDIR/logs
#># STEP_CODE   --------------------------------------------------------------#<#
#
#<# 
#
GENEID="$SRC/geneid_v1.1-sgp/bin/geneid" ; # geneid v1.1-sgp
PARAM="$SRC/geneid_v1.1-sgp/param/human3iso.param.sgp" ;
EW=0 ; # add to exon weigth
#
#<# ISEQ="$HSAP/chromFaMasked/$CHRNUM/$SEQ.fa.masked" ; 
#<# IDIR="$HUMUS/$NCHR/sgp/$XID/" ;
#<# ODIR="$HUMUS/$NCHR/sgp/$XID/out" ;
#--> we do not run geneid on masked sequences at this moment
#--> we are using original un-masked fasta sequences from GP
ISEQ="$HSEQ/$SEQ.fa" ;
#
HOMOLOGY="$HUMUS/$NCHR/sgp/$XID/hsp-sr/$SEQ.gff" ;
if [ -f "$HOMOLOGY" ] ;
  then
    echo "### Using homology data from: $HOMOLOGY" 1>&2 ;
    HOMOLOGY_PAR="-S $HOMOLOGY" ;
  else
    echo "### Homology file NOT found: $HOMOLOGY" 1>&2 ;
    HOMOLOGY_PAR="" ;
  fi ;
#
TERMINI="$IDIR/tmp/$SEQ.termini" ;
if [ -f "$TERMINI" ] ;
  then
    echo "### Using termini file: $TERMINI" 1>&2 ;
    TERMINI_PAR="-R $TERMINI" ;
  else
    TERMINI_PAR="" ;
  fi ;
#
CheckFile R $PARAM $ISEQ ;
#
GENEID_CMDLN="-v -DE $EW -P $PARAM $HOMOLOGY_PAR $TERMINI_PAR $ISEQ" ;
echo "$GENEID $GENEID_CMDLN 2> $EDIR/$SEQ.sgp" 1>&2 ;
( $GENEID $GENEID_CMDLN 2> $EDIR/$SEQ.sgp || TheEnd CKO ) \
           | grep -v 'evidence' > $ODIR/$SEQ ;
#
( cat $EDIR/$SEQ.sgp 1>&2 ) || TheEnd CMDKO ;
#
#># END_OF_STEP --------------------------------------------------------------#<#
@ 

\chklst{
\item ...
}

\subsubsctn{Processing output for {\sgp} (with homology)}

<<STEPS(SGP HSAPgpa x MmusRKNcDNA): Processing SGP results>>=
####>#########>#######################<########################################<#
#># STEP_ID   SGP_OUTPUT
#># STEP_DESC Processing geneid format from sgp output (with homology).
#># STEP_PATH gff
#># STEP_XID  $<JOB{.}{JOB_XID}>
#># STEP_IDIR $HUMUS/$NCHR/$<JOB{.}{JOB_PATH}>/$XID
#># STEP_ODIR $JOBDIR/$<STEP{.}{.}{STEP_PATH}>
#># STEP_EDIR $JOBDIR/$<STEP{.}{.}{STEP_PATH}>
#># STEP_CODE   --------------------------------------------------------------#<#
#
#<# IDIR="$HUMUS/$NCHR/sgp/$XID" ;
#
CheckFile R $IDIR/out/$SEQ ;
#
$BIN/geneid_raw2GFF.pl $SEQ $IDIR $IDIR/out/$SEQ ;
#
( ls -1 $IDIR/gff/$SEQ.sg/ | egrep "^$SEQ" | \
    while read n;
      do {
        cat $IDIR/gff/$SEQ.sg/$n;
        };
      done | sort +3n +4n -5 - > $IDIR/gff/$SEQ ) || TheEnd BASHKO ;
#
get_geneid_genes $IDIR/gff/$SEQ > $IDIR/$SEQ.gene_list || TheEnd FUNCKO ;
#
#># END_OF_STEP --------------------------------------------------------------#<#
@
%$

\chklst{
\item Number of genes, average length, average exon number, exon/intron length ratio...
\item ...
}


\subsubsctn{Evaluation of {\sgp} predictions (with homology)}

<<STEPS(SGP HSAPgpa x MmusRKNcDNA): Evaluating SGP results>>=
####>#########>#######################<########################################<#
#># STEP_ID   SGP_EVALUATION
#># STEP_DESC Evaluation of SGP predictions (geneid with homology).
#># STEP_PATH eval
#># STEP_XID  $<JOB{.}{JOB_XID}>
#># STEP_IDIR $JOBDIR/$<STEP{.}{SGP_OUTPUT}{STEP_PATH}>
#># STEP_ODIR $JOBDIR/$<STEP{.}{.}{STEP_PATH}>
#># STEP_EDIR $JOBDIR/$<STEP{.}{.}{STEP_PATH}>
#># STEP_CODE   --------------------------------------------------------------#<#
#
#<# IDIR="$HUMUS/$NCHR/sgp/$XID" ;
CheckFile R $IDIR/$SEQ ;
gawk '$3~/^(Single|First|Internal|Terminal)$/ {print $0}' \
               $IDIR/$SEQ > $ODIR/$SEQ.eval.gff || TheEnd GAWKKO ;
$BIN/gffsplitstrand.pl $ODIR/$SEQ.eval.gff ; # no sequence length record required here
#
A_REFSEQ="$CHRDIR/$<JOB{HSAP_GP_ANNOTATION}{JOB_PATH}>/$<JOB{HSAP_GP_ANNOTATION}{JOB_XID}>/$<STEP{HSAP_GP_ANNOTATION}{HSAP_GP_REFSEQ}{STEP_PATH}>/$SEQ.eval" ;
A_ENSEMBL="$CHRDIR/$<JOB{HSAP_GP_ANNOTATION}{JOB_PATH}>/$<JOB{HSAP_GP_ANNOTATION}{JOB_XID}>/$<STEP{HSAP_GP_ANNOTATION}{HSAP_GP_ENSEMBL}{STEP_PATH}>/$SEQ.eval" ;
cat > $ODIR/${SEQ}.summary <<EOT ;
#
# Evaluation summary results for SGP on CHROM[$CHR] - SEQ[$SEQ]
#
EOT
#
CheckFile R $A_REFSEQ.fwd.gff  $A_REFSEQ.rev.gff  \
            $A_ENSEMBL.fwd.gff $A_ENSEMBL.rev.gff ;
#
$BIN/runeval.pl $A_REFSEQ.fwd.gff $ODIR/$SEQ.eval.fwd.gff                   \
    "${CHR}::${HSAPID}x${RIKENID}::REFSEQ::FWD::SGP-RKNcDNA::geneid_1.1::." \
    >> $ODIR/${SEQ}.summary 2> $ODIR/${SEQ}.sgp_refseq.fwd ;
$BIN/runeval.pl $A_REFSEQ.rev.gff $ODIR/$SEQ.eval.rev.gff                   \
    "${CHR}::${HSAPID}x${RIKENID}::REFSEQ::REV::SGP-RKNcDNA::geneid_1.1::." \
    >> $ODIR/${SEQ}.summary 2> $ODIR/${SEQ}.sgp_refseq.rev ;
$BIN/runeval.pl $A_ENSEMBL.fwd.gff $ODIR/$SEQ.eval.fwd.gff                   \
    "${CHR}::${HSAPID}x${RIKENID}::ENSEMBL::FWD::SGP-RKNcDNA::geneid_1.1::." \
    >> $ODIR/${SEQ}.summary 2> $ODIR/${SEQ}.sgp_ensembl.fwd ;
$BIN/runeval.pl $A_ENSEMBL.rev.gff $ODIR/$SEQ.eval.rev.gff                   \
    "${CHR}::${HSAPID}x${RIKENID}::ENSEMBL::REV::SGP-RKNcDNA::geneid_1.1::." \
    >> $ODIR/${SEQ}.summary 2> $ODIR/${SEQ}.sgp_ensembl.rev ;
#
#># END_OF_STEP --------------------------------------------------------------#<#
@

\chklst{
\item ...
}


\newpage %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\sctn{Gene Prediction: {\sgp} (III)} %%%%%%%%%%%%%%%%%%%%%%

\subsctn{Homology taken from MGSCv3 assembly plus RIKEN cDNAs library} %%%%%%%%%%%%%%%%%%%%%%

\whtlst{
\item Project together similarity regions from MGSCv3 assembly and RIKEN cDNAs dataset: SRs'. %'
\item Re-score similarity regions: SRs' to HSP-SRs'.
\item Initialize any auxiliarly file (like those [[*.termini]]).
\item Run {\sgp} with homology, then evaluate results.
\item TODO -> Run {\sgp} with homology plus evidences, then evaluate results.
}

<<JOBheader: SGP with HSAPgpa x MmusMGSCv3+RIKENcDNA homology>>=
####>#########>#######################<########################################<#
#># JOB_ID    SGP_HSAPgpa_MGSC+RKN_TBX
#># JOB_DESC  Running "SGP" on unmasked H.sapiens UCSC Golden Path 
#>#        :  assembly sequences, using TBLASTX homology results (human against 
#>#        :  RIKEN cDNAs plus human versus mouse genomes) as evidences once 
#>#        :  they have been projected into SRs.
#># JOB_PATH  sgp
#># JOB_XID   ${HSAPSTR}-${MGSC_RKN}
#># JOB_FILE  ${LIBSTEP}/sgp-mgsc+riken.job
#># END_OF_JOB ##################################################################
@ 

<<JOBS: SGP with HSAPgpa x MmusMGSCv3+RIKENcDNA homology>>=
<<STEPS(SGP): Initialization>>
<<STEPS(SGP HSAPgpa x MmusMGSCv3+RKNcDNA): Auxiliarly files>>
<<STEPS(SGP HSAPgpa x MmusMGSCv3+RKNcDNA): Merging and projecting HSP-SRs>>
<<STEPS(SGP HSAPgpa x MmusMGSCv3+RKNcDNA): Running SGP>>
<<STEPS(SGP HSAPgpa x MmusMGSCv3+RKNcDNA): Processing SGP results>>
<<STEPS(SGP HSAPgpa x MmusMGSCv3+RKNcDNA): Evaluating SGP results>>
@ 

<<STEPS(SGP): Initialization>>=
####>#########>#######################<########################################<#
#># STEP_ID   SGP_INITIALIZE
#># STEP_DESC Preparing subdirectories for sgp results.
#># STEP_PATH .
#># STEP_XID  $<JOB{.}{JOB_XID}>
#># STEP_IDIR .
#># STEP_ODIR $JOBDIR
#># STEP_EDIR $JOBDIR
#># STEP_CODE   --------------------------------------------------------------#<
#
#<# ODIR="$HUMUS/$NCHR/sgp/$XID" ; MkDirs $ODIR ;
#
( for c in out gff gtf2 cds prot hsp-sr logs tmp ;
    do { 
      MkDirs $ODIR/$c ;
      } ;
    done ) || TheEnd BASHKO ;
#
#># END_OF_STEP --------------------------------------------------------------#<#
@

\subsubsctn{Merging HSP-SRs from MGSC v3 assembly and RIKEN cDNAs}

<<STEPS(SGP HSAPgpa x MmusMGSCv3+RKNcDNA): Merging and projecting HSP-SRs>>=
####>#########>#######################<########################################<#
#># STEP_ID   MERGING_SRs
#># STEP_DESC Merging HSP-SRs from MGSC v3 assembly and RIKEN cDNAs homology
#>#         : to H.sapiens NCBI28 assembly (GP20011222).
#># STEP_PATH hsp-sr
#># STEP_XID  $<JOB{.}{JOB_XID}>
#># STEP_IDIR $HUMUS/$NCHR/
#># STEP_ODIR $JOBDIR/$<STEP{.}{.}{STEP_PATH}>
#># STEP_EDIR $JOBDIR/$<STEP{.}{.}{STEP_PATH}>
#># STEP_CODE   --------------------------------------------------------------#<#
#
MGSC="$IDIR/$<JOB{HSAPgpa_MGSCv3_WUTBLASTX}{JOB_PATH}>/$<JOB{HSAPgpa_MGSCv3_WUTBLASTX}{JOB_XID}>/$<JOB{HSAPgpa_MGSCv3_WUTBLASTX}{PROJECTING_HSPs}{STEP_PATH}>" ;
RKN="$IDIR/$<JOB{HSAPgp_MMUScDNA_WUTBLASTX}{JOB_PATH}>/$<JOB{HSAPgp_MMUScDNA_WUTBLASTX}{JOB_XID}>/$<JOB{HSAPgp_MMUScDNA_WUTBLASTX}{PROJECTING_HSPs}{STEP_PATH}>" ;
#
CheckFile R $MGSC/$SEQ.gff $RKN/$SEQ.gff ;
#
( sort +3n -6 +6 -7 $MGSC/$SEQ.gff $RKN/$SEQ.gff \
                    > $ODIR/$SEQ.merged.gff ) || TheEnd CMDKO ;
#
$BIN/blast2gff -vg $ODIR/$SEQ.merged.gff > $ODIR/$SEQ.gff || TheEnd CKO ;
#
gawk '
  BEGIN{ chr=ARGV[1]; ARGV[1]=""; t=b["+"]=b["-"]=b["."]=0; }
  ($0 !~ /^[ \t]*$/ && $1 !~ /^\#/) { t++; a[$7,$8]++; b[$7]++; c[$8]++ }
  END{ 
    printf "# TOTAL %s SRs on %s: %s forward, %s reverse, %s without strand.\n", 
           t, chr, b["+"], b["-"], b["."];
    for (i in c) {
      printf "#\t%s : %6s\t\|\t%s : %6s\t|\t%s : %6s\n", 
             "+"i, a["+",c[i]] ? a["+",i] : 0,
             "-"i, a["-",c[i]] ? a["-",i] : 0,
             "."i, a[".",c[i]] ? a[".",i] : 0;
    };
  }
' $SEQ $ODIR/$SEQ.gff > $EDIR/$SEQ.report || TheEnd GAWKKO ;
#
# $BIN/getHSPSR.pl is not needed here as we are already taken HSP-SRs...
#
#># END_OF_STEP --------------------------------------------------------------#<#
@
%$

\chklst{
\item ...
}

\subsubsctn{Preparing auxiliarly files}

<<STEPS(SGP HSAPgpa x MmusMGSCv3+RKNcDNA): Auxiliarly files>>=
####>#########>#######################<########################################<#
#># STEP_ID   AUX_FILES
#># STEP_DESC Preparing auxiliarly files: CHR.termini
#># STEP_PATH tmp
#># STEP_XID  $<JOB{.}{JOB_XID}>
#># STEP_IDIR .
#># STEP_ODIR $JOBDIR/$<STEP{.}{.}{STEP_PATH}>
#># STEP_EDIR $JOBDIR/$<STEP{.}{.}{STEP_PATH}>
#># STEP_CODE   --------------------------------------------------------------#<#
#
#<# ODIR="$HUMUS/$NCHR/sgp/$XID/tmp" ;
#<# LEN="$HUMUS/$NCHR/annotation/$HSAPID/length" ;
LEN="$CHRDIR/$<JOB{HSAP_GP_ANNOTATION}{JOB_PATH}>/$<JOB{HSAP_GP_ANNOTATION}{JOB_XID}>/length" ;
#
CheckFile R $LEN ;
#
perl -e '
  use strict;
  my $chr = shift @ARGV;
  my %SEQlen;
  my $seqln = shift @ARGV;
  open(FRGLEN, "< $seqln");
  while (<FRGLEN>) {
      next if /^#/o;
      next if /^\s*$/o;
      chomp;
      my @l = split /\s+/og, $_;
      $SEQlen{$l[0]} = $l[1];
  }; # while
  close(FRGLEN);
  print STDOUT join("\t", $chr, qw/ force cap  -2  0 . + 0 / )."\n";
  print STDOUT join("\t", $chr, qw/ force poly /,
                        ($SEQlen{$chr} - 1) x 2, qw/ . + 0/ )."\n";
' $SEQ $LEN > $ODIR/$SEQ.termini || TheEnd PERLKO ;
#
#># END_OF_STEP --------------------------------------------------------------#<#
@
%$

\chklst{
\item ...
}

\subsubsctn{Running {\sgp} ({\gnid} with homology)}

<<STEPS(SGP HSAPgpa x MmusMGSCv3+RKNcDNA): Running SGP>>=
####>#########>#######################<########################################<#
#># STEP_ID   SGP_HSAPgpa_MGSCv3
#># STEP_DESC Running geneid on Hsapiens sequences from Golden Path assembly
#>#         : with homology evidences taken from MGSC v3 assembly.
#># STEP_PATH out
#># STEP_XID  $<JOB{.}{JOB_XID}>
#># STEP_IDIR $HUMUS/$NCHR/$<JOB{.}{JOB_PATH}>/$XID
#># STEP_ODIR $JOBDIR/$<STEP{.}{.}{STEP_PATH}>
#># STEP_EDIR $JOBDIR/logs
#># STEP_CODE   --------------------------------------------------------------#<#
#
#<# 
#
GENEID="$SRC/geneid_v1.1-sgp/bin/geneid" ; # geneid v1.1-sgp
PARAM="$SRC/geneid_v1.1-sgp/param/human3iso.param.sgp" ;
EW=0 ; # add to exon weigth
#
#<# ISEQ="$HSAP/chromFaMasked/$CHRNUM/$SEQ.fa.masked" ; 
#<# IDIR="$HUMUS/$NCHR/sgp/$XID/" ;
#<# ODIR="$HUMUS/$NCHR/sgp/$XID/out" ;
#--> we do not run geneid on masked sequences at this moment
#--> we are using original un-masked fasta sequences from GP
ISEQ="$HSEQ/$SEQ.fa" ;
#
HOMOLOGY="$HUMUS/$NCHR/sgp/$XID/hsp-sr/$SEQ.gff" ;
if [ -f "$HOMOLOGY" ] ;
  then
    echo "### Using homology data from: $HOMOLOGY" 1>&2 ;
    HOMOLOGY_PAR="-S $HOMOLOGY" ;
  else
    echo "### Homology file NOT found: $HOMOLOGY" 1>&2 ;
    HOMOLOGY_PAR="" ;
  fi ;
#
TERMINI="$IDIR/tmp/$SEQ.termini" ;
if [ -f "$TERMINI" ] ;
  then
    echo "### Using termini file: $TERMINI" 1>&2 ;
    TERMINI_PAR="-R $TERMINI" ;
  else
    TERMINI_PAR="" ;
  fi ;
#
CheckFile R $PARAM $ISEQ ;
#
GENEID_CMDLN="-v -DE $EW -P $PARAM $HOMOLOGY_PAR $TERMINI_PAR $ISEQ" ;
echo "$GENEID $GENEID_CMDLN 2> $EDIR/$SEQ.sgp" 1>&2 ;
( $GENEID $GENEID_CMDLN 2> $EDIR/$SEQ.sgp || TheEnd CKO ) \
           | grep -v 'evidence' > $ODIR/$SEQ ;
#
( cat $EDIR/$SEQ.sgp 1>&2 ) || TheEnd CMDKO ;
#
#># END_OF_STEP --------------------------------------------------------------#<#
@ 

\chklst{
\item ...
}

\subsubsctn{Processing output for {\sgp} (with homology)}

<<STEPS(SGP HSAPgpa x MmusMGSCv3+RKNcDNA): Processing SGP results>>=
####>#########>#######################<########################################<#
#># STEP_ID   SGP_OUTPUT
#># STEP_DESC Processing geneid format from sgp output (with homology).
#># STEP_PATH gff
#># STEP_XID  $<JOB{.}{JOB_XID}>
#># STEP_IDIR $HUMUS/$NCHR/$<JOB{.}{JOB_PATH}>/$XID
#># STEP_ODIR $JOBDIR/$<STEP{.}{.}{STEP_PATH}>
#># STEP_EDIR $JOBDIR/$<STEP{.}{.}{STEP_PATH}>
#># STEP_CODE   --------------------------------------------------------------#<#
#
#<# IDIR="$HUMUS/$NCHR/sgp/$XID" ;
#
CheckFile R $IDIR/out/$SEQ ;
#
$BIN/geneid_raw2GFF.pl $SEQ $IDIR $IDIR/out/$SEQ ;
#
( ls -1 $IDIR/gff/$SEQ.sg/ | egrep "^$SEQ" | \
    while read n;
      do {
        cat $IDIR/gff/$SEQ.sg/$n;
        };
      done | sort +3n +4n -5 - > $IDIR/gff/$SEQ ) || TheEnd BASHKO ;
#
get_geneid_genes $IDIR/gff/$SEQ > $IDIR/$SEQ.gene_list || TheEnd FUNCKO ;
#
#># END_OF_STEP --------------------------------------------------------------#<#
@
%$

\chklst{
\item Number of genes, average length, average exon number, exon/intron length ratio...
\item ...
}


\subsubsctn{Evaluation of {\sgp} predictions (with homology)}

<<STEPS(SGP HSAPgpa x MmusMGSCv3+RKNcDNA): Evaluating SGP results>>=
####>#########>#######################<########################################<#
#># STEP_ID   SGP_EVALUATION
#># STEP_DESC Evaluation of SGP predictions (geneid with homology).
#># STEP_PATH eval
#># STEP_XID  $<JOB{.}{JOB_XID}>
#># STEP_IDIR $JOBDIR/$<STEP{.}{SGP_OUTPUT}{STEP_PATH}>
#># STEP_ODIR $JOBDIR/$<STEP{.}{.}{STEP_PATH}>
#># STEP_EDIR $JOBDIR/$<STEP{.}{.}{STEP_PATH}>
#># STEP_CODE   --------------------------------------------------------------#<#
#
#<# IDIR="$HUMUS/$NCHR/sgp/$XID" ;
CheckFile R $IDIR/$SEQ ;
gawk '$3~/^(Single|First|Internal|Terminal)$/ {print $0}' \
               $IDIR/$SEQ > $ODIR/$SEQ.eval.gff || TheEnd GAWKKO ;
$BIN/gffsplitstrand.pl $ODIR/$SEQ.eval.gff ; # no sequence length record required here
#
A_REFSEQ="$CHRDIR/$<JOB{HSAP_GP_ANNOTATION}{JOB_PATH}>/$<JOB{HSAP_GP_ANNOTATION}{JOB_XID}>/$<STEP{HSAP_GP_ANNOTATION}{HSAP_GP_REFSEQ}{STEP_PATH}>/$SEQ.eval" ;
A_ENSEMBL="$CHRDIR/$<JOB{HSAP_GP_ANNOTATION}{JOB_PATH}>/$<JOB{HSAP_GP_ANNOTATION}{JOB_XID}>/$<STEP{HSAP_GP_ANNOTATION}{HSAP_GP_ENSEMBL}{STEP_PATH}>/$SEQ.eval" ;
cat > $ODIR/${SEQ}.summary <<EOT ;
#
# Evaluation summary results for SGP on CHROM[$CHR] - SEQ[$SEQ]
#
EOT
#
CheckFile R $A_REFSEQ.fwd.gff  $A_REFSEQ.rev.gff  \
            $A_ENSEMBL.fwd.gff $A_ENSEMBL.rev.gff ;
#
$BIN/runeval.pl $A_REFSEQ.fwd.gff $ODIR/$SEQ.eval.fwd.gff                                     \
    "${CHR}::${HSAPID}x${MGSC_RKN}::REFSEQ::FWD::SGP-MGSCv3+RKNcDNA::geneid_1.1::." \
    >> $ODIR/${SEQ}.summary 2> $ODIR/${SEQ}.sgp_refseq.fwd ;
$BIN/runeval.pl $A_REFSEQ.rev.gff $ODIR/$SEQ.eval.rev.gff                                     \
    "${CHR}::${HSAPID}x${MGSC_RKN}::REFSEQ::REV::SGP-MGSCv3+RKNcDNA::geneid_1.1::." \
    >> $ODIR/${SEQ}.summary 2> $ODIR/${SEQ}.sgp_refseq.rev ;
$BIN/runeval.pl $A_ENSEMBL.fwd.gff $ODIR/$SEQ.eval.fwd.gff                                     \
    "${CHR}::${HSAPID}x${MGSC_RKN}::ENSEMBL::FWD::SGP-MGSCv3+RKNcDNA::geneid_1.1::." \
    >> $ODIR/${SEQ}.summary 2> $ODIR/${SEQ}.sgp_ensembl.fwd ;
$BIN/runeval.pl $A_ENSEMBL.rev.gff $ODIR/$SEQ.eval.rev.gff                                     \
    "${CHR}::${HSAPID}x${MGSC_RKN}::ENSEMBL::REV::SGP-MGSCv3+RKNcDNA::geneid_1.1::." \
    >> $ODIR/${SEQ}.summary 2> $ODIR/${SEQ}.sgp_ensembl.rev ;
#
#># END_OF_STEP --------------------------------------------------------------#<#
@

\chklst{
\item ...
}


\sctn{Visualizing results}

\subsctn{Visualizing annotations with {\apo}}

<<JOBheader: Visualizing Results with Apollo>>=
####>#########>#######################<########################################<#
#># JOB_ID    APOLLO_VIEWER
#># JOB_DESC  Preparing all the files required to show the results on the Apollo
#>#        :  genomic annotations browser. Apollo is a collaborative project 
#>#        :  between the Berkeley Drosophila Genome Project (www.bdgp.org) and 
#>#        :  Ensembl (www.ensembl.org). 
#>#        :  URL: http://www.ensembl.org/apollo/
#># JOB_PATH  apollo
#># JOB_XID   20020225
#># JOB_FILE  ${LIBSTEP}/apollo.job
#># END_OF_JOB ##################################################################
@ 

<<JOBS: Visualizing Results with Apollo>>=
<<STEPS(Apollo Browser): >>
@ 

\subsubsctn{Preparing GFF files for {\apo}}

<<STEPS(Apollo Browser): >>=
@ 
<<Visualizing: >>=
#
IDIR="$HUMUS/$NCHR" ;
ODIR="$IDIR/apollo" ;
#
MkDirs $ODIR $ODIR/$XID ;
#
ODIR="$ODIR/$XID" ;
#
gawk 'BEGIN{OFS="\t"}
      ($0 !~ /^[ \t]*$/ && $1 !~ /^\#/) {
          $6=1; 
          print $1,$2,$3,$4,$5,$6,$7,$8,$9;
      }
     ' $IDIR/annotation/$HSAPID/gaps/${CHR}.gff \
     > $ODIR/${CHR}_gaps.gff ;
#
gawk 'BEGIN{OFS="\t"}
      ($0 !~ /^[ \t]*$/ && $1 !~ /^\#/) {
          print $1,$2,$3,$4,$5,$6,$7,$8,$9;
      }
     ' $IDIR/annotation/$HSAPID/repeats/${CHR}.gff \
     > $ODIR/${CHR}_repeats.gff ;
#
gawk 'BEGIN{OFS="\t"}
      ($0 !~ /^[ \t]*$/ && $1 !~ /^\#/) {
          $3="exon"; $6=1; print $0;
      }
     ' $IDIR/annotation/$HSAPID/refseq/${CHR}.gff \
     > $ODIR/${CHR}_refseq.gff ;
#
gawk 'BEGIN{OFS="\t"}
      ($0 !~ /^[ \t]*$/ && $1 !~ /^\#/) {
          $3="exon";
          $6=1;
          gsub(/ENST0+/,"ENST",$9);
          print $0;
      }
     ' $IDIR/annotation/$HSAPID/ensembl/${CHR}.gff \
     > $ODIR/${CHR}_ensembl.gff ;
#
gawk 'BEGIN{OFS="\t"}
      ($0 !~ /^[ \t]*$/ && $1 !~ /^\#/) {
          $3="exon"; $6=1; print $0;
      }
     ' $IDIR/annotation/$HSAPID/genscan/${CHR}.gff \
     > $ODIR/${CHR}_genscan.gff ;
#
gawk 'BEGIN{OFS="\t"}
      ($0 !~ /^[ \t]*$/ && $1 !~ /^\#/) {
          $2="geneid";
          $3="exon"; 
          gsub(/chr.*_/,"",$9);
          print $0;
      }
     ' $IDIR/geneid/$XID/gff/${CHR} \
     > $ODIR/${CHR}_geneid.gff ;
#
gawk 'BEGIN{OFS="\t"}
      ($0 !~ /^[ \t]*$/ && $1 !~ /^\#/) {
          $2="homology";
          $3="hsp-sr";
          $8=".";
          print $0;
      }
     ' $IDIR/sgp/20020122/hsp-sr/${CHR}.gff \
     > $ODIR/${CHR}_hsp-sr.gff ;
#
gawk 'BEGIN{OFS="\t"}
      ($0 !~ /^[ \t]*$/ && $1 !~ /^\#/) {
          $2="sgp";
          $3="exon"; 
          gsub(/chr.*_/,"",$9);
          print $0;
      }
     ' $IDIR/sgp/20020122/gff/${CHR} \
     > $ODIR/${CHR}_sgp.gff ;
#
gawk 'BEGIN{OFS="\t"}
      ($0 !~ /^[ \t]*$/ && $1 !~ /^\#/) {
          $2="homology+";
          $3="hsp-sr"; 
          $8=".";
          print $0;
      }
     ' $IDIR/sgp+/20020212/hsp-sr/${CHR}.gff \
     > $ODIR/${CHR}_hsp-sr+.gff ;
#
gawk 'BEGIN{OFS="\t"}
      ($0 !~ /^[ \t]*$/ && $1 !~ /^\#/) {
          $2="sgp+";
          $3="exon"; 
          gsub(/chr.*_/,"",$9);
          print $0;
      }
     ' $IDIR/sgp+/20020212/gff/${CHR} \
     > $ODIR/${CHR}_sgp+.gff ;
#
cat $ODIR/${CHR}_gaps.gff    \
    $ODIR/${CHR}_repeats.gff \
    $ODIR/${CHR}_refseq.gff  \
    $ODIR/${CHR}_ensembl.gff \
    $ODIR/${CHR}_genscan.gff \
    $ODIR/${CHR}_geneid.gff  \
    $ODIR/${CHR}_hsp-sr.gff  \
    $ODIR/${CHR}_sgp.gff     \
    $ODIR/${CHR}_hsp-sr+.gff \
    $ODIR/${CHR}_sgp+.gff    \
  > $ODIR/all_${CHR}.gff
#
@


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\newpage %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\sctn{Quick tests section}

\subsctn{Gene Prediction: {\sgp}} %%%%%%%%%%%%%%%%%%%%%%

<<SGP: >>=
#
# Initialization
# 
ODIR="$HUMUS/$NCHR/sgp+/$XID" ;
#
MkDirs $ODIR ;
for c in hsp-sr out gff gtf2 cds prot logs tmp ;
    do { MkDirs $ODIR/$c ; } ; done ;
#
@

\subsubsctn{Re-scoring SRs}

<<SGP: >>=
#
# Re-scoring SRs to produce HSP-SRs
#
IDIR="$HUMUS/$NCHR/tblastx+/$XID/sr" ;
ODIR="$HUMUS/$NCHR/sgp+/$XID/hsp-sr" ;
#
$BIN/getHSPSR.pl $SEQ < $IDIR/$SEQ.merged.gff \
                      > $ODIR/$SEQ.gff 2> $ODIR/$SEQ.report ;
#
@

\subsubsctn{Preparing auxiliarly files}

<<SGP: >>=
#
# Preparing auxiliarly files: CHR.termini
#
ODIR="$HUMUS/$NCHR/sgp+/$XID/tmp" ;
SDIR="$HUMUS/$NCHR/annotation/$HSAPID" ;
#
perl -e '
  use strict;
  my $chr = shift @ARGV;
  my %SEQlen;
  my $seqln = shift @ARGV;
  open(FRGLEN, "< $seqln");
  while (<FRGLEN>) {
      next if /^#/o;
      next if /^\s*$/o;
      chomp;
      my @l = split /\s+/og, $_;
      $SEQlen{$l[0]} = $l[1];
  }; # while
  close(FRGLEN);
  print STDOUT join("\t", $chr, qw/ force cap  -2  0 . + 0 / )."\n";
  print STDOUT join("\t", $chr, qw/ force poly /,
                        ($SEQlen{$chr} - 1) x 2, qw/ . + 0/ )."\n";
' $SEQ $SDIR/length > $ODIR/$SEQ.termini ;
#
@

\subsubsctn{Running {\sgp} ({\gnid} with homology)}

<<SGP: >>=
#
# Running geneid with homology
#
SGP2="/projects/sgp/src/geneid_v1.1-sgp" ;
     # binaries, scripts and params in SGP2
GENEID="$SGP2/bin/geneid" ; # geneid v1.1-sgp
PARAM="$SGP2/param/human3iso.param.sgp" ;
EW=0 ; # add to exon weigth
#
# ISEQ="$HSAP/chromFaMasked/$CHRNUM/$SEQ.fa.masked" ; 
#--> we do not run geneid on masked sequences at this moment
#--> we are using original un-masked fasta sequences from GP
ISEQ="$HSAP/chromosomes/$SEQ.fa" ;
IDIR="$HUMUS/$NCHR/sgp+/$XID/" ;
# ODIR="$HUMUS/$NCHR/sgp/$XID/out" ;
HOMOLOGY="$HUMUS/$NCHR/sgp+/$XID/hsp-sr/$SEQ.gff" ;
#
# {
  { $GENEID -v -DE $EW -P $PARAM -S $HOMOLOGY \
        -R $IDIR/tmp/$SEQ.termini $ISEQ | grep -v evidence \
        > $IDIR/out/$SEQ ;
  } 2> $IDIR/logs/$SEQ ;
#   } 2>&1 | tee $HUMUS/logs/geneid_sgp.$locus ;
#
@ 

\subsubsctn{Processing output for {\sgp} (with homology)}

<<SGP: >>=
#
# Processing geneid format from sgp output (with homology)
#
IDIR="$HUMUS/$NCHR/sgp+/$XID" ;
#
$BIN/geneid_raw2GFF $SEQ $IDIR $IDIR/out/$SEQ ;
#
ls -1 $IDIR/gff/ | egrep "^$SEQ" | \
  while read n;
    do {
         cat $IDIR/gff/$n;
       };
    done | sort +3n +4n -5 - > $IDIR/gff/$SEQ ;
#
get_geneid_genes $IDIR/gff/$SEQ > $IDIR/out.gene_list ;
#
@

\subsubsctn{Evaluation of {\sgp} predictions (with homology)}

<<SGP: >>=
#
# Evaluation of SGP predictions (with homology)
#
IDIR="$HUMUS/$NCHR/sgp+/$XID" ;
#
#
@

\subsctn{Running {\sgp} with homology and evidences}

<<SGP: >>=
#
#  Running geneid with homology + evidences
#
SGP2="/projects/sgp/src/geneid_v1.1-sgp" ;
     # binaries, scripts and params in SGP2
GENEID="$SGP2/bin/geneid" ; # geneid v1.1-sgp
PARAM="$SGP2/param/human3iso.param.sgp" ;
EW=0 ; # add to exon weigth
#
ISEQ="$HSAP/chromFaMasked/$CHRNUM/$SEQ.fa.masked" ;
IDIR="$HUMUS/$NCHR/sgp/$XID/" ;
# ODIR="$HUMUS/$NCHR/sgp/$XID/out" ;
HOMOLOGY="$HUMUS/$NCHR/sgp/$XID/hsp-sr/$SEQ.gff" ;
EVIDENCES="/$SEQ.gff" ;
#
{ $GENEID -v -D -E $EW -P $PARAM -S $HOMOLOGY \
        -R $EVIDENCES $ISEQ > $IDIR/out/$SEQ ;
  } 2> $IDIR/logs/$SEQ ;
#  } 2>&1 | tee $HUMUS/logs/geneid_sgp.$locus ;
#
@

\chklst{
\item ...
}

\subsctn{Masking gene-predictions along masked sequences}

<<Global: >>=
#
#
# HUMUS="$BASE/H.sapiens" -> .project_VARS
#
CHRLIST="22" ;
#
for n in $CHRLIST;
  do {
       chrdir="$HUMUS/chr$n" ;
       MkDirs $chrdir ;
       MkDirs $chrdir/tblastx+ $chrdir/sgp+ ;
     };
  done ;
#
CHRNUM="22" ; # length -> 47748585
CHR="chr$CHRNUM" ;
XID="20020212";
#
@

<<>>=
# bash
# CLEAR, RESET, CONCEALED,
# BOLD, DARK, UNDERLINE, UNDERSCORE, BLINK, REVERSE,
# BLACK, RED, GREEN, YELLOW, BLUE, MAGENTA, 
# ON_BLACK, ON_RED, ON_GREEN, ON_YELLOW, ON_BLUE, ON_MAGENTA, ON_CYAN, and ON_WHITE 
#
function show_masked {
    perl -npe '
        use Term::ANSIColor;
        s/^(>.*?)(\s+.*)$/color("bold red").$1.color("reset").$2/oe;
        # masked
        s/(N+)/color("green").$1.color("reset")/oge;
        s/(n+)/color("yellow").$1.color("reset")/oge;
        # starts
        s/(ATG)/color("black on_green").$1.color("reset")/oge; # forward
        s/(CAT)/color("white on_green").$1.color("reset")/oge; # reverse
        # stops
        s/(TAA|TAG|TGA)/color("black on_red").$1.color("reset")/oge; # forward
        s/(TTA|CTA|TCA)/color("white on_red").$1.color("reset")/oge; # reverse
    ' "$@" | more
}
#
@ 

\subsubsctn{Masking cds on Pankaj masked sequence fragments}

\begin{center}
% \fbox{
  \begin{minipage}{0.95\linewidth}
   \textbf{What to do here:}
   \begin{itemize}
    \item Mask CDSs predicted by {\sgp} on the sequence fragmetns already masked by Pankaj.
   \end{itemize}
  \end{minipage}
% } % fbox
\end{center}

<<>>=
perl -e '
  use strict;
  my ($base,$ipath,$opath,$gnlst,@files,
      %offset,%cds,%genes,$n,$totgns,$totcds,$tgenes,$tcds);
  my $chr = shift @ARGV;
  $base = "/projects/H.sapiens";
  $ipath = "$base/.ftp/PankajAgarwal/20020123.seq-masked";
  $opath = "$base/.ftp/PankajAgarwal/20020208.seq-masked+genes-masked";
  my $gff = "$base/$chr/sgp/20020122/gff/$chr";
  # $gnlst = "$base/$chr/sgp/20020122/out.gene_list";
  # getting input filenames
  opendir(NA,$ipath);
  @files = grep { /^$chr/ } readdir(NA);
  closedir(NA);
  print STDERR "## Found ".scalar(@files)." input files for $chr...\n";
  # get sequence starting coord offset
  foreach my $fl (@files) {
      $fl =~ /_(\d+)_\d+$/o && ($offset{$1} = $fl);
  };
 #
  # reading gene coords
  # open(GF,"< $gnlst");
  # $n = 0;
  # while (<GF>) {
  #     my @l;
  #     next if /^#/o;
  #     next if /^\s*$/o;
  #     chomp;
  #     @l = split /\s+/og, $_, 5;
  #     $genes{$n++} = [ @l[1,2],"$l[0]$l[3]" ];
  # };
  # close(GF);
  # $tgenes = $n;
  # print STDERR "## Found $tgenes genes to mask on $chr...\n";
 #
  # reading from GFF
  open(GFF,"< $gff");
  $n = 0;
  %genes = ();
  while (<GFF>) {
      my @l;
      next if /^#/o;
      next if /^\s*$/o;
      chomp;
      @l = split /\s+/og, $_;
      $cds{$n++} = [ @l[3,4],"$l[8]$l[6]" ];
      $genes{"$l[8]$l[6]"}++;
  };  
  close(GFF);
  $tgenes = scalar (keys %genes);
  $tcds   = $n;
  print STDERR "## Found $tgenes genes ($tcds cds) to mask on $chr...\n";
  # processing fastas
  $totgns = $totcds = 0;
  foreach my $fl (sort keys %offset) {
      my ($sqn,$fstg,$fcds);
      open(FI,"< $ipath/$offset{$fl}");
      open(FO,"> $opath/$offset{$fl}.cds");
      $sqn = $fl;
      $n = $fstg = $fcds = 0;
      %genes = ();
      while ($cds{$n}[1] <= $fl) { $n++; }; # if gene ends before sequence ori
      while (<FI>) {
          my (@l,$ln);
          next if /^\s*$/o;
          /^>/o && do {
              print FO $_;
              next;
          };
          chomp;
          s/\s*$//o; s/^\s*//o;
          @l = split //, uc($_);
          $ln = "";
          for (my $i = 0; $i <= $#l; $i++) {
              $sqn++;
              $ln .= ($sqn >= $cds{$n}[0] && $sqn <= $cds{$n}[1]) 
                     ? "n" : $l[$i] ;
              ($sqn == $cds{$n}[0]) && ($fcds++);
              ($sqn == $cds{$n}[1]) && ($n++, $genes{$cds{$n}[2]}++);
          }; 
          print FO "$ln\n";
      };
      close(FO);
      close(FI);
      $fstg = scalar (keys %genes);
      print STDERR "### $fstg genes ($fcds cds) were masked on \"$offset{$fl}\"...\n";
      # $totgns += $fstg;
      $totgns += $fstg;
      $totcds += $fcds;
  };
  print STDERR "### $totgns of $tgenes genes ($totcds of $tcds cds) were masked on $chr...\n";
  # counter sums are not well done... but masking is ok
' chr22 2> ./masking_cds.log ; # 2> ./masking_genes.log ;
@ 


\subsubsctn{Processing Pankaj {\tbx} results}

\begin{center}
% \fbox{
  \begin{minipage}{0.95\linewidth}
   \textbf{What to do here:}
   \begin{itemize}
 \item Process {\tbx} results from Pankaj:
  \begin{itemize}
   \item Masked sequences plus {\sgp} predicted cds also masked (20020208).
   \item Mouse genome assembly from Sanger Center Phusion assembly (20011109 ???).\\[-3ex]
\begin{verbatim}
# Database:  /bioinfo/gapdb/blastdb/MusPhusion
# Title:  MusPhusion
# # of letters in database:  2,374,690,634  (Z = 3000000000)
# # of sequences in database:  431,480
# Format:  XDF-1
# Created:  5:32:13 PM EST Dec 10, 2001
# Posted:  5:32:14 PM EST Dec 10, 2001
\end{verbatim}
   \item {\tbx} was run with the following parameters:\\[-3ex]
%	   \begin{center}
%	   \begin{minipage}[c]{0.75\linewidth}
\begin{verbatim}
W=5  Z=3000000000
matrix=blosum62mod  filter=xnu+seg
nogaps  hspmax=500  topcomboN=100
B=9000  V=9000  E=0.01  E2=0.01  S2=80
warnings  cpus=4  ctxfactor=36.0
\end{verbatim}
% tail -54 ori/chr22_* | sort | uniq -c | sort +0nr | more
%	   \end{minipage}
%	   \end{center}
  \end{itemize}
\item Get HSPs $\Rightarrow$ SRs $\Rightarrow$ HSP-SRs
   \end{itemize}
  \end{minipage}
% } % fbox
 \end{center}

<<Homology: >>=
#
# Unpacking TBLASTX results obtained by Pankaj
#
IDIR="$HUMUS/.ftp/PankajAgarwal/20020212.genes-masked+tbxPhusion" ;
ODIR="$HUMUS/$NCHR/tblastx+/$XID" ;
#
MkDirs $ODIR $ODIR/ori ;
#
mv -v $IDIR/${CHR}* $ODIR/ori ;
#
$BIN/sbp_checkblastout.pl $SEQ $ODIR/ori > $ODIR/ori/$SEQ.report ;
#
@ 

\subsubsctn{Retrieving {\tbx} results by chromosome}

<<Homology: >>=
#
# Retrieving TBLASTX results by chromosome
#
IDIR="$HUMUS/$NCHR/tblastx+/$XID/ori" ;
ODIR="$HUMUS/$NCHR/tblastx+/$XID/hsp" ;
SDIR="$HUMUS/$NCHR/annotation" ;
#
MkDirs $ODIR ;
#
$BIN/sbp_blast2gff.pl $SEQ $SDIR/$HSAPID/length $IDIR \
         > $ODIR/$SEQ.fullgff 2> $ODIR/$SEQ.report ;
#
perl -ne '/^#/o && next; /^\s+$/o && next; 
          $_ =~ s/;\s+Strand//o; 
          $_ =~ s/;\s+Frame//o; 
          $_ =~ s/;\s+E_value.*$//o;
          print STDOUT $_;' $ODIR/$SEQ.fullgff | \
          sort +3n -6 +6 -7 - > $ODIR/$SEQ.gff ;
#
@ 

\subsubsctn{Merging HSPs from first {\tbx} run and the new ones}

<<Homology: >>=
#
# Merging TBLASTX results 
PXID="20020122" ; # XID of the tblastx run we want to merge (default PXID==XID)
IDIR="$HUMUS/$NCHR/tblastx/$PXID/hsp" ;
ODIR="$HUMUS/$NCHR/tblastx+/$XID/hsp" ;
#
cat $IDIR/$SEQ.gff $ODIR/$SEQ.gff |  \
          sort +3n -6 +6 -7 - > $ODIR/$SEQ.merged.gff ;
#
@ 

\subsubsctn{Projecting HSPs into SRs}

<<Homology: >>=
#
# Projecting HSPs into SRs
#
IDIR="$HUMUS/$NCHR/tblastx+/$XID/hsp" ;
ODIR="$HUMUS/$NCHR/tblastx+/$XID/sr" ;
#
MkDirs $ODIR ;
#
BLAST2GFF="/projects/bin/blast2gff";
$BLAST2GFF -g $IDIR/$SEQ.gff > $ODIR/$SEQ.gff ;
$BLAST2GFF -g $IDIR/$SEQ.merged.gff > $ODIR/$SEQ.merged.gff ;
#
gawk '
  BEGIN{ chr=ARGV[1]; ARGV[1]=""; }
  ($0 !~ /^[ \t]*$/ && $1 !~ /^\#/) { a[$7.$8]++; b[$7]++ }
  END{ 
    printf "# TOTAL %s SRs on %s: %s forward, %s reverse.\n", 
           b["+"]+b["-"], chr, b["+"], b["-"];
    for (i in a) {
      printf "#  \t%s : %s\n", i, a[i];
    };
  }
' $SEQ $ODIR/$SEQ.gff > $ODIR/$SEQ.report ;
#
gawk '
  BEGIN{ chr=ARGV[1]; ARGV[1]=""; }
  ($0 !~ /^[ \t]*$/ && $1 !~ /^\#/) { a[$7.$8]++; b[$7]++ }
  END{ 
    printf "# TOTAL %s SRs on %s: %s forward, %s reverse.\n", 
           b["+"]+b["-"], chr, b["+"], b["-"];
    for (i in a) {
      printf "#  \t%s : %s\n", i, a[i];
    };
  }
' $SEQ $ODIR/$SEQ.merged.gff > $ODIR/$SEQ.merged.report ;
#
@


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\newpage %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\sctn{Working on {\lmmus} sequences}

<<>>=
# GET SEQS
$BIN/getfastadesc.pl $MySQLPAR/Mmusculus_chrs.tbl $MSEQ \
                     > $MUSHU/seqid_list 2> $MUSHU/seqid_list.rpt ;
   ## checking execution status of getfastadesc.pl
   grep '^\#\# ' seqid_list.rpt | \
     gawk '{
         gsub(/[\"]/,"",$7);
         printf "\n%s %s %s %s",$1,$2,$3,$6"-> "$7
       }
       END{ printf " <-\n"; }' | sort +4n ;
#
# INITIALIZE
gawk '$1!~/^\#/ {print $1}' $MUSHU/seqid_list | \
  while read CHR ;
    do {
      ODIR="$MUSHU/chr$CHR" ;
      MkDirs $ODIR ;
      gawk 'BEGIN{ chrom="\^"ARGV[1]"\$"; ARGV[1]=""; }
            $1 ~ chrom { print $0; }
           ' $CHR $MUSHU/seqid_list > $ODIR/desc ;
      gawk '{ print $2, $3; }' $ODIR/desc > $ODIR/length ;
      gawk 'BEGIN{ OFS="\t"; ofile=ARGV[1]; s="Sequence"; d="." }
            { print $1,s,s,1,$2,d,d,d,1 > ofile"."$1".gff"; }
           ' $ODIR/length ;
      } ;
    done ;
#
gawk '$1!~/^\#/ {print $1}' $MUSHU/seqid_list | \
  while read CHR ;
    do {
       cat $MUSHU/chr$CHR/length ;
       } ;
    done > $MUSHU/all_length ;
#
# RETRIEVE INVTBX HSPs FROM TBX[HsapSQ-MmusDB]
# gawk '$1!~/^\#/ {print $1}' $MySQLPAR/Mmusculus_chrs.tbl | \
MkDirs $MUSHU/invTBX $MUSHU/invTBX/$FTPTBXID ;
gawk 'BEGIN{ prt=1 }
      $1~/^6$/ { prt=0 }
      { if (prt) print $0 }
      ' $HUMUS/seqid_list > $MUSHU/bin/hsap.seqid_a ;
gawk 'BEGIN{ prt=0 }
      $1~/^6$/ { prt=1 } $1~/^11$/ { prt=0 }
      { if (prt) print $0 }
      ' $HUMUS/seqid_list > $MUSHU/bin/hsap.seqid_b ;
gawk 'BEGIN{ prt=0 }
      $1~/^11$/ { prt=1 } $1~/^16$/ { prt=0 }
      { if (prt) print $0 }
      ' $HUMUS/seqid_list > $MUSHU/bin/hsap.seqid_c ;
gawk 'BEGIN{ prt=0 }
      $1~/^16$/ { prt=1 }
      { if (prt) print $0 }
      ' $HUMUS/seqid_list > $MUSHU/bin/hsap.seqid_d ;
# ls -1 bin/hsap.seqid_* | while read n; do echo "$n ->"`gawk '{s+=$3}END{print s}' $n`; done
cnt=0; ko="a"; 
cnt=0; ko="b"; 
cnt=0; ko="c"; 
cnt=0; ko="d";
gawk '$1!~/^\#/ {print $1, $2}' $MUSHU/bin/hsap.seqid_$ko | \
    while read CH SQ;
      do { # HUMUS=/projects/H.sapiens/20011222.UCSCgp
        ls "-1" $HUMUS/chr$CH/tblastx/$FTPTBXID/hsp/$SQ.fullgff ; 
      } ;
    done | \
  while read file ;
    do {
      $BIN/swapHSPcoords.pl -o "-1" \
            -a $MUSHU/invTBX/$FTPTBXID/'_*_'.$ko\_$cnt.fullgff \
            $MUSHU/all_length $file ;
      cnt=`expr $cnt + 1` ;
      } ;
    done ;
#
# RUN RAW GENEID on MASKED SEQUENCES
gawk '$1!~/^\#/ {print $1, $2}' $MUSHU/seqid_list | \
  while read CHR SEQ ;
    do {
      ODIR="$MUSHU/chr$CHR" ;
      ###
      echo "# RUNNING GENEID on $CHR" 1>&2 ;
      GDIR="$ODIR/geneid" ;
      MkDirs $GDIR $GDIR/$FTPTBXID ;
      GDIR="$ODIR/geneid/$FTPTBXID" ;
      for c in out gff gtf2 cds prot logs tmp eval ;
        do { MkDirs $GDIR/$c ; } ; done ;
      GENEID="$SRC/geneid_v1.1/bin/geneid" ; # geneid v1.1
      PARAM="$SRC/geneid_v1.1/param/human3iso.param" ;
      EW=0 ; # add to exon weigth
      ISEQ="$MSEQMSK/$SEQ.fa.masked" ;
      GENEID_CMDLN="-v -DE $EW -P $PARAM $ISEQ" ;
      echo "$GENEID $GENEID_CMDLN" 1>&2 ;
      $GENEID $GENEID_CMDLN 2> $GDIR/logs/$SEQ.geneid | \
              grep -v 'evidence' > $GDIR/out/$SEQ ;
      $BIN/geneid_raw2GFF.pl $SEQ $GDIR $GDIR/out/$SEQ ;
      #
      ls -1 $GDIR/gff/$SEQ.sg/ | egrep "^$SEQ" | \
      while read n;
        do {
          cat $GDIR/gff/$SEQ.sg/$n;
          };
        done | sort +3n +4n -5 - > $GDIR/gff/$SEQ ;
      #
      gawk '($0 !~ /^[ \t]*$/ && $1 !~ /^\#/) { # get_geneid_genes 
        genes[$9]++;
        if (genes[$9]>1) {
          min[$9] = $4<min[$9] ? $4 : min[$9] ;
          max[$9] = $5>max[$9] ? $5 : max[$9] ;
        } else {
          min[$9] = $4 ;
          max[$9] = $5 ;
          strand[$9] = $7;
        };
        len[$9]+=$5-$4+1
      }
      END {
        for (n in genes) {
          print n, min[n], max[n], strand[n], len[n],genes[n];
        };
      }' $GDIR/gff/$SEQ | \
         sort +1n +2n -3 - > $GDIR/$SEQ.gene_list ;
      } ;
    done ;
##
@ 

<<runallmouse.sh>>=
###
### runallmouse.sh ### RUNNING ALMOST EVERYTHING ON MOUSE !!!
###
<<BASH Project Variables>>
# $MUSHU/seqid_list
SEQID="$1" ;
gawk '$1!~/^\#/ {print $1, $2}' $SEQID | \
  while read CHR SEQ ;
    do {
      ODIR="$MUSHU/chr$CHR" ;
      ###
      echo "# PROCESSING TBLASTX INV-HSPs on $CHR" 1>&2 ;
      TDIR="$ODIR/tblastx";
      MkDirs $TDIR $TDIR/$FTPTBXID ;
      TDIR="$ODIR/tblastx/$FTPTBXID";
      for c in ori inv-hsp inv-sr eval;
        do { MkDirs $TDIR/$c ; } ; done ;
      mega "cp -v" $MUSHU/invTBX/$FTPTBXID '^'$SEQ'\.[abcd]_[0-9]' $TDIR/ori ;
      mega "cat" $TDIR/ori '^'$SEQ'\.[abcd]_[0-9].*\.fullgff$' > $TDIR/inv-hsp/$SEQ.fullgff ;
      perl -ne '/^#/o && next;
                /^\s+$/o && next; 
                $_ =~ s/;\s+Strand//o; 
                $_ =~ s/;\s+Frame//o; 
                $_ =~ s/;\s+E_value.*$//o;
                print STDOUT $_;
           ' $TDIR/inv-hsp/$SEQ.fullgff | \
             sort +3n -6 +6 -7 - > $TDIR/inv-hsp/$SEQ.gff ;
      $BIN/blast2gff -vg  $TDIR/inv-hsp/$SEQ.gff > $TDIR/inv-sr/$SEQ.gff ;
      gawk '
        BEGIN{ chr=ARGV[1]; ARGV[1]=""; t=b["+"]=b["-"]=b["."]=0; }
        ($0 !~ /^[ \t]*$/ && $1 !~ /^\#/) { t++; a[$7,$8]++; b[$7]++; c[$8]++ }
        END{ 
          printf "# TOTAL %s SRs on %s: %s forward, %s reverse, %s without strand.\n", 
                 t, chr, b["+"], b["-"], b["."];
          for (i in c) {
            printf "#\t%s : %6s\t\|\t%s : %6s\t|\t%s : %6s\n", 
                   "+"i, a["+",c[i]] ? a["+",i] : 0,
                   "-"i, a["-",c[i]] ? a["-",i] : 0,
                   "."i, a[".",c[i]] ? a[".",i] : 0;
          };
        }
      ' $SEQ $TDIR/inv-sr/$SEQ.gff > $TDIR/inv-sr/$SEQ.report ;
      ###
      echo "# RUNNING SGP on $CHR" 1>&2 ;
      SDIR="$ODIR/sgp" ;
      MkDirs $SDIR $SDIR/$FTPTBXID ;
      SDIR="$ODIR/sgp/$FTPTBXID" ;
      for c in inv-hsp-sr out gff gtf2 cds prot logs tmp eval ;
        do { MkDirs $SDIR/$c ; } ; done ;
      $BIN/getHSPSR.pl $SEQ < $TDIR/inv-sr/$SEQ.gff \
            > $SDIR/inv-hsp-sr/$SEQ.gff 2> $SDIR/inv-hsp-sr/$SEQ.report ;
      #
      GENEID="$SRC/geneid_v1.1-sgp/bin/geneid" ; # geneid v1.1-sgp
      PARAM="$SRC/geneid_v1.1-sgp/param/human3iso.param.sgp" ;
      EW=0 ; # add to exon weigth
      ISEQ="$MSEQ/$SEQ.fa" ;
      HOMOLOGY="$SDIR/inv-hsp-sr/$SEQ.gff" ;
      if [ -f "$HOMOLOGY" ] ;
        then
          echo "### Using homology data from: $HOMOLOGY" 1>&2 ;
          HOMOLOGY_PAR="-S $HOMOLOGY" ;
        else
          echo "### Homology file NOT found: $HOMOLOGY" 1>&2 ;
          HOMOLOGY_PAR="" ;
        fi ;
      #
      GENEID_CMDLN="-v -DE $EW -P $PARAM $HOMOLOGY_PAR $ISEQ" ;
      echo "$GENEID $GENEID_CMDLN" 1>&2 ;
      $GENEID $GENEID_CMDLN 2> $SDIR/logs/$SEQ.sgp | \
          grep -v 'evidence' > $SDIR/out/$SEQ ;
      $BIN/geneid_raw2GFF.pl $SEQ $SDIR $SDIR/out/$SEQ ;
      #
      ls -1 $SDIR/gff/$SEQ.sg/ | egrep "^$SEQ" | \
        while read n;
          do {
            cat $SDIR/gff/$SEQ.sg/$n;
            };
          done | sort +3n +4n -5 - > $SDIR/gff/$SEQ ;
      #
      gawk '($0 !~ /^[ \t]*$/ && $1 !~ /^\#/) { # get_geneid_genes 
          genes[$9]++;
          if (genes[$9]>1) {
            min[$9] = $4<min[$9] ? $4 : min[$9] ;
            max[$9] = $5>max[$9] ? $5 : max[$9] ;
          } else {
            min[$9] = $4 ;
            max[$9] = $5 ;
            strand[$9] = $7;
          };
          len[$9]+=$5-$4+1
        }
        END {
          for (n in genes) {
            print n, min[n], max[n], strand[n], len[n],genes[n];
          };
        }' $SDIR/gff/$SEQ | \
           sort +1n +2n -3 - > $SDIR/$SEQ.gene_list ;      
      } ;
    done ;
###EOF###
@ 
<<Mouse Fast Scripting>>=
notangle -R'runallmouse.sh' $WORK/$nwfile.nw | cpif $MUSHU/bin/runallmouse.sh ;
is_exec $MUSHU/bin/runallmouse.sh ;
##
##
gawk 'BEGIN{ prt=1 }
      $1~/^6$/ { prt=0 }
      { if (prt) print $0 }
      ' $MUSHU/seqid_list > $MUSHU/bin/seqid_a ;
gawk 'BEGIN{ prt=0 }
      $1~/^6$/ { prt=1 } $1~/^11$/ { prt=0 }
      { if (prt) print $0 }
      ' $MUSHU/seqid_list > $MUSHU/bin/seqid_b ;
gawk 'BEGIN{ prt=0 }
      $1~/^11$/ { prt=1 } $1~/^16$/ { prt=0 }
      { if (prt) print $0 }
      ' $MUSHU/seqid_list > $MUSHU/bin/seqid_c ;
gawk 'BEGIN{ prt=0 }
      $1~/^16$/ { prt=1 }
      { if (prt) print $0 }
      ' $MUSHU/seqid_list > $MUSHU/bin/seqid_d ;
# ls -1 bin/seqid_* | while read n; do echo "$n ->"`gawk '{s+=$3}END{print s}' $n`; done
#
# monstre4
( $MUSHU/bin/runallmouse.sh $MUSHU/bin/seqid_d 2> $MUSHU/bin/seqid_d.log 1>&2 ) &
# monstre3									      						     
( $MUSHU/bin/runallmouse.sh $MUSHU/bin/seqid_a 2> $MUSHU/bin/seqid_a.log 1>&2 ) &
# monstre2									      						     
( $MUSHU/bin/runallmouse.sh $MUSHU/bin/seqid_b 2> $MUSHU/bin/seqid_b.log 1>&2 ) &
# monstre1									       						     
( $MUSHU/bin/runallmouse.sh $MUSHU/bin/seqid_c 2> $MUSHU/bin/seqid_c.log 1>&2 ) &
#
egrep '^# (PROCESSING TBLASTX|RUNNING SGP)' bin/seqid_*.log
@ 

<<>>=
# EVALUATIONS 
gawk '$1!~/^\#/ {print $1, $2}' $MUSHU/seqid_list | \
  while read CHR SEQ ;
    do {
      ADIR="$MUSHU/chr$CHR" ;
      ODIR="$ADIR/annotation" ;
      MkDirs $ODIR $ODIR/refseq ;
      ODIR="$ODIR/refseq" ;
      ###
      echo "# PREPARING ANNOTATION on $CHR" 1>&2 ;
      $BIN/gp2gff.pl --no-overlap --exonori-nuclfix 1 -- \
               $SEQ refseq $MUSHU/tmp/refGene.txt \
             > $ODIR/$SEQ.eval.fullgff 2> $ODIR/$SEQ.eval.report ;
      gawk '$3~/^(Single|First|Internal|Terminal)$/ {print $0}' \
               $ODIR/$SEQ.eval.fullgff > $ODIR/$SEQ.eval.gff ;
      $BIN/gffsplitstrand.pl -l $ADIR/length.$SEQ.gff $ODIR/$SEQ.eval.gff ;
      } ;
    done ;
#
gawk '$1!~/^\#/ {print $1, $2}' $MUSHU/seqid_list | \
  while read CHR SEQ ;
    do {
      ODIR="$MUSHU/chr$CHR" ;
      A_REFSEQ="$ODIR/annotation/refseq/$SEQ.eval" ;
      ###
      echo "# PREPARING TBLASTX INV-SRs on $CHR" 1>&2 ;
      TDIR="$ODIR/tblastx/$FTPTBXID/inv-sr" ;
      gawk 'BEGIN{OFS="\t";}
            $7 ~ "+" {
               $8="1"; $9="1"; print $0;
            }' $TDIR/$SEQ.gff > $TDIR/$SEQ.PRJ.fwd.gff
      gawk 'BEGIN{OFS="\t";}
            $7 ~ "-" {
               $8="1"; $9="1"; print $0;
            }' $TDIR/$SEQ.gff > $TDIR/$SEQ.PRJ.rev.gff
      $BIN/blast2gff -vg $TDIR/$SEQ.PRJ.fwd.gff | \
        gawk 'BEGIN{ OFS="\t"; }
              ($0 !~ /^[ \t]*$/ && $1 !~ /^\#/) { print $0,"1" }' \
              - > $TDIR/$SEQ.PRJeval.fwd.gff
      $BIN/blast2gff -vg $TDIR/$SEQ.PRJ.rev.gff | \
        gawk 'BEGIN{ OFS="\t"; }
              ($0 !~ /^[ \t]*$/ && $1 !~ /^\#/) { print $0,"1" }' \
              - > $TDIR/$SEQ.PRJeval.rev.gff
      } ;
    done ;
#
gawk '$1!~/^\#/ {print $1, $2}' $MUSHU/seqid_list | \
  while read CHR SEQ ;
    do {
      ODIR="$MUSHU/chr$CHR" ;
      A_REFSEQ="$ODIR/annotation/refseq/$SEQ.eval" ;
      echo "# EVALUATING TBLASTX INV-SRs on $CHR" 1>&2 ;
      TDIR="$ODIR/tblastx/$FTPTBXID/inv-sr" ;
      #
      cat > $TDIR/$SEQ.summary <<EOT ;
#
# Evaluation summary results for SRs on Mmus SEQ[$SEQ] using INVTBX[HsapSQ-MmusDB]
#
EOT
      $BIN/runeval.pl $A_REFSEQ.fwd.gff $TDIR/$SEQ.PRJeval.fwd.gff \
                "${SEQ}::INVTBX[HsapSQ-MmusDB]->SRs::REFSEQ::FWD::invMmusSRs::.::." \
                >> $TDIR/$SEQ.summary 2> $TDIR/$SEQ.sr_refseq.fwd ;
      $BIN/runeval.pl $A_REFSEQ.rev.gff $TDIR/$SEQ.PRJeval.rev.gff \
                "${SEQ}::INVTBX[HsapSQ-MmusDB]->SRs::REFSEQ::REV::invMmusSRs::.::." \
                >> $TDIR/$SEQ.summary 2> $TDIR/$SEQ.sr_refseq.rev ;
      } ;
    done ;
#
gawk '$1!~/^\#/ {print $1, $2}' $MUSHU/seqid_list | \
  while read CHR SEQ ;
    do {
      ODIR="$MUSHU/chr$CHR" ;
      A_REFSEQ="$ODIR/annotation/refseq/$SEQ.eval" ;
      ###
      echo "# EVALUATING GENEID on $CHR" 1>&2 ;
      GDIR="$ODIR/geneid/$FTPTBXID" ;
      #
      gawk '$3~/^(Single|First|Internal|Terminal)$/ {print $0}' \
               $GDIR/gff/$SEQ > $GDIR/eval/$SEQ.eval.gff ;
      $BIN/gffsplitstrand.pl $GDIR/eval/$SEQ.eval.gff ;
      #
      cat > $GDIR/eval/$SEQ.summary <<EOT ;
#
# Evaluation summary results for geneid on SEQ[$SEQ]
#
EOT
      $BIN/runeval.pl $A_REFSEQ.fwd.gff $GDIR/eval/$SEQ.eval.fwd.gff \
                "${SEQ}::MmusGENEID::REFSEQ::FWD::GENEID::1.1::." \
                >> $GDIR/eval/$SEQ.summary 2> $GDIR/eval/$SEQ.sr_refseq.fwd ;
      $BIN/runeval.pl $A_REFSEQ.rev.gff $GDIR/eval/$SEQ.eval.rev.gff \
                "${SEQ}::MmusGENEID::REFSEQ::REV::GENEID::1.1::." \
                >> $GDIR/eval/$SEQ.summary 2> $GDIR/eval/$SEQ.sr_refseq.rev ;
      } ;
    done ;
#
gawk '$1!~/^\#/ {print $1, $2}' $MUSHU/seqid_list | \
  while read CHR SEQ ;
    do {
      ODIR="$MUSHU/chr$CHR" ;
      A_REFSEQ="$ODIR/annotation/refseq/$SEQ.eval" ;
      ###
      echo "# EVALUATING SGP on $CHR" 1>&2 ;
      SDIR="$ODIR/sgp/$FTPTBXID" ;
      #
      gawk '$3~/^(Single|First|Internal|Terminal)$/ {print $0}' \
               $SDIR/gff/$SEQ > $SDIR/eval/$SEQ.eval.gff ;
      $BIN/gffsplitstrand.pl $SDIR/eval/$SEQ.eval.gff ;
      #
      cat > $SDIR/eval/$SEQ.summary <<EOT ;
#
# Evaluation summary results for geneid on SEQ[$SEQ]
#
EOT
      $BIN/runeval.pl $A_REFSEQ.fwd.gff $SDIR/eval/$SEQ.eval.fwd.gff \
                "${SEQ}::MmusSGP+invTBX[HsapSQ-MmusDB]::REFSEQ::FWD::SGP::1.1::." \
                >> $SDIR/eval/$SEQ.summary 2> $SDIR/eval/$SEQ.sr_refseq.fwd ;
      $BIN/runeval.pl $A_REFSEQ.rev.gff $SDIR/eval/$SEQ.eval.rev.gff \
                "${SEQ}::MmusSGP+invTBX[HsapSQ-MmusDB]::REFSEQ::REV::SGP::1.1::." \
                >> $SDIR/eval/$SEQ.summary 2> $SDIR/eval/$SEQ.sr_refseq.rev ;
      } ;
    done ;
#
# WHOLE SUMMARY (MOUSE)
gawk '$1!~/^\#/ {print $1, $2}' $MUSHU/seqid_list | \
  while read CHR SEQ ;
    do {
      ODIR="$MUSHU/chr$CHR" ;
      echo "### WORKING ON $SEQ : MOUSE" ;
      TDIR="$ODIR/tblastx/$FTPTBXID/inv-sr" ;
      GDIR="$ODIR/geneid/$FTPTBXID" ;
      SDIR="$ODIR/sgp/$FTPTBXID" ;
      #
      cat $GDIR/eval/$SEQ.summary \
          $TDIR/$SEQ.summary      \
          $SDIR/eval/$SEQ.summary ; 
    };
  done > $MUSHU/evaluation.summary ;
$BIN/process_eval.pl -T "REFSEQ" \
                     -P "GENEID invMmusSRs SGP" \
                        $MUSHU/evaluation.summary > $MUSHU/evaluation_prog.summary ;
$BIN/process_eval.pl -T "REFSEQ" \
                     -P "GENEID invMmusSRs SGP" \
                     -t $MUSHU/evaluation.summary > $MUSHU/evaluation_test.summary ;
@ 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{comment}
\end{comment}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%%%%%%%%%%%%%%%%%%% BACKMATTER

% \newpage %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% 
% \bibliographystyle{apalike}
% \bibliography{/home1/rguigo/docs/biblio/References}

\newpage %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\appendix

\sctn{Auxiliarly Perl Scripts}

\subsctn{Annotation phase}

\subsubsctn{[[getfastadesc.pl]]: retrieving sequence names and nucleotide composition}

<<tangling: perl scripts>>=
echo "# --> \$BIN/getfastadesc.pl" 1>&2 ;
notangle -R"getfastadesc.pl" $WORK/$nwfile.nw | cpif $BIN/getfastadesc.pl ;
perl -c $BIN/getfastadesc.pl ;
is_exec $BIN/getfastadesc.pl ;
@ 

<<getfastadesc.pl>>=
<<PERL shebang>>
# getfastadesc.pl
#
# USAGE:
#   getfastadesc.pl chr_list.file fasta_files.dir > chr_seqs.list
#
# [chr_seqs.list] -> chr_id seq_id length date_file description
#
use strict;
#
use global;
&init_timer(\@exectime);
#
# VARS
$PROG = 'getfastadesc.pl';
$PRGVER = '0.9alpha';
#
my (@files,%seqs,@order);
@@files = ();
%seqs = ();
@@order = ();
#
# ARGVS
&match_argv_num(\@ARGV,2);
my ($chrlistfile,$ipath) = @ARGV;
$ipath =~ s%/$%%o;
#
# MAIN
&program_started($PROG);

&load_chr_tbl();
&get_file_names();
&parse_fasta_seqs();
&output_results();

&program_finished($PROG);
exit(0);
#
# SUBS
sub load_chr_tbl() {
    open(CHR,"< $chrlistfile") || do {
        print STDERR "## $PROG ## EXITING NOW: CANNOT open file $chrlistfile\n";
        exit($exit_codes{'NOREADFILE'}{CODE});
    };
    while (<CHR>) {
        my $chr;
        next if /^#/o;
        next if /^\s*$/o;
        chomp;
        s/^\s+//o;
        s/\s+$//o;
        ($chr,undef) = split /\s+/og, $_, 2;
        push @order, $chr;
        @{ $seqs{$chr} } = ();
    }; # while 
    close(CHR);
} # load_chr_tbl

sub get_file_names() {
    opendir(FA, $ipath) || do {
        print STDERR "## $PROG ## EXITING NOW: CANNOT open dir $ipath\n";
        exit($exit_codes{'NOREADDIR'}{CODE});
    };
    @files = grep { /\.fa$/ } readdir(FA);
    closedir(FA);
} # get_file_names

# 
# we are going to assume that input filenames
# have the following "chr"$chr"(.*).fa" (so we can assign
# "automagically" which sequence correspond to each chromosome)
# without having to set a table with the files corresponding to each chromosome
#
sub parse_fasta_seqs() {
    foreach my $fl (@files) {
        my ($thechr,$modtime,$ct,$cc,$go,@lengths);
        ($thechr) = uc($fl) =~ /^CHR([\d]+|[XY]|NA|UL|UN)/o;
        defined($seqs{$thechr}) || do {
            print STDERR "## $PROG ## SKIPPING chr \"$thechr\"".
                         " (NOT IN SEQ LIST) file: \"$fl\"\n";
            next;
        };
        $fl = "$ipath/$fl";
        open(FAF,"< $fl") || do {
            print STDERR "## $PROG ## Cannot open file \"$fl\" for chr \"$thechr\"...\n";
            next;
        };
        print STDERR "## $PROG ## Working on chr \"$thechr\" file: \"$fl\"\n";
        $modtime = &get_fh_mod_date(\*FAF);
        $ct = 0;
        $cc = ".";
        $go = $F;
        @lengths = ();
        while (<FAF>) {
            my ($id,$desc);
            next if /^\s*$/o;
            chomp;
            m/^>/o && do {
                $go = $T;
                print STDERR "X";
                &add_lengths_to_hash(\@lengths,\@{ $seqs{$thechr} });
                ($id,$desc) = split /\s+/og, $_, 2;
                $id =~ s/^>//o;
                defined($desc) || ($desc = ".");
                push @{ $seqs{$thechr} }, [ $id, undef, $modtime, $desc ];
                next;
            };
            $go && do { &add_to_seq_length($_,\@lengths); };
        } continue {
            $ct++;
            ($ct%10 == 0) && (print STDERR "$cc");
            ($ct%1000 == 0) && (print STDERR " [$ct]\n");
        }; # while <FAF>
        ($ct%1000 != 0) && (print STDERR " [$ct]\n");
        &add_lengths_to_hash(\@lengths,\@{ $seqs{$thechr} });
        close(FAF);
    }; # foreach $fl
} # parse_fasta_seqs
#  print STDERR "#\n# $chr has ".(scalar @files)." fragments (files)\n#\n# ".
#             (sprintf("%12s %12s %8s %8s %10s  %s\n",
#                      "begin","end","#seqs","#errors","rand","file"));

sub get_fh_mod_date() {
    my $fh = shift;
    my ($year,$month,$day,$hour,$min,$sec);
    ($year,$month,$day,$hour,$min,$sec) = 
            (localtime((stat $fh)[9]))[5,4,3,2,1,0];
    # stat ->  [8] is access date,
    #          [9] is modif date and
    #         [10] is inode change date
    return sprintf("%04d%02d%02d%02d%02d%02d",
                   $year + 1900,$month + 1,$day,$hour,$min,$sec);
} # get_fh_mod_date

sub add_lengths_to_hash() {
    my ($ref,$hsh) = @_;
    (scalar(@{$ref}) == 7) && do {
        my $s = $ref->[1] + $ref->[2] + $ref->[3] + $ref->[4];
        $hsh->[$#{$hsh}][1] = ($s > 0) ? $ref->[0] : 0;
        $hsh->[$#{$hsh}][3] = sprintf("A:%d T:%d G:%d C:%d N:%d ?:%d Desc: ",
                                      @{$ref}[1..6]).$hsh->[$#{$hsh}][3];
        @{$ref} = ();
    };
} # add_lengths_to_hash

sub add_to_seq_length() {
    my ($l,$a,$t,$g,$c,$n,$x) = (0..6);
    my ($str,$ary) = @_;
    (scalar(@{$ary}) == 7) || do { @{$ary} = (0) x 7; };
    $str = uc($str);
    $str =~ s/^\s+//o;
    $str =~ s/\s+$//o;
	$ary->[$l] += length($str);
    $ary->[$a] += scalar($str =~ s/A//og);
    $ary->[$t] += scalar($str =~ s/T//og);
    $ary->[$g] += scalar($str =~ s/G//og);
    $ary->[$c] += scalar($str =~ s/C//og);
    $ary->[$n] += scalar($str =~ s/N//og);
    $ary->[$x] += length($str) > 0 ? length($str) : 0;
} # add_to_seq_length
   
sub output_results() {
    foreach my $cs (@order) {
        defined($seqs{$cs}) || do {
            print STDERR "## $PROG ## No sequences found for chromosome $cs !!!\n";
            next;
        };
        scalar(@{ $seqs{$cs} }) > 1 && do {
            @{ $seqs{$cs} } = map { $_->[1] }
                              sort { $a->[0] cmp $b->[0] } # ascending alpha sort
                              map { [ $_->[0], $_ ] } @{ $seqs{$cs} };
        };
        foreach my $sq (@{ $seqs{$cs} }) {
            scalar(@{ $sq }) != 4 && do { 
                # why must be only 4 elements there? -> see &add_lengths_to_hash
                print STDERR "## $PROG ## Chromosome $cs: ".
                             "Sequence $sq->[0] data set incomplete !!!\n";
                next;
            };
            (defined($sq->[2]) && $sq->[2] > 0) || do {
                print STDERR "## $PROG ## Chromosome $cs: ".
                             "Sequence $sq->[0] has zero length !!!\n";
                next;
            };
            print STDOUT "$cs @{$sq}\n";
        }; # foreach $sq
    }; # foreach $cs
} # output_results
@

<<HIDE: >>=
use db_Hsapiens;
#
################## MAIN
&open_DB();
&output_results();
&close_DB();
################## SUBS
sub output_results() {
    my ($ctbl,$cscode,@coflds,@cqflds,$stbl,@sfld,@soflds,@sqflds);
    ($ctbl,$stbl) = qw( tb_chromosome tb_sequence );
    @sfld = qw( 0 2 );
    @coflds = qw( code );
    @cqflds = qw( id );    
    @soflds = qw( id chr length version descr );
    foreach my $cs (@order) {
        defined($seqs{$cs}) || do {
            print STDERR "# No sequences found for chromosome $cs !!!";
            next;
        };
        scalar(@{ $seqs{$cs} }) > 1 && do {
            @{ $seqs{$cs} } = map { $_->[1] }
                              sort { $a->[0] cmp $b->[0] } # ascending alpha sort
                              map { [ $_->[0], $_ ] } @{ $seqs{$cs} };
        };
        foreach my $sq (@{ $seqs{$cs} }) {
            print STDOUT "$cs @{$sq}\n";
        }; # foreach $sq
        $isDBon && do {
            ($cscode) = &get_row_fields($ctbl, \@coflds, \@cqflds, [ $cs ]);
            foreach my $sq (@{ $seqs{$cs} }) {
                @sqflds = ( $sq->[0], $cscode, @{$sq}[1..3] );
                &put_row_fields($stbl, \@sfld, \@soflds, \@sqflds);
                print STDERR "$cs($cscode) @{$sq}[0,1,3]\n";
            }; # foreach $sq
        }; # $isDBon
    }; # foreach $cs
} # output_results
@ 

\subsubsctn{[[gp2gff.pl]]: Processing Golden Path annotation}

<<tangling: perl scripts>>=
echo "# --> \$BIN/gp2gff.pl" 1>&2 ;
notangle -R"gp2gff.pl" $WORK/$nwfile.nw | cpif $BIN/gp2gff.pl ;
perl -c $BIN/gp2gff.pl ;
is_exec $BIN/gp2gff.pl ;
@ 
<<gp2gff.pl>>=
<<PERL shebang>>
# Transforms the goldenpath format to gff file
#   retrieving gene(mrna)/utr/cds coordinates.
# Now, goldenpath file records do not need to be ordered by acceptor
# as the script sorts them before their processing.
#
# USAGE: gp2gff.pl [options] "chrname" "source" goldenpath_file > stdout
#
use strict;
#
use global qw( :ExecReport :ExitStatus );
&init_timer(\@exectime);
#
$PROG = 'gp2gff.pl';
$PRGVER = '0.9alpha';
#
# ARGVS
use Getopt::Long;
Getopt::Long::Configure qw/ bundling /;
#
my ($overlap,$exon_ori_fix,$exon_end_fix) = (0,0,0);
$SIG{__WARN__} = sub {
                       print STDERR "### UNKNOWN COMMAND-LINE OPTION: $_[0]\n";
                     };
GetOptions(
           'no-overlap'        => \$overlap,
           'exonori-nuclfix=i' => \$exon_ori_fix,
           'exonend-nuclfix=i' => \$exon_end_fix,
           ) || do {
               print STDERR "### ERROR when PARSING ARGUMENTS\n";
               exit($exit_codes{'BADCMDLINEOPT'}{CODE});
           };
$SIG{__WARN__} = 'DEFAULT';
#
my ($seqname,$source,$ifile) = @ARGV;
#
# VARS
my $c = 0;
my (@allgp,@exary);
my %laste = ();
#
# MAIN
&program_started($PROG);
&main();
&program_finished($PROG);
exit(0);
#
# SUBS
sub main() {
    open(GPFILE,"< $ifile") || do {
        print STDERR "## $PROG ## EXITING NOW: CANNOT open file $ifile\n";
        exit($exit_codes{'NOREADFILE'}{CODE});
    };
    while (<GPFILE>) {
        my @l;
        next if /^#/o;
        next if /^\s*$/o;
        chomp;
        @l = split /\s+/og, $_;
        push @allgp, [ @l ];
    };
    close(GPFILE);
    # we must sort input as it can be provided unordered
    @allgp = sort { $a->[3] <=> $b->[3] || $a->[4] <=> $b->[4] } @allgp;
    foreach my $gp (@allgp) {
        $c++ if &process_gene($gp);
    };
    print STDERR "###\n$c genes for $seqname were found in \"$ifile\".\n";
} # main
sub process_gene() {
    my $rec = shift;
    my $maxrec = 10; # refseq record structure
    my ($gene,$seq,$strand,$mrna_ori,$mrna_end,
        $cds_ori,$cds_end,$exons_num,$exons_ori,$exons_end) = (0..($maxrec - 1));
    my (@l,@o,@e,$frame,$cdso,$cdse);
    @l = @{ $rec };
    ((scalar(@l) >= $maxrec) && ($l[$seq] eq $seqname)) || return 0;
    @o = split /,/og, $l[$exons_ori];
    @e = split /,/og, $l[$exons_end];
    # fixing displacement at exon coordinates (also at mrna and cds levels)
    $exon_ori_fix == 0 || do {
         $l[$mrna_ori] += $exon_ori_fix;
         $l[$cds_ori]  += $exon_ori_fix;
         @o = map { $_ += $exon_ori_fix } @o;
    };
    $exon_end_fix == 0 || do {
         $l[$mrna_end] += $exon_end_fix;
         $l[$cds_end]  += $exon_end_fix;
         @e = map { $_ += $exon_end_fix } @e;
    };
    #
    ($cdso,$cdse) = @l[$cds_ori,$cds_end];
    # checking if gene overlaps previous one...
    #   (we assume they are sorted by acceptor)
    $overlap && do {
        defined($laste{$l[$strand]}) && do {
            ($laste{$l[$strand]} > $cdso) && return 0;
		};
        $laste{$l[$strand]} = $cdse;
    }; # $overlap
    #
    &prt_gene(@l[$mrna_ori,$mrna_end,$strand,$gene,$exons_num]);
    @exary = ();
    $frame = 0;
    for (my $j = 0; $j < $l[$exons_num]; $j++) {
        my ($ori,$end,$p);
        $p = ($l[$strand] eq '-') ? ($l[$exons_num] - ($j + 1)) : $j;
        ($ori,$end) = ($o[$p],$e[$p]);
        ($end < $cdso || $ori > $cdse) && do {
            &prt_utr($ori,$end,@l[$strand,$gene]);
            next;
        };
        ($ori < $cdso  && $end <= $cdse) && do {
            &prt_utr($ori,($cdso - 1),@l[$strand,$gene]);
            $frame = &prt_exon($cdso,$end,$frame,@l[$strand,$gene],$cdso,$cdse);
            &swap_items(0) if ($l[$strand] eq '-');
            next;
        };
        ($ori >= $cdso && $end > $cdse) && do {
            $frame = &prt_exon($ori,$cdse,$frame,@l[$strand,$gene],$cdso,$cdse);
            &prt_utr(($cdse + 1),$end,@l[$strand,$gene]);
            &swap_items(0) if ($l[$strand] eq '-');
            next;
        };
        ($ori < $cdso  && $end > $cdse) && do {
            &prt_utr($ori,($cdso - 1),@l[$strand,$gene]);
            $frame = &prt_exon($cdso,$cdse,$frame,@l[$strand,$gene],$cdso,$cdse);
            &prt_utr(($cdse + 1),$end,@l[$strand,$gene]);
            &swap_items(1) if ($l[$strand] eq '-');
            next;
        };
        $frame = &prt_exon($ori,$end,$frame,@l[$strand,$gene],$cdso,$cdse);
    };
    ($l[$strand] eq '-') && (@exary = reverse @exary);
    print STDOUT join('',@exary); # each line already has its own linefeed
    return 1;
} # process_gene
# GFF: seqname source feat start end score strand frame group
sub prt_gene() {
    my @data = @_;
    print STDOUT "# Gene: $data[3]   Strand: $data[2]   Exons: $data[4]\n";
    print STDOUT join("\t",$seqname,$source,"mrna",@data[0,1],
                      ".",$data[2],".",$data[3])."\n";
} # prt_gene
sub prt_utr() {
    my @data = @_;
    push @exary, join("\t",$seqname,$source,"utr",@data[0,1],
                      ".",$data[2],".",$data[3])."\n";
} # prt_utr
sub prt_exon() {
    my ($eo,$ee,$frm,$str,$grp,$co,$ce) = @_;
    my $feat;
#     my ($myfrm,$feat);
    # remainder = ((exon_end - exon_ori + 1) + frame) mod 3;
    # nextframe = (3 - ((exon_end - exon_ori + 1) + frame) mod 3) mod3;
#   $myfrm = ($str eq '-') # exon frame is set to remainder for - strand
#            ? ( (($ee - $eo + 1) + $frm) % 3 )
#            : $frm;
    $feat = &get_feat($eo,$ee,$str,$co,$ce);
#   $feat =~ /Single/io && ($myfrm = 0); # single frame hack (specially for -)
    push @exary, join("\t",$seqname,$source,$feat,$eo,$ee,
                      ".",$str,$frm,$grp)."\n";
#                       ".",$str,$myfrm,$grp)."\n";
    return ( (3 - (($ee - $eo + 1) + $frm) % 3 ) % 3 ); # return nextframe
} # prt_exon
# gene structure GFF-feature names
sub get_feat() {
    my ($eo,$ee,$str,$co,$ce) = @_;
    my ($fts,$fto,$fti,$fte);
    ($fts,$fto,$fti,$fte) = ("Single","First","Internal","Terminal");
    $str eq "-" && do {
        ($fto,$fte) = ($fte,$fto);
    };
    ($eo == $co && $ee == $ce) && return $fts;
    ($eo == $co) && return $fto;
    ($ee == $ce) && return $fte;
    return $fti;
} # get_feat
sub swap_items() {
     shift || do {
         ($exary[$#exary],$exary[$#exary-1]) =
             ($exary[$#exary-1],$exary[$#exary]);
         return;
     };
     ($exary[$#exary],$exary[$#exary-1],$exary[$#exary-2]) =
         ($exary[$#exary-2],$exary[$#exary-1],$exary[$#exary]);
     return;
} # swap_items
@ 


\subsctn{Homology search phase}

\subsubsctn{[[sbp-checkblastout.pl]]: Verifying SBP {\tbx} output for chromosome fragments}

<<tangling: perl scripts>>=
echo "# --> \$BIN/sbp-checkblastout.pl" 1>&2 ;
notangle -R"sbp-checkblastout.pl" $WORK/$nwfile.nw | \
     cpif $BIN/sbp_checkblastout.pl ;
perl -c $BIN/sbp_checkblastout.pl ;
is_exec $BIN/sbp_checkblastout.pl ;
@ 
<<sbp-checkblastout.pl>>=
<<PERL shebang>>
# Parsing tblastx files from SBP to check blast output
#   contents for each fragment of the broken chromosomic sequence
#
# USAGE: sbp_checkblastout.pl "chrname" input_dir > stdout.report
#
use strict;
#
use global qw( :ExecReport :ExitStatus );
&init_timer(\@exectime);
#
$PROG = 'sbp_checkblastout.pl';
$PRGVER = '0.9alpha';
#
my @files = ();
my $formstring = '%12s %12s %8s %8s %10s  %s%s'."\n";
                 # begin end #seqs #errors rand_flg file
#
# ARGVS
&match_argv_num(\@ARGV,2);
my ($chr,$path) = @ARGV;
#
# MAIN
&program_started($PROG);
&read_dir_files();
&count_fragments();
&program_finished($PROG);
(scalar(@files) > 0) || exit($exit_codes{'NOFILE'}{CODE});
exit(0);
#
# SUBS
sub read_dir_files() {
    my $rflg;
    if ($chr =~ /^.*_rand.*?_.*$/o) {
        $rflg = '1';
    } else {
        $rflg = '-';
    }; 
    opendir(TBX, $path) || do {
        print STDERR "## $PROG ## EXITING NOW: CANNOT open dir $path\n";
        exit($exit_codes{'NOREADDIR'}{CODE});
    };
    @files = map  { [ $_ , /^$chr\_(\d+)\_(\d+)(?:\..*)?$/, $rflg ] } 
             grep { /^[^\.]/ } readdir(TBX);
    closedir(TBX);
    @files = map { $_->[1] }
             sort { $a->[0] <=> $b->[0] }
             map { [ $_->[1], $_ ] } @files;
    print STDERR "# $chr has ".(scalar @files)." fragments (files)\n";
    print STDOUT "#\n# $chr has ".(scalar @files)." fragments (files)\n#\n# ".
          (sprintf($formstring,"begin","end","#seqs","#errors","rand","file",""));
} # read_dir_files
sub count_fragments() {
    my ($te,$the,$tqe) = (0,0,0);
    my ($c,$e,$z,$hok,$qok,$nok);
    $z = 0;
    foreach my $fl (@files) {
        ($c,$e,$hok,$qok,$nok) = (0,0,0,0,'');
        my $fname = "$path/$fl->[0]";
        open(TBXFL,"< $fname") || do {
            print STDERR "## $PROG ## SKIPPING: CANNOT OPEN $fname\n";
            next;
        };
        print STDERR "## $PROG ## Working on $fname\n";
        while (<TBXFL>) {
            /^>/o   && ($c++,next);
            /EXIT/o && ($e++);
            ($. == 1 && $_ =~ /BLAST/io) && ($hok=1);
            ($_ =~ /^Query=/io)          && ($qok=1);
        }; # while
        $c == 0 && ($z++);
        close(TBXFL);
        $hok || ($nok = "\t# Check BLAST HEADER",$the++,$e++);
        $qok || ($nok .= "\t# Check BLAST QUERY",$tqe++,$e++);
        printf STDOUT "  $formstring",
             ($fl->[1] + 1),($fl->[1] + $fl->[2]),$c,$e,$fl->[3],$fl->[0],$nok;
        $te += $e;
    }; # foreach
    print STDOUT "# $chr ran into ".(scalar @files).
                 " fragments, $z of which having NO HSPs.\n";
    print STDERR "# $e ERRORS FOUND: ".($te - ($the+$tqe))." in exit status,".
                 " $the missing blast headers, $tqe missing query seqname.\n";
} # count_fragments
@ 

\subsubsctn{[[sbp-blast2gff.pl]]: Parsing SBP {\tbx} output to GFF}

<<tangling: perl scripts>>=
echo "# --> \$BIN/sbp-blast2gff.pl" 1>&2 ;
notangle -R"sbp-blast2gff.pl" $WORK/$nwfile.nw | \
     cpif $BIN/sbp_blast2gff.pl ;
perl -c $BIN/sbp_blast2gff.pl ;
is_exec $BIN/sbp_blast2gff.pl ;
@
 
<<sbp-blast2gff.pl>>=
<<PERL shebang>>
# Parsing tblastx files from SBP to get HSPs in GFF format
#
# USAGE: sbp_blast2gff.pl "chrname" length_file input_dir report_file \
#                          > gff_output  2> stdout.report
# <report_file> has been obtained with $BIN/sbp_checkblastout.pl
#
use strict;
#
use global qw( :ExecReport :ExitStatus );
&init_timer(\@exectime);
#
$PROG = 'sbp_blast2gff.pl';
$PRGVER = '0.9alpha';
#
my ($seq,$src,$ftr,$ori,$end,$sco,$str,$frm) = (0..7);
my @frame = ( 3, 1, 2 ); # frm 0 -> blastfrm 3
                         # frm 1 -> blastfrm 1
                         # frm 2 -> blastfrm 2
my %SEQlen;
my @files = ();
my %g = ( "+1" => 0,  "+2" => 1,  "+3" => 2,  "+" => 3,
          "-1" => 4,  "-2" => 5,  "-3" => 6,  "-" => 7,
          ".1" => 8,  ".2" => 9,  ".3" => 10, "." => 11,
                     "all" => 12,            "sum" => [ (0) x 13 ] );
my ($cf,$cr);
#
# ARGVS
&match_argv_num(\@ARGV,4);
my ($chr, $seqln, $input, $report) = @ARGV;
$input =~ s%/$%%o;
#
# MAIN
&program_started($PROG);
&read_lengths();
&read_filenames();
&run_parseblast();
&program_finished($PROG);
exit(0);
#
# SUBS
<<sbp-blast2gff.pl: reading lengths>>
<<sbp-blast2gff.pl: reading filenames from report>>
<<sbp-blast2gff.pl: running parseblast>>
@ 

<<sbp-blast2gff.pl: reading lengths>>=
sub read_lengths() {
    open(FRGLEN, "< $seqln") || do {
        print STDERR "## $PROG ## EXITING NOW: CANNOT open file $seqln\n";
        exit($exit_codes{'NOREADFILE'}{CODE});
    };
    while (<FRGLEN>) {
        next if /^\#/o;
        next if /^\s*$/o;
        chomp;
        my @l = split /\s+/og, $_;
        $SEQlen{$l[0]} = $l[1];
    }; # while
    close(FRGLEN);
} # read_lengths
@ 

<<sbp-blast2gff.pl: reading filenames from report>>=
sub read_filenames() {
    open(FRGLST, "< $report") || do {
        print STDERR "## $PROG ## EXITING NOW: CANNOT open file $report\n";
        exit($exit_codes{'NOREADFILE'}{CODE});
    };
    while (<FRGLST>) {
        next if /^\#/o;
        next if /^\s*$/o;
        chomp;
        s/^\s*//o;
        my @l = split /\s+/og, $_;
        ($l[2] > 0) && do {
            push @files, [ $l[$#l], ($l[0] - 1) ];
        };
        # skipping fragments without HSPs
    }; # while
    close(FRGLST);
} # read_filenames
@ 

<<sbp-blast2gff.pl: running parseblast>>=
sub run_parseblast() {
    my $pblsterr = "$input.parseblast.err";
    my $cmd = "$ENV{BIN}/parseblast.pl";
    print STDERR "#\n# $chr has ".(scalar @files)." fragments (files)\n#\n# ".
             (sprintf("%8s %8s %8s  %s\n","#hsp","#hsp(+)","#hsp(-)","file"));
    (-e $cmd && -x _ ) || do {
        print STDERR "## $PROG ## EXITING NOW: CANNOT exec \"$cmd\"\n";
        exit($exit_codes{'NOCMD'}{CODE});
    };
#    if ( -e $pblsterr ) {
#        unlink($pblsterr) || do {
#            print STDERR "## $PROG ## CANNOT REMOVE $pblsterr\n";
#        };
#    };
    my %errcnt = ( FIELD => 0, STRAND => 0, FRAME => 0 );
    foreach my $fl (@files) {
        $cf = $cr = 0;
        my ($fname,$offset) = ("$input/$fl->[0]", $fl->[1]);
#        &wait_for_file($fname,$PROG,$F); # file prog exitflg
        open(TBXFL, "$cmd --fullgff --full-scores".
                    " --comments --verbose --bit-score $fname".
                    " 2>> $pblsterr |") || do {
            print STDERR "## $PROG ## SKIPPING: CANNOT RUN parseblast on $fname\n";
            next;
        };
        # print STDERR "## $PROG ## RUNNING parseblast on $fname\n";
        while (<TBXFL>) {
            my @l;
            next if /^\s*$/o;
            /^\#/o && do {
                print STDOUT $_;
                next;
            };
            chomp;
            @l = split /\s+/og, $_, 9;
            (scalar(@l) < 8) && do {
                print STDERR "## FIELD NUMBER ERROR ($.): @l \n";
                $errcnt{FIELD}++;
                next;
            };
            ($l[$str] !~ /[\+\-\.]/o) && do {
                print STDERR "## NO VALID STRAND ($.): $l[$str] \n";
                $errcnt{STRAND}++;
                next;
            };  
            ($l[$frm] !~ /[123]/o) && do {
                print STDERR "## NO VALID FRAME ($.): \"@l\"\n"; # $l[$frm] \n";
                $errcnt{FRAME}++;
                next;
            };  
            $l[$seq] = $chr;
            $l[$src] = "tblastx";
            $l[$ftr] = "hsp";
            $l[$ori] += $offset;
            $l[$end] += $offset;
            if ($l[$str] eq "-") {
                $l[$frm] = $frame[(($SEQlen{$chr} - $l[$end] + 1) % 3)];
                $cr++;
            } else {
                $l[$frm] = $frame[($l[$ori] % 3)];
                $cf++;
            };
            print STDOUT (join("\t", (@l)))."\n";
            $g{sum}[$g{"$l[$str]$l[$frm]"}]++;
        }; # while
        close(TBXFL);
        printf STDERR "  %8s %8s %8s  %s\n",($cf+$cr),$cf,$cr,$fl->[0];
    }; # foreach
    $g{sum}[$g{"+"}] = $g{sum}[$g{"+1"}] + $g{sum}[$g{"+2"}] + $g{sum}[$g{"+3"}];
    $g{sum}[$g{"-"}] = $g{sum}[$g{"-1"}] + $g{sum}[$g{"-2"}] + $g{sum}[$g{"-3"}];
    $g{sum}[$g{"."}] = $g{sum}[$g{".1"}] + $g{sum}[$g{".2"}] + $g{sum}[$g{".3"}];
    $g{sum}[$g{"all"}] = $g{sum}[$g{"+"}] + $g{sum}[$g{"-"}];
    print STDERR "# TOTAL ".$g{sum}[$g{"all"}]." HSPs on $chr: ".
                 $g{sum}[$g{"+"}]." forward, ".$g{sum}[$g{"-"}]." reverse, ".
                 $g{sum}[$g{"."}]." without strand.\n";
    foreach my $t (qw/ 1 2 3 /) {
       printf STDERR "#\t%s : %6s\t\|\t%s : %6s\t|\t%s : %6s\n",
              "+$t",$g{sum}[$g{"+$t"}],"-$t",$g{sum}[$g{"-$t"}],
              ".$t",$g{sum}[$g{".$t"}];
    }; # foreach
    $errcnt{TOT} = $errcnt{FIELD} + $errcnt{STRAND} + $errcnt{FRAME};
    print STDERR "# $errcnt{TOT} ERRORS FOUND: $errcnt{FIELD} in fields number,".
                 " $errcnt{STRAND} in strand, $errcnt{FRAME} in frame.\n";
} # run_parseblast
@


\subsubsctn{[[swapHSPcoords.pl]]: mapping DB coordinates from parseblast}

<<tangling: perl scripts>>=
echo "# --> \$BIN/swapHSPcoords.pl" 1>&2 ;
notangle -R"swapHSPcoords.pl" $WORK/$nwfile.nw | \
     cpif $BIN/swapHSPcoords.pl ;
perl -c $BIN/swapHSPcoords.pl ;
is_exec $BIN/swapHSPcoords.pl ;
@
 
<<swapHSPcoords.pl>>=
<<PERL shebang>>
# Parsing tblastx files from SBP to get HSPs in GFF format
#
# USAGE: swapHSPcoords.pl "chrname_sqDB" length_file_sqDB \
#                         input_sqQuery.fullgff [ ... input_sqQuery.fullgff ] \
#                         > sqDB.fullgff  2> stderr.report
#
use strict;
#
use global qw( :ExecReport :ExitStatus :StringFill :Counter );
&init_timer(\@exectime);
$_cntN = 100; # split counter dots line each $_cntN dots
#
$PROG = 'swapHSPcoords.pl';
$PRGVER = '0.9alpha';
#
my ($seq,$src,$ftr,$ori,$end,$sco,$str,$frm,$other) = (0..8);
my @frame = ( 3, 1, 2 ); # frm 0 -> blastfrm 3
                         # frm 1 -> blastfrm 1
                         # frm 2 -> blastfrm 2
my (%SEQlen, %opened, $FHOUT);
my @files = ();
my %g = ( "+1" => 0,  "+2" => 1,  "+3" => 2,  "+" => 3,
          "-1" => 4,  "-2" => 5,  "-3" => 6,  "-" => 7,
          ".1" => 8,  ".2" => 9,  ".3" => 10, "." => 11,
                     "all" => 12,            "sum" => [ (0) x 13 ] );
my ($fixpos,$cf,$cr);
#
# ARGVS
use Getopt::Std;
my %opts = ();
getopts("o:a:",\%opts);
       # -o integer
       #    fix coords offset (so if target label is seq_10001_10300
       #    and we set "-o -1", we can set start offset to 10000)
       # -a prefix_*_suffix
       #    open a filehandle for each sequence...
$fixpos = (defined($opts{o}) && $opts{o} =~ /^[+-]?\d+$/o) ? $opts{o} : 0;
#
my ($chr, $flg, $ofile, $seqln, @inputfiles);
if (defined($opts{a})) {
    $ofile = $opts{a};
    $flg = 1;
    &match_argv_num(\@ARGV,2);
    ($seqln, @inputfiles) = @ARGV;
    $chr = '.*';
} else {
    $flg = 0;
    &match_argv_num(\@ARGV,3);
    ($chr, $seqln, @inputfiles) = @ARGV;
};
foreach (my $r = 0; $r < scalar(@inputfiles); $r++) {
    $inputfiles[$r] =~ s%/$%%o;
};
#
# MAIN
&program_started($PROG);
print STDERR "### Working on SEQUENCE -> $chr\n".
             "### Getting sequence length from\n\t-> $seqln\n".
             "### Processing the following files\n\t-> ".(join("\n\t->", @inputfiles))."\n";
&read_lengths();
&parse_gff();
&program_finished($PROG);
exit(0);
#
# SUBS
<<sbp-blast2gff.pl: reading lengths>>
<<swapHSPcoords.pl: process records>>
@

<<swapHSPcoords.pl: process records>>=
sub parse_gff() {
    my %errcnt = ( FIELD => 0, STRAND => 0, FRAME => 0 , SKIPPED => 0 );
    my $summary = 
          "#\n# Processing ".(scalar @inputfiles)." tblastx files\n#\n# ".
          (sprintf("%8s %8s %8s  %s\n","#hsp","#hsp(+)","#hsp(-)","file"));
    my $opencnt = 0;
    foreach my $fl (@inputfiles) {
        $cf = $cr = 0;
        open(TBXFL, "< $fl") || do {
            print STDERR "## $PROG ## SKIPPING: CANNOT READ from $fl\n";
            next;
        };
        $n = 0;
        while (<TBXFL>) {
            my (@l,@f,@t,$out,$sqlen,$offset);
            $c = '.';
            next if /^\s*$/o;
            next if /^\#/o;
            # /^\#/o && do {
            #     print STDOUT $_;
            #     next;
            # };
            chomp;
            @l = split /\s+/og, $_, 9;
                 # we are going to assume that first eigth fields are OK
            @f = split /\s*;\s+/og, $l[8];
            (scalar(@l) < 8) && do {
                # print STDERR "## QUERY-FIELDS NUMBER ERROR ($.): @l \n";
                $c = '#';
                $errcnt{FIELD}++;
                next;
            };
            $out = &process_subject_fields(\@f,\@t);
            ($out ne 'OK') && do {
                $errcnt{$out}++;
                next;
            };
            if ($flg) {
                if ($t[$seq] =~ /^(.*)_(\d+)_\d+$/o) {
                    $t[$seq] = $1;
                    $offset  = $2 + $fixpos;
                } else {
                    # print STDERR "#[$.]# SKIPPING FIELD $seq \!= $chr\n";
                    $c = '-';
                    $errcnt{SKIPPED}++;
                    next;
                };
            } else {
                if ($t[$seq] =~ /^($chr)_(\d+)_\d+$/) {
                    $t[$seq] = $1;
                    $offset  = $2 + $fixpos;
                } else {
                    # print STDERR "#[$.]# SKIPPING FIELD $seq \!= $chr\n";
                    $c = '-';
                    $errcnt{SKIPPED}++;
                    next;
                };
            };
            # print STDERR "#[$.]# $t[$seq] --> $offset\n";
            if ($flg) {
                 defined($SEQlen{$t[$seq]}) || do {
                    # print STDERR "#[$.]# NO LENGTH SET for $t[$se]\n";
                    $c = '!';
                    $errcnt{SKIPPED}++;
                    next;
                 }; 
                 $sqlen = $SEQlen{$t[$seq]};
            } else { 
                 $sqlen = $SEQlen{$chr};
            };
            # print STDERR "#[$.]# ACCEPTING FIELD $t[$seq] == $chr -> $offset\n";
            $c = '+';
            $t[$src] = "tblastx";
            $t[$ftr] = "hsp";
            $t[$ori] += $offset;
            $t[$end] += $offset;
            $t[$sco] = $l[$sco];
            if ($t[$str] eq "-") {
                $t[$frm] = $frame[(($sqlen - $t[$end] + 1) % 3)];
                $cr++;
            } else {
                $t[$frm] = $frame[($t[$ori] % 3)];
                $cf++;
            };
            if ($flg) {
                unless (defined($opened{$t[$seq]})) {
                    my ($flnm);
                    ($flnm = $ofile) =~ s/\_\*\_/$t[$seq]/;
                    open($opened{$t[$seq]}, "> $flnm");
                    $opencnt++;
                };
                $FHOUT = $opened{$t[$seq]};
            } else {
                $FHOUT = *STDOUT;
            };
            print $FHOUT (join("\t", (@t[$seq..$frm]))).
                         "\tTarget \"$l[$seq]\" $l[$ori] $l[$end] ;".
                         "\tStrand $l[$str] ;\tFrame $l[$frm] ;\t$t[$other]\n";
            $g{sum}[$g{"$t[$str]$t[$frm]"}]++;
        } continue {
            &counter(++$n,$c);
        }; # while
        &counter_end($n,$c);
        close(TBXFL);
        ($opencnt > 0) && do {
            foreach my $k (keys %opened) {
                close($opened{$k});
            };
        }; 
        $summary .= sprintf("  %8s %8s %8s  %s\n",($cf+$cr),$cf,$cr,$fl);
    }; # foreach
    $g{sum}[$g{"+"}] = $g{sum}[$g{"+1"}] + $g{sum}[$g{"+2"}] + $g{sum}[$g{"+3"}];
    $g{sum}[$g{"-"}] = $g{sum}[$g{"-1"}] + $g{sum}[$g{"-2"}] + $g{sum}[$g{"-3"}];
    $g{sum}[$g{"."}] = $g{sum}[$g{".1"}] + $g{sum}[$g{".2"}] + $g{sum}[$g{".3"}];
    $g{sum}[$g{"all"}] = $g{sum}[$g{"+"}] + $g{sum}[$g{"-"}];
    print STDERR "$summary# TOTAL ".$g{sum}[$g{"all"}]." HSPs on $chr: ".
                 $g{sum}[$g{"+"}]." forward, ".$g{sum}[$g{"-"}]." reverse, ".
                 $g{sum}[$g{"."}]." without strand.\n";
    foreach my $t (qw/ 1 2 3 /) {
       printf STDERR "#\t%s : %6s\t\|\t%s : %6s\t|\t%s : %6s\n",
              "+$t",$g{sum}[$g{"+$t"}],"-$t",$g{sum}[$g{"-$t"}],
              ".$t",$g{sum}[$g{".$t"}];
    }; # foreach
    $errcnt{TOT} = $errcnt{FIELD} + $errcnt{STRAND} + $errcnt{FRAME};
    print STDERR "# $errcnt{TOT} ERRORS FOUND: $errcnt{FIELD} in fields number,".
                 " $errcnt{STRAND} in strand, $errcnt{FRAME} in frame.\n";
} # run_parseblast
my %val = ();
sub process_subject_fields() {
    my ($Sary,$Tary) = @_;
    %val = ( 'other' => [] );
    my %tag = (
        'target'  => sub {
                my $str = shift;
                $str =~ /^\"(.*?)\"             # subject sequence name
                          (?:\s+(\d+)           # start (opt)
                            (?:\s+(\d+)         # end (opt)
                              (?:\s+([\+\-\.])  # strand (opt)
                                (?:\s+([123]))? # frame (opt)
                              )?
                            )?
                          )?$/ox;
                defined($1) && ($val{'target'} = $1);
                defined($2) && ($val{'start'}  = $2);
                defined($3) && ($val{'end'}    = $3);
                defined($4) && ($val{'strand'} = $4);
                defined($5) && ($val{'frame'}  = $5);
            },
        'start'   => sub {
                my $str = shift;
                $str =~ /^(\d+)$/o; # start
                defined($1) && ($val{'start'}  = $1);
            },
        'end'     => sub {
                my $str = shift;
                $str =~ /^(\d+)$/o; # end
                defined($1) && ($val{'end'}  = $1);
            },
        'strand'  => sub {
                my $str = shift;
                $str =~ /^([\+\-\.])$/o; # strand
                defined($1) && ($val{'strand'}  = $1);
            },
        'frame'   => sub {
                my $str = shift;
                $str =~ /^([123])$/o; # frame
                defined($1) && ($val{'frame'}  = $1);
            }
        );
    foreach my $elm (@{$Sary}) {
        my (@p,$curr);
        @p = split /\s+/o, $elm, 2;
        $curr = (lc($p[0]));
        # print STDERR "#@#--> $p[0] $p[1] --".&printvals(\%val)."\n";
        defined($tag{$curr}) && do { $tag{$curr}->($p[1]); next; };
        push @{ $val{'other'} }, $elm;
    }; # foreach $elm
    defined($val{'strand'}) || do {
        print STDERR "## NO VALID STRAND ($.): @{$Sary} \n";
        return 'STRAND';
    };  
    defined($val{'frame'}) || do {
        print STDERR "## NO VALID FRAME ($.): @{$Sary} \n"; # $l[$frm] \n";
        return 'FRAME';
    };  
    @{ $Tary } = ();
    scalar(keys %val) == 6 && do {
        @{ $Tary } = ( $val{'target'}, undef, undef, $val{'start'}, $val{'end'},
                       undef, $val{'strand'}, $val{'frame'}, 
                       join(" ;\t", @{ $val{'other'} }) );
        return 'OK';
    };
    print STDERR "## SUBJECT-FIELDS NUMBER ERROR ($.): @{$Sary} \n";
    return 'FIELD';
} # process_subject_fields
sub printvals() {
    my $hsh = shift;
    my $str = '';
    foreach my $q (qw( target start end strand frame )) {
        $str .= defined($hsh->{$q}) ? ">".$hsh->{$q}."<" : ">*???*<";
    };
    return $str;
} # printvals
@


\subsctn{Gene-prediction phase}
    
\subsubsctn{[[geneid_raw2GFF.pl]]: Processing raw output from {\gnid}}

<<tangling: perl scripts>>=
echo "# --> \$BIN/geneid_raw2GFF.pl" 1>&2 ;
notangle -R"geneidraw2GFF.pl" $WORK/$nwfile.nw | cpif $BIN/geneid_raw2GFF.pl ;
perl -c $BIN/geneid_raw2GFF.pl ;
is_exec $BIN/geneid_raw2GFF.pl ;
@ 

<<geneidraw2GFF.pl>>=
<<PERL shebang>>
# Processing geneid output
#
# USAGE: geneid_raw2GFF seq_name output_dir geneid_file
#
use strict;
#
use global qw( :ExecReport :ExitStatus :CheckFiles :StringFill );
&init_timer(\@exectime);
#
$PROG = 'geneid_raw2GFF.pl';
$PRGVER = '0.9alpha';
<<Global Vars - Counter>>
#
# ARGVS
&match_argv_num(\@ARGV,3);
my ($seq,$odir,$ifile) = @ARGV;
my $seqsuffix = ".sg";
#
## MAIN
&program_started($PROG);
&clean_output_dirs();
&parse_genes();
&program_finished($PROG);
exit(0);
#
## SUBS
sub clean_output_dirs() {
    print $ERRFH "## $PROG ## PREPARING OUTPUT DIRECTORIES.\n";
    foreach my $sdir (qw/ gff prot cds /) {
        my ($cpath,@files);
        $cpath = "$odir/$sdir";
        &check_dir($cpath) || do {
            print $ERRFH "## $PROG ## EXITING NOW: CANNOT create BASE dir $cpath\n";
            exit($exit_codes{'NONEWDIR'}{CODE});
        };
        $cpath .= "/$seq$seqsuffix";
        &check_dir($cpath) || do {
            print $ERRFH "## $PROG ## EXITING NOW: CANNOT create dir $cpath\n";
            exit($exit_codes{'NONEWDIR'}{CODE});
        };
        opendir(CLR, $cpath) || do {
            print $ERRFH "## $PROG ## EXITING NOW: CANNOT open dir $cpath\n";
            exit($exit_codes{'NOREADDIR'}{CODE});
        };
        @files = grep { /^[^\.]/ } readdir(CLR);
        closedir(CLR);
        next unless scalar(@files) > 0;
        print $ERRFH "## $PROG ## REMOVING FILES FROM: $cpath\n";
        ($n,$c,$_cntN) = (0,".",60);
        foreach my $fl (@files) {
            &counter(++$n,$c);
            unlink "$cpath/$fl";
        }; # foreach $fl
        &counter_end($n,$c);
        print $ERRFH "## $PROG ## $n files have been removed from $cpath\n";
    }; # foreach $sdir
} # clean_output_dirs
<<Common PERL subs - Counter>>
sub parse_genes() {
    my ($gene,$go,$gene_cmt,$gff,$cds,$prot);
    my $prog = "geneid_v1.1";
    open(GENES,"< $ifile") || do {
        print $ERRFH "## $PROG ## EXITING NOW: CANNOT open file $ifile\n";
        exit($exit_codes{'NOREADFILE'}{CODE});
    };
    ($gff,$cds,$prot) = ('') x 3;
    $go = 0;
    while (<GENES>) {
        my @f;
        next if /^\s*$/o;
        /^\#/o && do {
            $go == 3 && do {
                $gff = $gene_cmt.$gff;
                &write_gene_to_files($gene,\$gff,\$cds,\$prot);
                $go = 0;
            };
            /^\#\s+Gene\s+(\d+)\s+/io && do {
                $gene = "$seq\_$1";
                $gene_cmt = $_;
                ($gff,$cds,$prot) = ('') x 3;
                $go = 1; # GFF
            };
            print $ERRFH $_;
            next;
        };
        chomp;
        /^>/o && do {
            /NN$/o && ($go = 2); # CDS
            /AA$/o && ($go = 3); # PROT
        };
        $go == 1 && do {
            $_ =~ s/^\s+//o; # remove leading blanks !!!
            @f = split /\s+/og, $_, 7;
            $gff .= (join("\t",($seq,$prog,@f[0..5],$gene)))."\n";
            next;
        };
        $go == 2 && do {
            $cds .= "$_\n";
            next;
        };
        $go == 3 && do {
            $prot .= "$_\n";
        };
    }; # while
    $go == 3 && do {
        $gff = $gene_cmt.$gff;
        &write_gene_to_files($gene,\$gff,\$cds,\$prot);
    };
    close(GENES);
} # parse_genes
sub write_gene_to_files() {
    my ($gene,$rgff,$rcds,$rprot) = @_;
    &write_file("$odir/gff/$seq$seqsuffix/$gene",  $rgff );
    &write_file("$odir/cds/$seq$seqsuffix/$gene",  $rcds );
    &write_file("$odir/prot/$seq$seqsuffix/$gene", $rprot);
} # write_gene_to_files
sub write_file() {
    my ($ofile, $stref) = @_;
    open(OFILE,"> $ofile") || do {
        print STDERR "## $PROG ## EXITING NOW: CANNOT open file to write: $ofile\n";
        exit($exit_codes{'NOWRITEFILE'}{CODE});
	};
    print OFILE $$stref;
    close(OFILE);
} # write_file
@

\subsubsctn{[[gffsplitstrand.pl]]: splitting GFF files by strand}

<<tangling: perl scripts>>=
echo "# --> \$BIN/gffsplitstrand.pl" 1>&2 ;
notangle -R"gffsplitstrand.pl" $WORK/$nwfile.nw | cpif $BIN/gffsplitstrand.pl ;
perl -c $BIN/gffsplitstrand.pl ;
is_exec $BIN/gffsplitstrand.pl ;
@ 

<<gffsplitstrand.pl>>=
<<PERL shebang>>
# Processing geneid output
#
# USAGE: gffsplitstrand.pl -l seq_length.gff <gff_files>
#
use strict;
#
use global qw( :ExecReport :ExitStatus :CheckFiles :StringFill );
&init_timer(\@exectime);
#
$PROG = 'gffsplitstrand.pl';
$PRGVER = '0.9alpha';
#
# VARS
my (@GFFlen,@GFF_fwd,@GFF_rev);
my ($T,$F) = (1,0);
<<Global Vars - Counter>>
#
# ARGVS
use Getopt::Std;
my %opts = ();
getopts("l:",\%opts);
       # -l GFF file which defines the max sequence length
       #    (single record having start_field==1 and end_field==seqlength)
defined($opts{l}) && &read_seq_length($opts{l});
my @files = @ARGV;
#
## MAIN
&program_started($PROG);
&on_each_single_file();
&program_finished($PROG);
exit(0);
#
## SUBS
<<Common PERL subs - Counter>>
sub read_seq_length() {
    my $sfile = shift;
    my ($GFFlen,@f);
    print $ERRFH "## $PROG ## READING LENGTH FILE...\n";
    @GFFlen = ();
    open(SLEN,"< $sfile") || do {
        print $ERRFH "## $PROG ## EXITING NOW: CANNOT open length file $sfile\n";
        exit($exit_codes{'NOREADFILE'}{CODE});
    };
    $GFFlen = <SLEN>;
    chomp($GFFlen);
    @f = split /\s+/og, $GFFlen;
    @GFFlen = (@f[0..8]);
    close(SLEN);
} # read_seq_length
sub on_each_single_file() {
    my ($fl,$fb);
    foreach $fl (@files) {
        @GFF_fwd = ();
        @GFF_rev = ();
        ($fb = $fl) =~ s/\.gff$//o;
        &load_gff_records($fl) || next;
        &sort_gff_records();
        &print_gff_records($fb);
    }; # foreach
} # on_each_single_file
sub load_gff_records() {
    my $fgff = shift;
    open(GFF,"< $fgff") || do {
        print $ERRFH "## $PROG ## SKIPPING: CANNOT open GFF file $fgff\n";
        return $F;
    };
    print $ERRFH "## $PROG ## READING GFF FILE: $fgff\n";
    ($n,$_cntN) = (0,50);
    while(<GFF>) {
        my @f;
        $c = '.';
        next if /^\s*$/o;
        next if /^\#/o;
        chomp;
        @f = split /\s+/og, $_;
        if ($f[6] eq '+') {
            push @GFF_fwd, [ @f[0..8] ];
            $c = '+';
        } elsif ($f[6] eq '-') {
            push @GFF_rev, [ @f[0..8] ];
            $c = '-';
        } else {
            $c = ':';
        };
    } continue {
        &counter(++$n,$c);
    }; # while GFF
    &counter_end($n,$c);
    print $ERRFH "## $PROG ## GFF file has $n lines, ".
                 (scalar(@GFF_fwd))." (+) records, ".
                 (scalar(@GFF_rev))." (-) records...\n";
    close(GFF);
    return $T;
} # load_gff_records
sub sort_gff_records() {
    print $ERRFH "## $PROG ## SORTING GFF RECORDS...\n";
    foreach my $ref (\@GFF_fwd,\@GFF_rev) {
        @{ $ref } = sort { $a->[3] <=> $b->[3]
                                   ||
                           $a->[4] <=> $b->[4] } @{ $ref };
        if (scalar(@GFFlen) > 0) {
            unshift @{ $ref }, [ @GFFlen ];
        };
    }; # foreach $ref
} # sort_gff_records
sub print_gff_records() {
    my $fgff = shift; # file base name (without ".gff")
    open(FWD,"> $fgff.fwd.gff") || do {
        print $ERRFH "## $PROG ## EXITING NOW: CANNOT write to file $fgff.fwd.gff\n";
        exit($exit_codes{'NOWRITEFILE'}{CODE});
    };
    open(REV,"> $fgff.rev.gff") || do {
        print $ERRFH "## $PROG ## EXITING NOW: CANNOT write to file $fgff.rev.gff\n";
        exit($exit_codes{'NOWRITEFILE'}{CODE});
    };
    print $ERRFH "## $PROG ## WRITING STRAND-GFF FILES: $fgff.(fwd|rev).gff\n";
    my $rcd;
    foreach $rcd (@GFF_fwd) {
        print FWD (join("\t",@{ $rcd }))."\n";
    }; # foreach $rcd
    foreach $rcd (@GFF_rev) {
        print REV (join("\t",@{ $rcd }))."\n";
    }; # foreach $rcd
    close(FWD);
    close(REV);
} # print_gff_records
@


\subsubsctn{[[runeval.pl]]: Running evaluation for gene-prediction}

<<tangling: perl scripts>>=
echo "# --> \$BIN/runeval.pl" 1>&2 ;
notangle -R"runeval.pl" $WORK/$nwfile.nw | cpif $BIN/runeval.pl ;
perl -c $BIN/runeval.pl ;
is_exec $BIN/runeval.pl ;
@ 
<<runeval.pl>>=
<<PERL shebang>>
# Running evaluation by chromosome.
#
# USAGE: runeval.pl real_file eval_file par_string
#
# par_string = "chromosome::release::testset::strand::program::prog_version::notes"
# 
use strict;
#
use global qw( :ExecReport :ExitStatus );
&init_timer(\@exectime);
#
$PROG = 'runeval.pl';
$PRGVER = '0.9alpha';
#
# ARGVS
&match_argv_num(\@ARGV,3);
my ($real_file,$eval_file,$param) = @ARGV;
my %data = ();
my @VARS = qw( CHR REL SEQ LEN TST STR PROG PVER NOTES );
#
## MAIN
&program_started($PROG);
&check_filenames();
&parse_param_string();
&run_eval_cmd();
&print_single_line();
&program_finished($PROG);
exit(0);
#
## SUBS
sub check_filenames() {
    unless ( -e "$real_file" && -r _ ) {
        print STDERR "## $PROG ## EXITING NOW: CANNOT open ANNOTATIONS file $real_file\n";
        exit($exit_codes{'NOREADFILE'}{CODE});
    };
    unless ( -e "$eval_file" && -r _ ) {
        print STDERR "## $PROG ## EXITING NOW: CANNOT open PREDICTIONS file $eval_file\n";
        exit($exit_codes{'NOREADFILE'}{CODE});
    };
} # check_filenames
sub parse_param_string() {
    ($data{CHR},$data{REL},$data{TST},$data{STR},$data{PROG},
     $data{PVER},$data{NOTES}) = split /::/og, $param;
} # parse_param_string
sub run_eval_cmd() {
    my ($vflg,$rnum,@varname,@vardata);
    my $cmd = "$ENV{BIN}/evaluation";
    open(EVAL,"$cmd -v $eval_file $real_file |") || do {
        print STDERR "## $PROG ## EXITING NOW: CANNOT exec \"$cmd\"\n";
        exit($exit_codes{'NOCMD'}{CODE});
    };
    $vflg = 0;
    $rnum = 0;
    while (<EVAL>) {
        print STDERR $_;
        next if /^\s*$/o;
        next if /^[-_]/o;
        next if /Level\s*$/io;
        $rnum++;
        $_ =~ /^\*\* Stats/o && do {
            $_ =~ /:\s+(.*?)\s+\(\s*(\d+)\s+/o &&
                ($data{SEQ} = $1, $data{LEN} = $2);
            next;
        };
        $_ =~ s/^\s+//o;
        $_ =~ s/\s+$//o;
        $vflg = ($_ =~ /^\d/o) ? 1 : 0;
        $vflg && do {
            @vardata = split /\s+/og, $_;
            for (my $k = 0; $k < scalar(@vardata); $k++) {
                $data{$varname[$k]} = $vardata[$k];
            }; 
            next;
        }; # $vflg
        @varname = split /\s+/og, $_;
        push @VARS, @varname;
    }; # while
    close(EVAL);
    ($rnum > 0) || do {
        print STDERR "## $PROG ## Error: Evaluation program has not produced output...\n";
    };
} # run_eval_cmd
sub print_single_line() {
    my $strng = '';
    foreach my $var (@VARS) {
        next if $var eq 'NOTES';
        defined($data{$var}) || ($data{$var} = '???');
        $strng .=  "$var\:$data{$var} ";
    }; # foreach
    $strng =~ s/\s+$/\n/o;
    print STDOUT "$strng";
} # print_single_line
@ 


\subsubsctn{[[processeval.pl]]: Processing evaluation data}

<<tangling: perl scripts>>=
echo "# --> \$BIN/process_eval.pl" 1>&2 ;
notangle -R"processeval.pl" $WORK/$nwfile.nw | cpif $BIN/process_eval.pl ;
perl -c $BIN/process_eval.pl ;
is_exec $BIN/process_eval.pl ;
@ 

<<processeval.pl>>=
<<PERL shebang>>
# Running evaluation by chromosome.
#
# USAGE: process_eval.pl [-t] eval_summary_file [ ... eval_summary_file ]
# by default it prints output sorted by program, '-t' prints sorted by testset
#
use strict;
#
use global qw( :ExecReport :ExitStatus :MathFuncts );
&init_timer(\@exectime);
#
$PROG = 'processeval.pl';
$PRGVER = '0.9alpha';
#
# ARGVS
<<processeval.pl: getoptions>>
#
# VARS
my %data = ();
my @vars       = qw( CHR REL SEQ LEN TST STR PROG PVER NOTES );
my @base_level = qw( NuR NuP TP TN FP FN SN SP AC CC );
my @exon_level = qw( ExR ExP TPe ME WE raME raWE SNe SPe SNSP );
my @gene_level = qw( GeR GeP TPg MG WG raMG raWG SNg SPg SNSPg raJG raSG );
my @sel = ( @base_level[0,1,6,7,9],
            @exon_level[0,1,2,3,4,5,6,7,8,9],
            @gene_level[0,1,2,3,4,5,6,7,8,9,10,11] ),
#
<<processeval.pl: getoptions - setting vars defaults>>
<<processeval.pl: getoptions - setting vars>>
#
## MAIN
# use Data::Dumper;
&program_started($PROG);
&parsing_input_files();
&get_var_means();
&print_output();
# print STDERR Data::Dumper->Dump([ \%data ],[ qw/ *data / ]);
&program_finished($PROG);
exit(0);
#
## SUBS
<<processeval.pl: getoptions help sub>>
sub parsing_input_files() {
    foreach my $ifile (@files) {
        open(EVAL,"< $ifile") || do {
            print $ERRFH "## $PROG ## EXITING NOW: CANNOT open summary file $ifile\n";
            next; # exit($exit_codes{'NOREADFILE'}{CODE});
        };
        while (<EVAL>) {
            my (@f,%t,$sq);
            next if /^\s*$/o;
            next if /^\#/o;
            chomp;
            @f = split /\s+/o, $_;
            %t = ( map { split /:/o, $_ } @f );
            $sq = $t{CHR}.$;.$t{SEQ}; # $; is perl SUBSEP
            defined($data{$sq}) || do {
                push @seqs, $sq;
                $seqlen{$sq} = $t{LEN};
            };
            %{ $data{$sq}{$t{PROG}}{$t{TST}}{$t{STR}} } = %t;
            foreach my $k (keys %t) {
                defined($maxlen{$k}) || do {
                    $maxlen{$k} = length($t{$k});
                    next;
                };
                $maxlen{$k} = &max($maxlen{$k},length($t{$k}));
            }; # foreach $k
        }; # while EVAL
        close(EVAL);
    }; # foreach $ifile
} # parsing_input_files
sub get_var_means() {
    foreach my $q (@seqs) {
        defined($data{$q}) || next;
        foreach my $p (@progs) {
            defined($data{$q}{$p}) || next;
            foreach my $t (@tests) {
                defined($data{$q}{$p}{$t}) || next;
                my $ref = \%{ $data{$q}{$p}{$t} };
                %{ $ref->{MEAN} } = ();
                foreach my $v (@base_level,@exon_level,@gene_level) {
                    $ref->{MEAN}{$v} = ( $ref->{FWD}{$v} + $ref->{REV}{$v} ) / 2;
                    $maxlen{$v} = &max($maxlen{$v},length($ref->{MEAN}{$v}));
                }; # foreach $v
            }; # foreach $t
        }; # foreach $p
    }; # foreach $q
} # get_var_means
sub print_output() {
    my $prt_function;
    $prt_function = ($opts{t}) ? \&print_sorted_by_test : \&print_sorted_by_prog ;
    print STDERR "### Printing by ".($opts{t} ? "TEST" : "PROGRAM")."\n";
    foreach my $k (keys %maxlen) {
        $maxlen{$k} = '%'.sprintf("%d", ($maxlen{$k} + 1)).'s';
    }; # foreach $k
    foreach my $q (@seqs) {
        defined($data{$q}) || next;
        printf STDOUT "### CHR$maxlen{CHR} : $maxlen{SEQ} ".
                      "# Length$maxlen{LEN} bp ".('#'x25)."\n",
                      (split /$;/o, $q), $seqlen{$q};
        &print_tbl_header();
        $prt_function->(\%{ $data{$q} });
        print STDOUT "###\n";
    }; # foreach $q
} # print_output
sub print_tbl_header() {
    $str = "$maxlen{PROG} $maxlen{TST} ";
    printf STDOUT $str, qw( PROGRAM TESTSET );
    foreach my $v (@sel) {
        $str = "$maxlen{$v} ";
        printf STDOUT $str, $v;
    }; # foreach $v
    print STDOUT "\n";
} # print_tbl_header
sub print_sorted_by_prog() {
    my $ref = shift;
    foreach my $p (@progs) {
        defined($ref->{$p}) || next;
        foreach my $t (@tests) {
            defined($ref->{$p}{$t}) || next;
            &print_fields($p, $t, \%{ $ref->{$p}{$t} });
        }; # foreach $t
    }; # foreach $p
} # print_sorted_by_prog
sub print_sorted_by_test() {
    my $ref = shift;
    foreach my $t (@tests) {
        print STDOUT "###\n";
        foreach my $p (@progs) {
            (defined($ref->{$p}) && defined($ref->{$p}{$t})) || next;
            &print_fields($p, $t, \%{ $ref->{$p}{$t} });
        }; # foreach $p
    }; # foreach $t
} # print_sorted_by_test
sub print_fields() {
    my ($p,$t,$rref) = @_;
    $str = "$maxlen{PROG} $maxlen{TST} ";
    printf STDOUT $str, $p, $t;
    foreach my $v (@sel) {
        $str = "$maxlen{$v} ";
        printf STDOUT $str, $rref->{MEAN}{$v};
    }; # foreach $v
    print STDOUT "\n";
} # sub print_fields
@

\parsctn{Getting options from command-line}

<<processeval.pl: getoptions help sub>>=
sub print_help() {
    print STDERR <<"+++EOF+++";
#
# $PROG [$PRGVER]
#
# Processing evaluation summaries generated by run_eval.pl
#
#   -h print this help
#   -a by default is on, you must pass it if you want to compare
#      average against recomputed stats as '-c' option disables it.
#   -c instead of computing average, recompute stats (using formulas 
#      taken from evaluation and Burset-Guigo'96).
#   -s also output the total results joining all stats from all sequences.
#   -t sort output by test-set, else by program
#   -S define a new strand strings set   : "str1 str2 ... strn"
#   -T define a new test-set strings set : "set1 set2 ... setn"
#   -P define a new program string set   : "prg1 prg2 ... prgn"
+++EOF+++
    exit(1);
} # print_help
@ 
<<processeval.pl: getoptions>>=
use Getopt::Std;
my %opts = ();
getopts("hacstS:T:P:",\%opts);
defined($opts{h}) && &print_help();
my @files = @ARGV;
@ 
<<processeval.pl: getoptions - setting vars defaults>>=
my ($str,$average_flg,$compute_flg,$totals_flg) = ('',1,0,0);
my %maxlen = ();
my %seqlen = ();
my @seqs = ();
my @strands = qw( FWD REV );
my @tests   = qw( REFSEQ ENSEMBL );
my @progs   = qw( GENSCAN SRs GENEID SGP );
my @tmp = ();
@
<<processeval.pl: getoptions - setting vars>>=
defined($opts{S}) && do {
    @tmp = split /\s+/og, $opts{S};
    (scalar(@tmp) > 0) && (@strands = @tmp);
}; # defined($opts{})
defined($opts{T}) && do {
    @tmp = split /\s+/og, $opts{T};
    (scalar(@tmp) > 0) && (@tests = @tmp);
}; # defined($opts{})
defined($opts{P}) && do {
    @tmp = split /\s+/og, $opts{P};
    (scalar(@tmp) > 0) && (@progs = @tmp);
}; # defined($opts{})
@

<<HIDE: >>=
( for n in 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 X Y NA UL ; do { { [ "$n" != "NA" -a "$n" != "UL" ] && ( echo '################################################### CHR '$n' #####'; echo '### GENSCAN'; cat $HUMUS/chr${n}/annotation/20010806/genscan/eval/chr${n}.summary ; echo '### SRs'; cat $HUMUS/chr${n}/tblastx/20020111/eval/chr${n}.summary ; echo '### GENEID';  cat $HUMUS/chr${n}/geneid/20020225/eval/chr${n}.summary ; echo '### SGP';  cat $HUMUS/chr${n}/sgp/20020225/eval/chr${n}.summary ); };  echo ''; } ; done; for  n in 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 X Y NA UL ; do { { [ `perl -e '%h = ( 1 => 1, 3 => 1, 4 => 1, 5 => 1, 8 => 1, 9 => 1, 10 => 1, 15 => 1, 17 => 1, 18 => 1, 19 => 1, X => 1, NA => 1, UL => 1 ); $k = shift @ARGV; if (defined($h{$k})) { print 1; } else { print 0; };' $n` -eq 1 ] && ( echo '################################################### CHR '$n'_random #####'; echo '### GENSCAN'; cat $HUMUS/chr${n}/annotation/20010806/genscan/eval/chr${n}_random.summary ; echo '### SRs'; cat $HUMUS/chr${n}/tblastx/20020111/eval/chr${n}_random.summary ; echo '###GENEID';  cat $HUMUS/chr${n}/geneid/20020225/eval/chr${n}_random.summary ; echo '### SGP';  cat $HUMUS/chr${n}/sgp/20020225/eval/chr${n}_random.summary ); };  echo ''; } ; done ) 2>&1 > EVAL.summary ;
$BIN/process_eval.pl    EVAL.summary > EVAL_prog.summary ;
$BIN/process_eval.pl -t EVAL.summary > EVAL_test.summary ;
@ 


\subsubsctn{[[getHSPSR.pl]]: Re-scoring SRs}

<<tangling: perl scripts>>=
echo "# --> \$BIN/getHSPSR.pl" 1>&2 ;
notangle -R"getHSPSR.pl" $WORK/$nwfile.nw | cpif $BIN/getHSPSR.pl ;
perl -c $BIN/getHSPSR.pl ;
is_exec $BIN/getHSPSR.pl ;
@
 
<<getHSPSR.pl>>=
<<PERL shebang>>
# Re-scoring SRs to produce HSP-SRs for SGP homology.
#
# USAGE: getHSPSR.pl "chrname" < SR_file.gff > HSP-SR_file.gff > stdout.report
#
<<PERL strict pragma + info>>
my $PROG = 'getHSPSR.pl';
my $PRGVER = '0.9alpha';
#
my $chr = shift;
my ($seq,$src,$ftr,$ori,$end,$sco,$str,$frm) = (0..7);
my %g = ( "+1" => 0,  "+2" => 1,  "+3" => 2,  "+" => 3,
          "-1" => 4,  "-2" => 5,  "-3" => 6,  "-" => 7,
          ".1" => 8,  ".2" => 9,  ".3" => 10, "." => 11,
                     "all" => 12,            "sum" => [ (0) x 13 ] );
my $HSPminLEN = 1; # $ori + $HSPminLEN - 1 ==> minimum length is 1 nucleotide
my $S_CUTOFF = 26;
my $SCF = 0; # substract to tblastx scores S_CUTOFF - SCF
my $DSC = $S_CUTOFF - $SCF;
my $SHSP  = 0;    # SHSP=6 # shrink hsp by $SHSP
my $WTBX  = 0.19; # weigth of tblastx score
my $WTBXF = 0.30; # weigth of tblastx score
my $WTBXI = 0.20; # weigth of tblastx score
my $WTBXT = 0.30; # weigth of tblastx score
while (<STDIN>) {
    my @l;
    next if /^#/o;
    next if /^\s*$/o;
    chomp;
    @l = split /\s+/og, $_;
    next unless $l[$sco] > $S_CUTOFF;
    $l[$sco] = sprintf("%.6f",($l[$sco] - $DSC) * $WTBX);
    $l[$ori] += $SHSP;
    $l[$end] -= $SHSP;
    next if $l[$end] < ($l[$ori] + $HSPminLEN - 1);
    print STDOUT (join("\t", (@l)))."\n";
    $g{sum}[$g{"$l[$str]$l[$frm]"}]++;
}; # while
$g{sum}[$g{"+"}] = $g{sum}[$g{"+1"}] + $g{sum}[$g{"+2"}] + $g{sum}[$g{"+3"}];
$g{sum}[$g{"-"}] = $g{sum}[$g{"-1"}] + $g{sum}[$g{"-2"}] + $g{sum}[$g{"-3"}];
$g{sum}[$g{"."}] = $g{sum}[$g{".1"}] + $g{sum}[$g{".2"}] + $g{sum}[$g{".3"}];
$g{sum}[$g{"all"}] = $g{sum}[$g{"+"}] + $g{sum}[$g{"-"}];
print STDERR "# TOTAL ".$g{sum}[$g{"all"}]." HSP-SRs on $chr: ".
             $g{sum}[$g{"+"}]." forward, ".$g{sum}[$g{"-"}]." reverse, ".
             $g{sum}[$g{"."}]." without strand.\n";
foreach my $t (qw/ 1 2 3 /) {
   printf STDERR "#\t%s : %6s\t\|\t%s : %6s\t|\t%s : %6s\n",
          "+$t",$g{sum}[$g{"+$t"}],"-$t",$g{sum}[$g{"-$t"}],
          ".$t",$g{sum}[$g{".$t"}];
}; # foreach
# foreach my $t (qw/ +1 +2 +3 -1 -2 -3 /) {
#    printf STDERR "#\t%s : %s\n",$t,$g{sum}[$g{$t}];
# }; # foreach
#
exit(0);
@


\sctn{Job Control System}

\subsctn{Interacting with [[MySQL]]} %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

We are going to base our job control system on a set of [[MySQL]] tables. Here we are setting up the main database, in the following subsections we are defining the database tables and the scripts to handle data within them.

<<MySQL: Creating Database Report>>=
#
# Creating mysql DataBase (root)
#
shell>  mysql -h monstre1 -u root -p   (u:user, p:passwd)
Enter password:
Welcome to the MySQL monitor.  Commands end with ; or \g.
Your MySQL connection id is 772 to server version: 3.23.36

Type 'help;' or '\h' for help. Type '\c' to clear the buffer

mysql> CREATE DATABASE db_Hsapiens;
Query OK, 1 row affected (0.06 sec)

mysql> show databases;
+-----------------+
| Database        |
+-----------------+
| admin_db        |
| db_Hsapiens     |
| db_SPtest       |
| ensembl_generic |
| horde           |
| mysql           |
| ontology_db     |
| popper          |
| smartie         |
| test            |
| texbiblio_db    |
| web_db          |
+-----------------+
12 rows in set (0.01 sec)

# Accession allowed only from monstre
mysql> GRANT ALL on db_Hsapiens.* TO genome@localhost IDENTIFIED BY "xxxx" ;
Query OK, 0 rows affected (0.10 sec)
# Access from anywhere in IMIM domain
mysql> GRANT ALL on db_Hsapiens.* TO "genome"@"%.imim.es" IDENTIFIED BY "xxxx" ;
Query OK, 0 rows affected (0.10 sec)
#
# Accessing to mysql DataBase (user)
#
shell>  mysql -h monstre1 -u genome -p db_Hsapiens 
#
@ 

\subsubsctn{[[db_Hsapiens.sql]]: Building database tables in [[MySQL]]}

<<MySQL: Setting up Tables>>=
/* Setting working database */
USE db_Hsapiens ;

/* Sequence related tables */
CREATE TABLE tb_chromosome
(
  id          CHAR(2)      NOT NULL,
  code        INT UNSIGNED NOT NULL AUTO_INCREMENT PRIMARY KEY,
  version     VARCHAR(50),
  descr       TEXT
);
CREATE TABLE tb_sequence
(
  id          VARCHAR(25)  NOT NULL,
  code        INT UNSIGNED NOT NULL AUTO_INCREMENT PRIMARY KEY,
  chr         INT UNSIGNED NOT NULL,
  length      INT UNSIGNED NOT NULL,
  version     CHAR(14)     NOT NULL, /* YYYYMMDDhhmmss */
  composition VARCHAR(150) NOT NULL,
  descr       TEXT
);

/* Process related tables */
CREATE TABLE tb_job
(
  id      VARCHAR(25)  NOT NULL,
  code    INT UNSIGNED NOT NULL AUTO_INCREMENT PRIMARY KEY,
  descr   TEXT,
  path    VARCHAR(100) NOT NULL,
  jxid    VARCHAR(25)  NOT NULL
);
CREATE TABLE tb_step
(
  id      VARCHAR(25)  NOT NULL,
  code    INT UNSIGNED NOT NULL AUTO_INCREMENT PRIMARY KEY,
  job     INT UNSIGNED NOT NULL,
  version VARCHAR(40), /* which program and its version is being run */
  descr   TEXT,
  path    VARCHAR(100) NOT NULL,
  sxid    VARCHAR(25)  NOT NULL,
  idir    VARCHAR(200) NOT NULL,
  odir    VARCHAR(200) NOT NULL,
  edir    VARCHAR(200) NOT NULL,
  script  TEXT         NOT NULL
);

/* Execution related tables */
CREATE TABLE tb_status
(
  id      VARCHAR(10)  NOT NULL,
  code    INT UNSIGNED NOT NULL AUTO_INCREMENT PRIMARY KEY,
  descr   TEXT,
  color   VARCHAR(30)  NOT NULL
);
CREATE TABLE tb_exec
(
  status       INT UNSIGNED NOT NULL,
  chr_seq      INT UNSIGNED NOT NULL,
  job_step     INT UNSIGNED NOT NULL,
  exec_pid     INT UNSIGNED NOT NULL,
  exec_date    CHAR(14)     NOT NULL, /* YYYYMMDDhhmmss */
  host         VARCHAR(15)  NOT NULL,
  user         VARCHAR(15)  NOT NULL,
  stdout       TEXT,
  stderr       TEXT
);

/* EOF */
@
<<tangling: mySQL scripts>>=
#
# MySQL tables description for db_Hsapiens
echo "# --> \$MySQLPAR/db_Hsapiens.sql" 1>&2 ;
notangle -R'MySQL: Setting up Tables' $WORK/$nwfile.nw | \
    cpif $MySQLPAR/db_Hsapiens.sql;
#
@ 
 

\subsubsctn{[[db_Hsapiens_in.pm]]: Initialitation files}

<<MySQL: initialization file for Perl scripts>>=
#
# db_Hsapiens_in.pm
#
#   setting user access to db_Hsapiens mySQL database
#
<<Version Control Id Tag>>
#
package db_Hsapiens_in;
use strict;
use vars qw( @ISA @EXPORT @EXPORT_OK %EXPORT_TAGS $VERSION
             $mySQL_db $mySQL_host $mySQL_user $mySQL_pswd );

use Exporter;
$VERSION = 1.00;
@@ISA = qw(Exporter);
@@EXPORT = qw( $mySQL_db $mySQL_host $mySQL_user $mySQL_pswd );
# @@EXPORT_OK = qw( );
# %EXPORT_TAGS = ();

$mySQL_db   = 'db_Hsapiens';
$mySQL_host = 'monstre1.imim.es';
$mySQL_user = 'genome';
$mySQL_pswd = ''; # use vi to introduce the pswd for this user!!!

1;
@
<<BASH Variables: Perl>>=
#
PERL5OPT="-I$BBIN/libperl" ;
export PERL5OPT;
#
@ 


This file was tangled the first time, since then it is under version control and edited by hand...

<<tangling: mySQL param>>=
# 
# mySQL perl auxiliarly files
# 
# notangle -R'MySQL: initialization file for Perl scripts' \
#     $WORK/$nwfile.nw | cpif $MySQLPAR/db_Hsapiens_in.pm ;
# chmod 660 $MySQLPAR/db_Hsapiens_in.pm ;
#
@ 

The following files will serve to load rows on different tables with [[admin_db_Hsapiens.pm]].

<<MySQL: adm file - chrs>>=
#
# chrs.tbl
#
#   chromosome table
#
<<Version Control Id Tag>>
#
# Setting global version (must start with '#># ')
#
#># Golden Path 20010806
#
# Record Format:
#   <chr_id> <version> <description>
# where:
#       <version> == . --> global version
#   <description> == . --> undef
 1 . .
 2 . .
 3 . .
 4 . .
 5 . .
 6 . .
 7 . .
 8 . .
 9 . .
10 . .
11 . .
12 . .
13 . .
14 . .
15 . .
16 . .
17 . .
18 . .
19 . .
20 . .
21 . .
22 . .
 X . .
 Y . .
#
# NA . .
# UL . .
UN . .
#
@  %%% MySQL: adm file - chrs

<<MySQL: adm file - seqs>>=
#
# seqs.tbl
#
#   sequences for each chromosome
#
<<Version Control Id Tag>>
#
# Record Format:
#   <chr_id> <sequence_id> <length> <file_modifying_date> <description>
# where:
#   <file_modifying_date> is in YYYYMMDDhhmmss format
#   <description> == . --> undef
# 
@  %%% MySQL: adm file - seqs

<<MySQL: adm file - jobs>>=
#
# jobs.tbl
#
#   main process id table
#
<<Version Control Id Tag>>
#
<<JOBheader: Sequence Analysis>>
<<JOBheader: HsapGPa x MGSCv3 WUTBLASTX>>
<<JOBheader: Running GENEID standard>>
<<JOBheader: SGP with HSAPgpa x MGSCv3 homology>>
<<JOBheader: HsapGPa x MmusRIKENcDNA WUTBLASTX>>
<<JOBheader: SGP with HSAPgpa x MmusRIKENcDNA homology>>
<<JOBheader: SGP with HSAPgpa x MmusMGSCv3+RIKENcDNA homology>>
<<JOBheader: Visualizing Results with Apollo>>
@  %%% MySQL: adm file - jobs

<<MySQL: adm file - steps>>=
#
# steps.tbl
#
#   process step (executable scripts) id table
#
<<Version Control Id Tag>>
#
@  %%% MySQL: adm file - steps
 
<<MySQL: adm file - status>>=
#
# status.tbl
#
#   program execution status table
#
<<Version Control Id Tag>>
#
# Record format:
#   <process_ID> <color_name>
#   <description-line_0>
#    ...
#   <description-line_n>
#   // # this is the new record separator
#
TODO     lightblue
Process was not started yet... 
//
RUNNING  steelblue
Current step is being executed at this moment...
//
DONE     seagreen
This step has finished without errors...
//
CHECK    orange
Process reported warnings...
Verify its execution log but following steps are going to be run...
//
KILLED   salmon
Program execution was interrupted by user... 
Following steps are being skipped...
//
DIED     red
An error ocurred when running this step...
Please, check error report that has been produced...
//
SKIPPED  gold
This step has been skipped due to a unfinished previous step... 
Please, check previous steps of the current job...
//
N/A      lightgrey
Job status is Not Available at this moment...
Just wait to the next update round to see if connection problem persist...
//
@  %%% MySQL: adm file - status

<<tangling: mySQL param>>=
# 
# mySQL perl auxiliarly files 
( echo "###"; echo "### PARAMETER FILES FOR H.sapiens..."; echo "###" ) 1>&2 ; 
for n in chrs jobs steps status;
  do { 
       echo "# --> \$MySQLPAR/$n.tbl" 1>&2 ;
       notangle -R"MySQL: adm file - $n" \
           $WORK/$nwfile.nw | cpif $MySQLPAR/$n.tbl ;
     }; 
  done;
# seqs.tbl is produced by initialization script on sequence analysis section
echo "# --> \$MySQLPAR/seqs.tbl" 1>&2 ;
{ notangle -R'MySQL: adm file - seqs' $WORK/$nwfile.nw ; 
  cat $HUMUS/seqid_list ; } | cpif $MySQLPAR/seqs.tbl ;
#
@ 

The following files contain the relevant data for mouse.

<<MySQL: adm file - mouse chrs>>=
#
# Mmusculus_chrs.tbl
#
#   chromosome table
#
<<Version Control Id Tag>>
#
# Setting global version (must start with '#># ')
#
#># MGSC V3 20020411
#
# Record Format:
#   <chr_id> <version> <description>
# where:
#       <version> == . --> global version
#   <description> == . --> undef
 1 . .
 2 . .
 3 . .
 4 . .
 5 . .
 6 . .
 7 . .
 8 . .
 9 . .
10 . .
11 . .
12 . .
13 . .
14 . .
15 . .
16 . .
17 . .
18 . .
19 . .
 X . .
# Y . .
#
UN . .
# NA . .
# UL . .
#
@  %%% MySQL: adm file - Mmusculus_chrs

<<MySQL: adm file - mouse seqs>>=
#
# Mmusculus_seqs.tbl
#
#   sequences for each chromosome
#
<<Version Control Id Tag>>
#
# Record Format:
#   <chr_id> <sequence_id> <length> <file_modifying_date> <description>
# where:
#   <file_modifying_date> is in YYYYMMDDhhmmss format
#   <description> == . --> undef
# 
@  %%% MySQL: adm file - Mmusculus_seqs

<<tangling: mySQL param>>=
# 
# mySQL perl auxiliarly files
( echo "###"; echo "### PARAMETER FILES FOR M.musculus..."; echo "###" ) 1>&2 ; 
for n in chrs ; #  jobs steps status;
  do { 
       echo "# --> \$MySQLPAR/Mmusculus_$n.tbl" 1>&2 ;
       notangle -R"MySQL: adm file - mouse $n" \
           $WORK/$nwfile.nw | cpif $MySQLPAR/Mmusculus_$n.tbl ;
     }; 
  done;
# seqs.tbl is produced by initialization script on sequence analysis section
echo "# --> \$MySQLPAR/Mmusculus_seqs.tbl" 1>&2 ;
{ notangle -R'MySQL: adm file - mouse seqs' $WORK/$nwfile.nw ; 
  cat $MUSHU/seqid_list ; } | cpif $MySQLPAR/Mmusculus_seqs.tbl ;
#
@ 


\subsubsctn{[[db_Hsapiens.pm]]: Perl interface to mySQL database}

<<tangling: mySQL perl scripts>>=
# 
# mySQL perl scripts: interacting with mySQL DB
echo "# --> \$LIBPERL/db_Hsapiens.pm" 1>&2 ;
notangle -R'MySQL: perl DB interface' \
    $WORK/$nwfile.nw | cpif $LIBPERL/db_Hsapiens.pm ;
perl -c $LIBPERL/db_Hsapiens.pm ;
is_exec $LIBPERL/db_Hsapiens.pm ;
#
@ 

<<MySQL: perl DB interface>>=
<<PERL shebang>>
# db_Hsapiens.pm
#
package db_Hsapiens;
use strict;
<<Use Modules - Dumper>>
#
use vars qw(
           @ISA @EXPORT @EXPORT_OK %EXPORT_TAGS $VERSION 
           $mySQL_db $mySQL_host $mySQL_user $MySQLPAR $dbh $sth
           $isDBon %status %chrs %jobs @seqs @steps
           );

use Exporter;
$VERSION = 1.00;
@@ISA = qw(Exporter);
@@EXPORT = qw(
    $mySQL_db $mySQL_host $mySQL_user $isDBon
    &open_DB &close_DB $MySQLPAR $dbh $sth
    &get_tbl_hash &get_row_fields &put_row_fields
    &get_DB_codes %status %chrs %jobs @seqs @steps
    &del_all_from_tbl
  );
@@EXPORT_OK = qw(
    &connection_details &load_to_tbl_ifdef
    &list_tables &show_tbl_desc &count_tbl_elements
  );
%EXPORT_TAGS = (
    AdminFunc => [ qw( &connection_details &load_to_tbl_ifdef
                       &list_tables &show_tbl_desc &count_tbl_elements
                       ) ],
    );

# use lib "$LIBPERL";
use db_Hsapiens_in;
my $dsn = "DBI:mysql:database=$mySQL_db;host=$mySQL_host";
#
use DBI;
#
use global;
#
$MySQLPAR = $ENV{MySQLPAR} || do {
        print STDERR $Messages{'ENVNOTDEF'}->("MySQLPAR");
        exit($exit_codes{'ENVUNDEFVAR'}{CODE});
    };

$global::_verbose{RAW} = $T;
$global::_verbose{DBCMD} = $F;
$global::_verbose{DB} = $F;
$isDBon = $F;
$global::CmdLineOpts{'DB-Verbose'} = sub {
        $_verbose{DB} = $T;
        $_verbose{DBCMD} = $T;
    };
$global::CmdLineOpts{'DB-verbose'} = sub { $_verbose{DB} = $T };
$global::CmdLineOpts{'DBsc|DB-showcommands'} = sub { $_verbose{DBCMD} = $T };

sub connection_details() {
    print STDERR $Messages{'DBIHEADER'}->("DBI: Available DBD Drivers");
    print STDERR $Messages{'DBIMSG'}->(
        "",(map { "\t$_" } DBI->available_drivers),"");
    print STDERR $Messages{'DBIHEADER'}->("mySQL DataBase Connection Info:");
    print STDERR $Messages{'DBIMSG'}->("","\tDBname: $mySQL_db",
        "\t  Host: $mySQL_host","\t  User: $mySQL_user","");
} # connection_details

sub open_DB() {
    my $trace_level = shift || 0;
    print STDERR $Messages{'DBIHEADER'}->(
        "Openning mySQL connection to \'$mySQL_db\' DB...");
    DBI->trace($trace_level);
    $dbh = DBI->connect($dsn, $mySQL_user, $mySQL_pswd,
                        { RaiseError => 1, AutoCommit => 1 } );
    # put here error processing...
    print STDERR $Messages{'DBIMSG'}->(
        "","mySQL connection to \'$mySQL_db\' DB succesfully established.","");
    $isDBon = $T;
} # open_DB

sub close_DB() {
    defined($dbh) && $dbh->disconnect();
    # put here error processing...
    print STDERR $Messages{'DBIHEADER'}->(
        "mySQL connection to \'$mySQL_db\' DB has been closed.");
    $isDBon = $F;
} # close_DB

sub list_tables() {
    my @tbls;
    print STDERR $Messages{'DBIHEADER'}->(
        "Retrieving tables definition for '$mySQL_db' DB...");
    @tbls = $dbh->func('_ListTables');
    # put here error processing...
    return @tbls;
} # do_DB

sub show_tbl_desc() {
    my ($table, $fhref) = @_;
    my @strdesc = ();
    $sth = $dbh->prepare(qq{
           DESC $table /* Shows mySQL table description */
         });
    # put here error processing...
    $sth->execute;
    # put here error processing...
    push @strdesc, '|-> DESC '.$table;
    while (my @fld = $sth->fetchrow_array()) {
        # put here error processing...
        push @strdesc, sprintf("\t%-10s : %s",$fld[0],@fld[1..$#fld]);
    };
    $sth->finish;
    # put here error processing...
    print $fhref $Messages{'DBIMSG'}->("",@strdesc);
} # show_tbl_desc

sub count_tbl_elements() {
    my ($fhref) = @_;
    print $fhref $Messages{'DBIHEADER'}->(
        "Counting elements number for tables on '$mySQL_db' DB...");
    my %tbls = ();
    foreach my $t (&list_tables()) {
        my $str = qq{
            SELECT COUNT(*) FROM $t /* Counting elements for mySQL table */
            };
        print $fhref $Messages{'DBICMD'}->("$str") if $_verbose{DBCMD};
        $sth = $dbh->prepare($str);
        $sth->execute();
        $tbls{$t} = $sth->fetchrow_array();
        $sth->finish;
    }; # foreach $t
    print $fhref $Messages{'DBIMSG'}->("");
    foreach my $k (keys %tbls) {
        print $fhref $Messages{'DBIMSG'}->(
                         sprintf("---> %-15s : %s",$k,$tbls{$k}));
    }; # foreach $k
    print $fhref $Messages{'DBIMSG'}->("");
} # count_tbl_elements

sub del_all_from_tbl() {
    my $table = shift;
    my ($dsth,$dstr);
    $dstr = qq{
        DELETE FROM $table
		};
    print STDERR $Messages{'DBICMD'}->("$dstr") if $_verbose{DBCMD};
    $dsth = $dbh->prepare($dstr);
    $dsth->execute();
    $dsth->finish();
    print STDERR $Messages{'DBIMSG'}->("All rows in \"$table\" were deleted...");
} # del_all_from_tbl

sub load_to_tbl_ifdef() { # mv $field to end of args and set as an array to allow multiple fields select... ;^D
    my ($table, $fields, $aryfld, $aryrow, $delflg) = @_;
    my ($fldstr,$valstr,$filter,$ssth,$sstr,$isth,$istr);
    defined($delflg) || ($delflg = $F);
    print STDERR $Messages{'DBIHEADER'}->(
        "REBUILDING FIELDS for TABLE \"$table\"") if $_verbose{DB};
    $fldstr = "(".join(', ',@{$aryfld}).")"; 
    $valstr = "VALUES(".join(',',('?') x scalar(@{$aryfld})).")"; 
    $filter = join("\n                 AND ",
                   ( map { $aryfld->[$_].'=?' } @{ $fields } ));
    $sstr = qq{
        SELECT COUNT(*)        /* COUNT(Saryfld->[Sfield]) */
               FROM $table
               WHERE $filter   /* Saryfld->[Sfield]=Q */
		};
    $istr = qq{
        INSERT $table
               $fldstr
               $valstr /* adding new records */
        };
    &del_all_from_tbl($table) if $delflg;
    print STDERR $Messages{'DBICMD'}->("$sstr$istr") if $_verbose{DBCMD};
    $ssth = $dbh->prepare($sstr);
    $isth = $dbh->prepare($istr);
    foreach my $row (@{$aryrow}) {
        my $count;
        my @trow = (map { $row->[$_] } @{ $fields });
        $ssth->execute(@trow);
        $count = $ssth->fetchrow_array();
        ($count == 0) && do {
            print STDERR $Messages{'DBIMSG'}->(
                "\"@trow\" NOT found in \"$table\": INSERTING...");
            $isth->execute(@{$row});
            next;
		};
        print STDERR $Messages{'DBIMSG'}->(
            "\"@trow\" already defined in \"$table\": SKIPPING...");
    }; # foreach $row 
    print STDERR $Messages{'DBIMSG'}->(
        "",(scalar (@{$aryrow}))." records were checked on \"$table\"...","");
    $ssth->finish();
    $isth->finish();
} # load_to_tbl_ifdef

sub get_tbl_hash() {
    # here we assume that the first element of $aryfld is a hash key
    my ($href, $table, $aryflds, $queryflds, $queryvals) = @_;
    print STDERR $Messages{'DBIHEADER'}->(
        "RETRIEVING HASH from TABLE \"$table\"") if $_verbose{DB};
    my ($ssth,$sstr,@ary,$aryfld_len,$fldstr,$valstr);
    $aryfld_len = $#{ $aryflds };
    $fldstr = join(', ',@{ $aryflds });
    $valstr = &build_where_clause($queryflds,$queryvals);
    $sstr = qq{
        SELECT $fldstr
               FROM $table $valstr
        }; 
    print STDERR $Messages{'DBICMD'}->("$sstr") if $_verbose{DBCMD};
    $ssth = $dbh->prepare($sstr);
    $ssth->execute();
    while (@ary = $ssth->fetchrow_array()) {
        %{ $href->{$ary[0]} } = map { $aryflds->[$_] => $ary[$_]
                                      } (1..$aryfld_len);
    }; # while @ary
    print STDERR $Messages{'DBIMSG'}->(
        "",(scalar (keys %{$href}))." records were retrieved from \"$table\"...","");
    $ssth->finish();
} # get_tbl_hash
sub build_where_clause() {
    my ($queryflds, $queryvals) = @_;
    my ($valstr,$q_len);
    $valstr = "";
    ((defined($queryflds) && scalar(@{ $queryflds }) > 0) &&
     (defined($queryvals) && scalar(@{ $queryvals }) > 0)) && do {
        # ensure that both arys ($queryflds & $queryvals)
        # have same length in calling function/script, and that are paired too...
        $q_len = &min($#{ $queryflds }, $#{ $queryvals });
        for (my $i = 0; $i <= $q_len; $i++) {
           $valstr .= "$queryflds->[$i] = ".
                      ($dbh->quote($queryvals->[$i]))." \n";
	    };
        chomp($valstr);
        $valstr = join('\n               AND ', (split /\n/og, $valstr));
        $valstr = "\n               WHERE $valstr";
	};
    return $valstr;
} # build_where_clause
sub get_row_fields() {
    my ($table, $outflds, $queryflds, $queryvals) = @_;
    my ($ssth,$sstr,$fldstr,$valstr,$q_len,@out);
    $fldstr = join(', ',@{$outflds});
    print STDERR $Messages{'DBIHEADER'}->(
        "RETRIEVING \"$fldstr\" ROW(s) from TABLE \"$table\"") if $_verbose{DB};
    $valstr = &build_where_clause($queryflds,$queryvals);
    $sstr = qq{
        SELECT $fldstr
               FROM $table $valstr
		};
    print STDERR $Messages{'DBICMD'}->("$sstr") if $_verbose{DBCMD};
    $ssth = $dbh->prepare($sstr);
    $ssth->execute();
    @out = $ssth->fetchrow_array();
    $ssth->finish();
    scalar(@out) > 0 || do {
        print STDERR $Messages{'DBIMSG'}->(
            "","NONE rows were selected from \"$table\"",
               "NONE fields were retrieved...","");
        return ( undef );
    };
    print STDERR $Messages{'DBIMSG'}->(
        "",scalar(@out)." fields were retrieved from \"$table\"...","");
    return @out;
} # get_row_fields

sub get_DB_codes() {
    my (@sel_fields,@qry_fields,@qry_values);
    print STDERR $Messages{'DBIHEADER'}->(
        "LOADING MAIN TABLES into PROGRAM VARIABLES") if $_verbose{DB};
    #
    # Loading Status tables
    %status = ();
    @sel_fields =  qw( id code descr color );
    &get_tbl_hash(\%status, 'tb_status', \@sel_fields);
    print STDERR (Data::Dumper->Dump([ \%status ],
                                  [ qw( *status ) ])) if $_verbose{DEBUG};
    #
    # Loading Chromosome tables
    %chrs = ();
    @sel_fields =  qw( id code version descr );
    &get_tbl_hash(\%chrs, 'tb_chromosome', \@sel_fields);
    foreach my $key (keys %chrs) {
        %{ $chrs{$key}{seqs} } = ();
        @sel_fields = qw( id code length version composition descr );
        @qry_fields = qw( chr );
        @qry_values = ( $chrs{$key}{code} );
        &get_tbl_hash(\%{ $chrs{$key}{seqs} }, 'tb_sequence',
                      \@sel_fields, \@qry_fields, \@qry_values);        
    }; # foreach $key
    print STDERR (Data::Dumper->Dump([ \%chrs ],
                                  [ qw( *chrs ) ])) if $_verbose{DEBUG};
    #
    # Loading Job tables
    %jobs = ();
    @sel_fields =  qw( id code path jxid descr );
    &get_tbl_hash(\%jobs, 'tb_job', \@sel_fields);
    foreach my $key (keys %jobs) {
        %{ $jobs{$key}{steps} } = ();
        @sel_fields = qw( id code version descr path
                          sxid idir odir edir script );
        @qry_fields = qw( job );
        @qry_values = ( $jobs{$key}{code} );
        &get_tbl_hash(\%{ $jobs{$key}{steps} }, 'tb_step',
                      \@sel_fields, \@qry_fields, \@qry_values);        
    }; # foreach $key
    print STDERR (Data::Dumper->Dump([ \%jobs ],
                                  [ qw( *jobs ) ])) if $_verbose{DEBUG};
    #
    # Building order arrays for chromosome seqs and job steps
    &build_ordering_ary(\@seqs, \%chrs, 'code', 'seqs',  'code');
    &build_ordering_ary(\@steps, \%jobs, 'code', 'steps', 'code');
    print STDERR (Data::Dumper->Dump([ \@seqs, \@steps ],
                                  [ qw( *seqs   *steps ) ])) if $_verbose{DEBUG};
} # get_DB_codes
sub build_ordering_ary() {
    my ($arf,$hrf,$Skey,$sfeat,$skey) = @_;
    print STDERR $Messages{'DBIMSG'}->(
        "","SORTING \"$sfeat\" to build ordering array (\@$sfeat)...","");
    @{ $arf } = ();
    foreach my $key (keys %{ $hrf }) {
        my @order = ();
        foreach my $yek (keys %{ $hrf->{$key}{$sfeat} }) {
            push @order, [ $hrf->{$key}{$sfeat}{$yek}{$skey}, [ $key, $yek ] ];
        }; # foreach $key
        @order = map  { $_->[1] }
                 sort { $a->[0] <=> $b->[0] }
                 map  { [ $_->[0], $_->[1] ] } @order;
        push @{ $arf }, [ $hrf->{$key}{$Skey}, [ @order ] ]
    }; # foreach $key
    @{ $arf } = map  { @{ $_->[1] } }
                sort { $a->[0] <=> $b->[0] }
                map  { [ $_->[0], $_->[1] ] } @{ $arf };
} # build_ordering_ary
#
sub put_row_fields() {
    my ($table, $fields, $aryfld, $aryrow) = @_;
    my ($q_len,$filter,$fldstr,$valstr,$setstr,
        $usth,$ustr,$ssth,$sstr,$isth,$istr,@trow,$count);
    print STDERR $Messages{'DBIHEADER'}->(
        "UPDATING FIELDS for TABLE \"$table\"") if $_verbose{DB};
    $q_len = &min($#{ $aryfld }, $#{ $aryrow });
#    my @setstr = ();
#    for (my $i = 0; $i <= $q_len; $i++) {
#        push @setstr, $aryfld->[$i].'='.($dbh->quote($aryrow->[$i]));
#	 };
    $filter = join("\n                 AND ",
                   ( map { $aryfld->[$_].'=?' } @{ $fields } ));
    $fldstr = "(".join(', ',@{$aryfld}).")"; 
    $valstr = "VALUES(".join(',',('?') x scalar(@{ $aryfld })).")";
    $setstr = join(",\n                   ",
                   ( map { $_.'=?' } @{ $aryfld } ));
#    $setstr = join(",\n                   ",@setstr);
    $sstr = qq{
        SELECT COUNT(*)        /* COUNT(Saryfld->[Sfield]) */
               FROM $table
               WHERE $filter   /* Saryfld->[Sfield]=Q */
		};
    $istr = qq{
        INSERT $table
               $fldstr
               $valstr /* adding new records */
        };
    $ustr = qq{
        UPDATE $table
               SET $setstr
               WHERE $filter   /* Saryfld->[Sfield]=Q */
		};
    print STDERR $Messages{'DBICMD'}->("$sstr$istr$ustr") if $_verbose{DBCMD};
    $ssth = $dbh->prepare($sstr);
    @trow = (map { $aryrow->[$_] } @{ $fields });
    $ssth->execute(@trow);
    $count = $ssth->fetchrow_array();   
    $ssth->finish();
    if ($count) {
        print STDERR $Messages{'DBIMSG'}->(
            "","UPDATING fields on selected record from \"$table\"...","")
            if $_verbose{DB};
        $usth = $dbh->prepare($ustr);
        $usth->execute(@{ $aryrow },@trow);
        $usth->finish();
	} else {
        print STDERR $Messages{'DBIMSG'}->(
            "","INSERTING new field on selected record from \"$table\"...","")
            if $_verbose{DB};
        $isth = $dbh->prepare($istr);
        $isth->execute(@{ $aryrow });
        $isth->finish();
    };
} # put_row_fields

1;
@ 


\subsubsctn{[[admin_db_Hsapiens.pl]]: Loading administrative tables}

<<tangling: mySQL perl scripts>>=
# 
# mySQL perl scripts: loading mySQL admin tables
echo "# --> \$MySQLPAR/admin_db_Hsapiens.pl" 1>&2 ;
notangle -R'MySQL: Initialize administrative tables' \
    $WORK/$nwfile.nw | cpif $MySQLPAR/admin_db_Hsapiens.pl ;
perl -c $MySQLPAR/admin_db_Hsapiens.pl ;
is_exec $MySQLPAR/admin_db_Hsapiens.pl ;
#
@ 

<<MySQL: Initialize administrative tables>>=
<<PERL shebang>>
# admin_db_Hsapiens.pl
#
use strict;
# use lib "$LIBPERL";
use db_Hsapiens qw( :DEFAULT :AdminFunc );
# $MySQLPAR/$admfiles[$i].tbl
# my @admfiles = qw/ chrs seqs jobs steps status /;
#
use global;
&init_timer(\@exectime);
#
$PROG = 'admin_db_Hsapiens.pl';
$PRGVER = '0.9alpha';
#
my (%PARAM, %tjobs); 
$PARAM{LIBSTEP} = $ENV{LIBSTEP} || do {
        print STDERR $Messages{'ENVNOTDEF'}->("MySQLPAR");
        exit($exit_codes{'ENVUNDEFVAR'}{CODE});
    };
my %clear = ( ALL => $F, EXEC => $F );
$global::CmdLineOpts{'clear-all'}  = sub { $clear{ALL}  = $T };
$global::CmdLineOpts{'clear-exec'} = sub { $clear{EXEC} = $T };
#
## MAIN
&parse_cmdline();
&check_clear_var();
&program_started($PROG);

&connection_details();

&open_DB();

&listing_tables();

# my (%tstatus,%tchrs,%tjobs);
# ($clear{EXEC}) || do {
#     &get_DB_codes();
#     %tstatus = %status; %tchrs = %chrs; %tjobs = %jobs;
# };
&load_status_tbl("$MySQLPAR/status.tbl");
&load_chromosome_tbl("$MySQLPAR/chrs.tbl");
&load_sequences_tbl("$MySQLPAR/seqs.tbl");
&load_jobs_tbl("$MySQLPAR/jobs.tbl");
if ($clear{EXEC}) {
    &del_all_from_tbl('tb_exec');
# } else {
#     &get_DB_codes();
#     &compare_execs(%status,%tstatus); 
#     &compare_execs(%chrs,%tchrs);
#     &compare_execs(%jobs,%tjobs);
# sub compare_execs() {
#     foreach $href{$key} do:
#       ALTER (chr/seq/job/step/status)_code in tb_exec if old_code != new_code
# }
};

&get_DB_codes();
&count_tbl_elements(*STDERR);

&close_DB();

&program_finished($PROG);
exit(0);

#
## SUBS
sub check_clear_var() {
    return unless $clear{ALL};
    foreach my $k (keys %clear) {
        $clear{$k} = $T;
    };
} # check_clear_var
sub listing_tables() {
    my @k = &list_tables();
    for (my $n=0; $n<=$#k; $n++) {
        &show_tbl_desc($k[$n], *STDERR);
    };
} # listing_tables
sub load_status_tbl() {
    my $ifile = shift;
    my @rows = ();
    open(IFILE,"< $ifile");
    local $/ = "\/\/\n";
    while (<IFILE>) {
        chomp;
        my @r = ();
        my @f = split /\n/og, $_;
        foreach my $l (@f) {
            next if $l =~ /^#/o;
            next if $l =~ /^\s*$/o;
            $l =~ s/^\s+//o;
            $l =~ s/\s+$//o;
            defined($r[0]) || do {
                ($r[0],$r[1]) = (split /\s+/o, $l, 2);
                next;
            };
            $r[2] .= "$l\n";
        };
        push @rows, [ @r ];
    };
    close(IFILE);
	my @flds = qw( id color descr );
    my ($tbl, @fld) = qw( tb_status 0 );
    &load_to_tbl_ifdef($tbl, \@fld, \@flds, \@rows, $T);
} # load_status_tbl
sub load_chromosome_tbl() {
    my $ifile = shift;
    my @rows = ();
    my $gpver = '';
    open(IFILE,"< $ifile");
    while (<IFILE>) {
        my @f;
        next if /^\s*$/o;
        /^#/o && do {
            /^#>#\s+(.*?)\s*$/o && ($gpver = $1);
            next;
        };
        chomp;
        s/^\s+//o;
        s/\s+$//o;
        @f = split /\s+/og, $_, 3;
        ($f[1] eq '.' && $gpver ne '') && ($f[1] = $gpver);
        push @rows, [ @f ];
    };
    close(IFILE);
	my @flds = qw( id version descr );
    my ($tbl, @fld) = qw( tb_chromosome 0 );
    &load_to_tbl_ifdef($tbl, \@fld, \@flds, \@rows, $T);
} # load_chromosome_tbl
sub load_sequences_tbl() {
    my $ifile = shift;
    my ($ctbl,$cscode,@coflds,@cqflds,$stbl,@sfld,@soflds,@sqflds);
    ($ctbl,$stbl) = qw( tb_chromosome tb_sequence );
    @coflds = qw( code );
    @cqflds = qw( id );    
    @sfld = qw( 0 1 );
    @soflds = qw( id chr length version composition descr );
    @sqflds = ();
    open(IFILE,"< $ifile");
    while (<IFILE>) {
        my @f;
        next if /^\s*$/o;
        next if /^#/o;
        chomp;
        s/^\s+//o;
        s/\s+$//o;
        @f = split /\s+/og, $_, 5;
        (@f[4,5]) = split /\s+Desc:\s+/o, $f[4], 2;
        ($cscode) = &get_row_fields($ctbl, \@coflds, \@cqflds, [ $f[0] ]);
        (@f[0,1]) = ($f[1],$cscode);
        push @sqflds, [ @f ];
        printf STDERR "%s(%d) %s %s %s\n",@f[0..2,4,5];
    };
    close(IFILE);
    &load_to_tbl_ifdef($stbl, \@sfld, \@soflds, \@sqflds, $T);
    # foreach my $row (@sqflds) {
    #     &put_row_fields($stbl, \@sfld, \@soflds, \@{ $row });
    # };
} # load_sequences_tbl
sub load_jobs_tbl() {
    my $ifile = shift;
    my ($jobcnt,$skipflg,%thsh,$ljob,$lastname);
    open(JFILE,"< $ifile");
    $jobcnt = 0;
    %tjobs = ();
    %thsh = ();
    $ljob = '';
    $skipflg = $F;
    $lastname = '';
    while (<JFILE>) {
        my ($name,$desc);
        next unless /^#>#/o;
        chomp;
        (undef,$name,$desc) = split /\s+/o, $_, 3;
        ($name ne '+' && $name ne ':') && ($lastname = $name);
        $desc =~ s/\s*$//o;
        ($name eq 'END_OF_JOB') && do {
            $skipflg || do {
                foreach my $k (keys %thsh) {
                    $tjobs{$ljob}{$k} = $thsh{$k};
                };
                &replace_link_holders(\%{ $tjobs{$ljob} },$ljob,undef,'JOB_XID');
                %{ $tjobs{$ljob}{'JOB_STEPS'} } = ();
                $tjobs{$ljob}{'JOB_FILE'} =~ s{(\$\{(.+?)\})}
                                              { defined($PARAM{$2})
                                                ? $PARAM{$2}
                                                : $1
                                                }ogex;
                &load_step_tbl($ljob,$tjobs{$ljob}{'JOB_FILE'},
                                 \%{ $tjobs{$ljob}{'JOB_STEPS'} });
            };
            %thsh = ();
            $skipflg = $F;
            next;
        };
        next if $skipflg;
        ($name eq 'JOB_ID') && do {
            $ljob = $desc;
            defined($tjobs{$ljob}) || do {
                %{ $tjobs{$ljob} } = ();
                $tjobs{$ljob}{'JOB_CNT'} = $jobcnt++;
                next;
            };
            $skipflg = $T;
            next;
        }; 
        ($name eq '+') && do {
            $thsh{$lastname} .= "$desc";
            next;
        };
        ($name eq ':') && do {
            $thsh{'JOB_DESC'} .= " $desc";
            next;
        };
        $thsh{$name} = $desc;
    };
#    print STDOUT (Data::Dumper->Dump([ \%tjobs ],
#                                  [ qw( *tjobs ) ])) if $_verbose{DEBUG};
    close(JFILE);
    &load_job_steps_tbl(\%tjobs);
} # load_jobs_tbl
sub load_step_tbl() {
    my ($sjob,$ifile,$href) = @_;
    print STDERR ">>>>>>>>>>>>>> $ifile\n";
    my ($stpcnt,$skipflg,$codeflg,%thsh,$lstep,$lastname);
    open(SFILE,"< $ifile");
    $stpcnt = 0;
    %thsh = ();
    $lstep = '';
    $skipflg = $codeflg = $F;
    $lastname = '';
    while (<SFILE>) {
        my ($name,$desc,$go);
        $go = /^#>#/o ? $T : $F;
        next unless ($go || $codeflg);
        ($codeflg && !$go) && do {
            $href->{$lstep}{'STEP_CODE'} .= "$_";
            next;
        };
        chomp;
        (undef,$name,$desc) = split /\s+/o, $_, 3;
        ($name ne '+' && $name ne ':') && ($lastname = $name);
        $desc =~ s/\s*$//o;
        ($name eq 'END_OF_STEP') && do {
            $skipflg || do {
                foreach my $k (keys %thsh) {
                    $href->{$lstep}{$k} = $thsh{$k};
                };
                &replace_link_holders(\%{ $href->{$lstep} },$sjob,$lstep,
                    'STEP_XID','STEP_IDIR','STEP_ODIR','STEP_EDIR','STEP_CODE');
#                print STDERR join("\n", 
#                           ( map { '#>>> '.$_ }
#                                 ( split /\n/o, $href->{$lstep}{'STEP_CODE'} )
#                             ) )."\n".(':'x40)."\n"; 
            };
            %thsh = ();
            $skipflg = $codeflg = $F;
            next;
        };
        next if $skipflg;
        ($name eq 'STEP_ID') && do {
            $lstep = $desc;
            defined($href->{$lstep}) || do {
                %{ $href->{$lstep} } = ();
                $href->{$lstep}{'STEP_CNT'} = $stpcnt++;
                next;
            };
            $skipflg = $T;
            next;
        }; 
        ($name eq '+') && do {
            $thsh{$lastname} .= "$desc";
            next;
        };
        ($name eq ':') && do {
            $thsh{'STEP_DESC'} .= " $desc";
            next;
        };
        ($name eq 'STEP_CODE') && do {
            $codeflg = $T;
            next;
        };
        $thsh{$name} = $desc;
    };
    close(SFILE);
} # load_step_tbl
sub replace_link_holders() {
    my ($href,$kjob,$kstp,@chk_keys) = @_;
    foreach my $k (@chk_keys) {
        $href->{$k} =~ s{\$\<(.*?){(.*?)}{(.*?)}(?:{(.*?)})?\>}
            { &get_link_vals($kjob, $kstp, $1, $2,
                             (defined($4) ? ($4, $3) : ($3, undef))); }gex;
    };
} # replace_link_holders
sub get_link_vals() {
    my ($j,$s,$v,$vj,$vv,$vs) = @_;
    my $out;
    $vj eq '.' && ($vj = $j);
    defined($vs) && do {
        $vs eq '.' && ($vs = $s);
        $out = $tjobs{$vj}{'JOB_STEPS'}{$vs}{$vv};
        print STDERR "---> $v : $out\n";
        return $out;
    };
    $out = $tjobs{$vj}{$vv};
    print STDERR "---> $v : $out\n";
    return $out;
} # get_link_vals
sub load_job_steps_tbl() {
    my $href = shift;
    my (@rows,@flds,$tbl,@fld,@oflds,@qryflds,@qryvals);
    # load jobs
    @rows = map  { $_->[1] }
            sort { $a->[0] <=> $b->[0] }
            map  { [ $href->{$_}{'JOB_CNT'},
                     [ $_, $href->{$_}{'JOB_XID'},
                           $href->{$_}{'JOB_PATH'},
                           $href->{$_}{'JOB_DESC'} ]
                   ] }
            (keys %{ $href });
	@flds = qw( id jxid path descr );
    ($tbl, @fld) = qw( tb_job 0 );
    &load_to_tbl_ifdef($tbl, \@fld, \@flds, \@rows, $T);
    # load steps
    @rows = ();
    @oflds = qw( code );
    @qryflds = qw( id );
    foreach my $k (keys %{ $href }) {
        my (@trows,$jcode,$tref);
        @qryvals = ( $k );
        ($jcode) = &get_row_fields($tbl, \@oflds, \@qryflds, \@qryvals);
        $tref = \%{ $href->{$k}{'JOB_STEPS'} };
        @trows = map  { $_->[1] }
                 sort { $a->[0] <=> $b->[0] }
                 map  { [ $tref->{$_}{'STEP_CNT'},
                          [ $_, $jcode,
                            $tref->{$_}{'STEP_XID'},
                            $tref->{$_}{'STEP_PATH'},
                            $tref->{$_}{'STEP_IDIR'},
                            $tref->{$_}{'STEP_ODIR'},
                            $tref->{$_}{'STEP_EDIR'},
                            $tref->{$_}{'STEP_DESC'},
                            $tref->{$_}{'STEP_CODE'} ]
                        ] }
                 (keys %{ $tref });
        push @rows, @trows;
    }; # foreach my $k
    @flds = qw( id job sxid path idir odir edir descr script );
    ($tbl, @fld) = qw( tb_step 0 1 );    
    &load_to_tbl_ifdef($tbl, \@fld, \@flds, \@rows, $T);
#   print STDOUT (Data::Dumper->Dump([ \@rows ],
#                                 [ qw( *rows ) ])) if $_verbose{DEBUG};
} # load_jobs_tbl
@ 


\subsctn{[[stepper.pl]]: Step processing script} %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

<<tangling: perl scripts>>=
# 
# mySQL perl scripts: running single/multiple jobs on single/multiple hosts
echo "# --> \$BIN/stepper.pl" 1>&2 ;
notangle -R'Step Execution Script' \
    $WORK/$nwfile.nw | cpif $BIN/stepper.pl ;
perl -c $BIN/stepper.pl ;
is_exec $BIN/stepper.pl ;
#
@ 

<<Step Execution Script>>=
<<PERL shebang>>
# stepper.pl
#
# USAGE:
#  stepper.pl [ --chr  chr_0,...,chr_c                 --chr  chr_cc        ]
#             [ --seq  chr_c:seq_0,...::chr_k:seq_q    --seq  chr_c:seq_qq  ]
#             [ --job  job_0,...,job_j                 --job  job_jj        ]
#             [ --step job_j:step_0,...::job_g:step_s  --step job_j:step_ss ]
#               --param <param_file> 
#               -- <jobs_file> 
#
# if no chr or seq are given then job is done for all seqs on every chr.
# if no job or step are given then all steps in all jobs are done for each seq.
# <param_file> contains all shell definitions to make child shells 
#   runnable anywhere (exported variables, shell functions, ...).
# jobs file 
use strict;
#
<<Use Modules - Dumper>>
<<stepper.pl: Use module IPC>>
<<stepper.pl: Use module POSIX>>
#
use db_Hsapiens;
#
use global;
&init_timer(\@exectime);
#
$PROG = 'stepper.pl';
$PRGVER = '0.91alpha';
# $MySQLPAR/$admfiles[$i].tbl
# my @admfiles = qw/ chrs seqs jobs steps status /;
#
## VARS
my ($pre_script,$post_script);
$pre_script = <<'+++EOPre+++';
<<BASH shebang>>
#
### SCRIPT HEADER
#
+++EOPre+++
$post_script = <<'+++EOPre+++';
#
### SCRIPT TRAILER
#
TheEnd OK;
+++EOPre+++

my %filter = ( 'CHR' => [], 'SEQ' => [], 'JOB' => [], 'STP' => [] );
my $paramfile = undef;
$global::CmdLineOpts{'c|chr=s'}   = \@{ $filter{CHR} };
$global::CmdLineOpts{'q|seq=s'}   = \@{ $filter{SEQ} };
$global::CmdLineOpts{'j|job=s'}   = \@{ $filter{JOB} };
$global::CmdLineOpts{'s|step=s'}  = \@{ $filter{STP} };
$global::CmdLineOpts{'p|param=s'} = \$paramfile;

if (!defined($paramfile)) {
    $paramfile = "./.project_VARS";
    (defined($ENV{WORK})) && ($paramfile = "$ENV{WORK}/.project_VARS");
};
( -e $paramfile && -r _ ) || die("No param file found");
      
<<stepper.pl: forked childs related vars>>
<<stepper.pl: global vars>>

#
## MAIN
&my_init_signals(); # &init_signals();
&parse_cmdline();
&program_started($PROG);
&get_param($paramfile);
&prepare_filter();
# my $stepfls = shift @ARGV;
# &get_steps($stepfls);
&open_DB();
&get_DB_codes(); # sets %chrs, $chrs{}{seqs},  @seqs,
                 #      %jobs, $jobs{}{steps}, @steps
&filtering_worklists();
&brown_dispatcher();
&close_DB();
IPC::Shareable->clean_up;
&program_finished($PROG);
exit(0);

#
## SUBS
<<stepper.pl: trapping signals>>
<<stepper.pl: subs>>
<<stepper.pl: job scheduling functions>>
@

<<stepper.pl: subs>>=
sub get_param() {
    my $ifile = shift;
    open(PFL,"< $ifile") || do {
        
        return;
    };
    while (<PFL>) {
        next if /^\s*$/o;
        $pre_script .= $_;
    }; # while PFL
    close(PFL);
} # get_param
@ 

<<stepper.pl: subs>>=
sub prepare_filter() {
    my ($k,$q,$pe);
    my %h = ( 'SEQ' => 'CHR', 'STP' => 'JOB' );
    print $ERRFH "### MAIN $gid ### PREPARING JOBS/SEQS FILTER...\n";
    foreach $k (qw/ CHR JOB /) {
        next unless (defined($filter{$k}) && scalar($filter{$k}) > 0 );
        @{ $filter{$k} } = split(/,/o,join(',',@{ $filter{$k} }));
        $q = "${k}_FILTER";
        %{ $filter{$q} } = ();
        foreach $pe (@{ $filter{$k} }) {
            @{ $filter{$q}{$pe} } = ('.*');
        }; # foreach $pe
    }; # foreach $k
    #
    foreach $k (qw/ SEQ STP /) {
        next unless (defined($filter{$k}) && scalar($filter{$k}) > 0 );
        @{ $filter{$k} } = split(/::/o,join('::',@{ $filter{$k} }));
        $q = "$h{$k}_FILTER";
        %{ $filter{$q} } = ()
             unless (defined($filter{$k}) && scalar($filter{$k}) > 0 );
        foreach $pe (@{ $filter{$k} }) {
            my ($aa,$bb,@ff,$po);
            ($aa,$bb) = split /:/o, $pe, 2;
            @ff = split /,/og, $bb;
            @{ $filter{$q}{$aa} } = ();
            foreach $po (@ff) {
                push @{ $filter{$q}{$aa} }, $po;
            }; # foreach $po
        }; # foreach $pe
    }; # foreach $k
    #
    print $ERRFH (Data::Dumper->Dump([ \%filter ],
                                  [ qw( *filter ) ])) if $_verbose{DEBUG};
} # prepare_filter
sub filtering_worklists() {
    # filtering a seqs  subset from @seqs
    if (defined($filter{'CHR_FILTER'}) &&
        scalar(keys %{ $filter{'CHR_FILTER'} }) > 0) {
        &set_filter('SEQUENCES',\@seqs, \%{ $filter{'CHR_FILTER'} });
    } else {
        print $ERRFH "### MAIN $gid ### SEQUENCES SUBSET:".
                     " RUNNING SELECTED SCRIPTS ON ALL SEQUENCES...\n";
        print $ERRFH (Data::Dumper->Dump([ \@seqs ],
                                      [ '*<SEQUENCES>' ])) if $_verbose{DEBUG};
    }; 
    # filtering a steps subset from @steps
    if (defined($filter{'JOB_FILTER'}) &&
        scalar(keys %{ $filter{'JOB_FILTER'} }) > 0 ) {
        &set_filter('STEPS',    \@steps,\%{ $filter{'JOB_FILTER'} });
    } else {
        print $ERRFH "### MAIN $gid ### STEPS SUBSET:".
                     " RUNNING ALL SCRIPTS ON SELECTED SEQUENCES...\n";
        print $ERRFH (Data::Dumper->Dump([ \@steps ],
                                        [ '*<STEPS>' ])) if $_verbose{DEBUG};
    }; 
} # filtering_worklists
sub set_filter() {
    my ($lbl,$arf,$hrf) = @_;
    my ($k,$q,$pe);
    my @ttt = ();
    print $ERRFH "### MAIN $gid ### FILTERING $lbl SUBSET TO RUN...\n";
    foreach $k (@{ $arf }) {
        my ($tsct,$telm) = @{ $k };
        (defined($hrf->{$tsct}) &&
          scalar(@{ $hrf->{$tsct} }) > 0) || do {
            print $ERRFH "### SKIPPING: $tsct NOT found on filtering array...\n";
            next;
        };
        foreach $q (@{ $hrf->{$tsct} }) {
            ($telm =~ /^$q$/) && do {
                push @ttt, [ $tsct, $telm ];
                print $ERRFH "### SELECTED: $tsct\[$telm\] matches to $tsct\[$q\]\n";
                next;
            };
            print $ERRFH "### SKIPPING: $tsct\[$telm\] does NOT match to $tsct\[$q\]\n";
        }; # foreach $q
    }; # foreach $k
    (scalar(@ttt) > 0) && do {
        print $ERRFH "### MAIN $gid ### $lbl SUBSET: selected ".
                     (scalar(@ttt))." of ".(scalar(@{$arf}))." elements.\n";
        @{$arf} = @ttt;
        print $ERRFH (Data::Dumper->Dump([ \@{$arf} ],
                                       [ '*<'.$lbl.'>' ])) if $_verbose{DEBUG};
        return;
    };
    @{$arf} = ();
    print $ERRFH "### MAIN $gid ### $lbl SUBSET: NO elements selected,".
                 " NOTHING is going to be executed...\n";
    print $ERRFH (Data::Dumper->Dump([ \@{$arf} ],
                                   [ '*<'.$lbl.'>' ])) if $_verbose{DEBUG};
} # set_filter
@ 

<<stepper.pl: subs>>=
sub get_steps() {
} # get_steps
@ 


\subsubsctn{Trapping system signals}

<<stepper.pl: Use module POSIX>>=
<<global.pm: use POSIX>>
@ 

<<stepper.pl: trapping signals>>=
#
# Trapping signals
sub my_init_signals() {
    $SIG{HUP}  = \&trap_signals_prog;
    $SIG{ABRT} = \&trap_signals;
    $SIG{INT}  = \&trap_signals;
    $SIG{QUIT} = \&trap_signals;
    $SIG{TERM} = \&trap_signals;
    $SIG{KILL} = \&trap_signals;
    $SIG{CHLD} = \&my_child_reaper; # \&child_reaper;
    @skip_next = ($F, $F, $F);
} # my_init_signals
@ 

We require the status checking function from the POSIX module we used in [[<<global.pm: trapping signals>>]] code chunk to reap zombie child processes, removing their process execution id from [[@semaphore]]. But we must redefine the child exit signal handler function to take care of the semaphore variable.

<<HIDE: stepper.pl: trapping signals>>=
# redefining child-exit signal handler (already defined in global.pm)
sub my_child_reaper() {
    my ($cpid,$ecod);
    $cpid = waitpid(-1, &WNOHANG);
    $ecod = $?;
    if (($cpid != -1) && WIFEXITED($?)) {
        if ($cpid > 0) {
            # child died
            print $ERRFH "## $cpid.$gid ## CHILD EXIT STATUS:\n".
                         "## $cpid.$gid -> $ecod\n";
        };
    };
    # $SIG{CHLD} = \&child_reaper;
} # my_child_reaper
@ 

<<stepper.pl: trapping signals>>=
sub my_child_reaper() {
    $handle->shlock();
    for (my $v = 0; $v < $maxjobs; $v++) {
        my ($spid,$cpid,$ecod);
        $semaphore[$v] =~ m/^(.*?):/o && ($spid = $1);
        ($spid != 0) && do {
            $cpid = waitpid($spid, &WNOHANG);
            $ecod = $?;
            if ($cpid > 0) {
                # child died
                print $ERRFH "## $spid.$gid ## CHILD EXIT STATUS:\n".
                             "## $spid.$gid -> $ecod\n";
            };
        }; # ($semaphore[$v][0] != 0)
    }; # for 
    $handle->shunlock();
#    $SIG{CHLD} = \&my_child_reaper;
} # my_child_reaper
@ 

<<HIDE: stepper.pl: trapping signals>>=
sub my_child_reaper() {
    $skip_next[0] $skip_next[1]
    &show_curr_pids($gid);
} # my_child_reaper
@


\subsubsctn{Forking child processes to local/remote machines}

The [[&brown_dispatcher]] function requires a semaphore variable that controls how many childs were forked, so we can fork a new one once any of the current childs job has finished (no matter where...). We require the following package, just to have such variable shared among the running child processes.

<<stepper.pl: Use module IPC>>=
use IPC::Shareable; 
IPC::Shareable->clean_up_all;
@ 

Here, we define the main function that launches child processes through [[fork]] perl function. Those child jobs are saving a temporary bash script that will be executed locally or remotely (using [[rsh]]) via a [[system]] command.

<<stepper.pl: job scheduling functions>>=
sub brown_dispatcher() {
#    my $oldFHE = $ERRFH;
#    open(FHERR, "> $TMP/run.rpt");
#    $ERRFH = \*FHERR;
    my ($seqs_done,$seqnum,@tmpsq,$thesem);
    print $ERRFH "### MAIN $gid ### BEGIN MAIN LOOP\n";
    &show_curr_pids($gid);
    $seqs_done = 0;
    $seqnum = scalar(@seqs);
    while ($seqs_done < $seqnum) { # loop through sequences
        for ($sem = 0; $sem < $maxjobs; $sem++) {
            $handle->shlock();
            $semaphore[$sem] =~ m/^(.*?):/o && ($thesem = $1);
            $handle->shunlock();
            ($thesem != 0) || do {
               next if $seqs_done == $seqnum; 
               next if (&no_host_there($hosts[$sem]));
               @tmpsq = @{ $seqs[$seqs_done] };
               &breed_crows(@tmpsq, $sem);
               @{ $pids{$pid} } = @tmpsq;
               $seqs_done++;
           }; # if job semaphore == 0 then fork child
           &do_wait();
        }; # for semaphores...
    }; # while
    while (&not_all_done()) { &do_wait(); };
    print $ERRFH "### MAIN $gid ### All Jobs ID: \n ".
                 join(" ",(sort keys %pids))."\n".
                 "### MAIN $gid ### END MAIN LOOP\n";    
#    close(FHERR);
#    $ERRFH = $oldFHE;
} # brown_dispatcher
#
sub do_wait() {
    sleep 5; # select(undef,undef,undef,1);
    &show_curr_pids($gid);
} # do_wait
sub show_curr_pids() {
    my $gd = shift;
    $handle->shlock();
    print $ERRFH "### MAIN $gd ### SEMAPHORE: ".
          (join(" ", ( map { $_ =~ m/^(.*?):/o; $1 } @semaphore )))."\n";
    $handle->shunlock();
} # show_curr_pids
sub not_all_done() {
    my $sum = 0;
    $handle->shlock();
    for (my $s = 0; $s < $maxjobs; $s++) {
        my $th;
        $semaphore[$s] =~ m/^(.*?):/o && ($th = $1);
        $sum += $th;
    }; # for semaphores...
    $handle->shunlock();
    return ($sum>0) ? $T : $F;
} # not_all_done
sub no_host_there() {
      my $host = shift;
      # print $ERRFH "### MAIN $gid ### CHECKING $host CONECTION...\n";
      ($skip_next[0]) && do {
          print $ERRFH "### MAIN $gid ### STOPPING PROGRAM: \"$host\" NOT CHECKED !!!\n";
          return $F;
      };
      ($host eq $HOST) && do { # running locally
          print $ERRFH "### MAIN $gid ### Local execution on $host...\n";
          return $F;
      };
      my $err;
      (undef,undef,$err) = 
          &check_syscall_exit(system("rsh $HOSTS{$host}[$hostip] exit 0"));
      ($err == 0) && do {
          print $ERRFH "### MAIN $gid ### Connection to $host available...\n";
          return $F;
      };
      print $ERRFH "### MAIN $gid ### UNREACHEABLE \"$host\", SKIPPING HOST !!!\n";
      return $T;
} # no_host_there
sub breed_crows() {
    my ($chrseq_code,$jobstep_code,$run_at,
        $script,$scriptx,$scripto,$scripte,$script_stat,$script_err,
        $pre_job,$chldpid,$chpid,$syscmd,$syserr);
    my ($thechr,$theseq,$pos) = @_;
    return if $pid = fork(); # return to parent, follows child code
    local *TMPFH;
    $CDATE = &get_date();
    $chrseq_code = $chrs{$thechr}{seqs}{$theseq}{code};
    $chpid = "$$";
    $chldpid = "$chpid.$gid";
    if ($skip_next[0]) {
        print $ERRFH "## $chldpid ## Skipping ALL JOBS".
                     " for sequence \"$theseq($thechr)\".\n";
        &init_DB_exec_tbl($hosts[$pos],$chldpid,$chrseq_code,
                          $status{'SKIPPED'}{'code'},
                          $exit_codes{'NOTRUN'}{SHORT},\@steps);
        exit(0); # exiting child process if skipping
    } else {
        print $ERRFH "## $chldpid ## Running child process jobs".
                     " on sequence \"$theseq\" (chr $thechr).\n";
        &init_DB_exec_tbl($hosts[$pos],$chldpid,$chrseq_code,
                          $status{'TODO'}{'code'},
                          "Job [$chldpid] has been scheduled...",\@steps);
    };
    foreach my $jobary (@steps) {
        my ($stdin,$stdout,$stderr);
        my ($thejob,$thestep) = @{ $jobary };
        $jobstep_code = $jobs{$thejob}{steps}{$thestep}{code};
        # &mod_semaphore($pos,$chldpid,$chrseq_code,$jobstep_code);
        $handle->shlock();
        $semaphore[$pos] = "$chpid\:$chrseq_code\:$jobstep_code";
        $handle->shunlock();
        ($stdin,$stdout,$stderr) = ( $jobs{$thejob}{steps}{$thestep}{idir},
                                     $jobs{$thejob}{steps}{$thestep}{odir},
                                     $jobs{$thejob}{steps}{$thestep}{edir} );
        if ($skip_next[0]) {
            $script_stat = $status{'SKIPPED'}{'code'};
            $script_err = $exit_codes{'NOTRUN'}{SHORT};
            print $ERRFH "## $chldpid ## Skipping job \"$thestep($thejob)\"".
                         " for sequence \"$theseq($thechr)\".\n";
        } else {
            $script_stat = $status{'RUNNING'}{'code'};
            $handle->shlock();
            &update_DB_exec_tbl($script_stat,$chrseq_code,$jobstep_code,
                                $hosts[$pos],$chldpid,
                                undef,"Job [$chldpid] is runnning...");
            $handle->shunlock();
            # names were shortened to avoid problem with file creation
            $script  = "$TMP/$thechr.$theseq.$jobstep_code.$chldpid";
            ($scriptx,$scripto,$scripte) =
                ("$script.x","$script.o","$script.e");
            ###
            $pre_job = <<"+++EOPre+++";
#
### CURRENT PROCESS DEFS
#
CHR="$thechr" ;
NCHR="chr\$CHR" ;
SEQ="$theseq" ;
JOB="$thejob" ;
JOBP="$jobs{$thejob}{path}" ;
STEP="$thestep" ;
XID="$jobs{$thejob}{steps}{$thestep}{sxid}" ;
MPID="$chldpid" ;
CHRDIR="\$HUMUS/\$NCHR" ;
CJBDIR="\$CHRDIR/\$JOBP" ;
JOBDIR="\$CJBDIR/\$XID" ;
IDIR="$stdin" ;
ODIR="$stdout" ;
EDIR="$stderr" ;
PSRF="$scriptx" ; # Process Status Reporter File
#
export CHR NCHR SEQ JOB JOBP STEP XID MPID      \\
       CHRDIR CJBDIR JOBDIR IDIR ODIR EDIR PSRF ;
#
# Making directories
MkDirs \$CHRDIR \$CJBDIR \$JOBDIR \$ODIR ;
[ "\$EDIR" != "\$ODIR" ] && MkDirs \$EDIR ;
#
### SCRIPT CODE
#
+++EOPre+++
            ###
            if ($hosts[$pos] ne $HOST) {
                $run_at = <<"+++EOSCRIPT+++";
# Run script remotely
#
# cat $script ;
{ rsh $HOSTS{$hosts[$pos]}[$hostip] \\
      $ENV{BIN}/remotelauncher.pl "$script > $scripto 2> $scripte" ;
  } || exit 10 ;
     # exit_code==10 if RSH fails
#
+++EOSCRIPT+++
            } else {
                $run_at = <<"+++EOSCRIPT+++";
# Run script locally
#
# cat $script ;
$ENV{BIN}/remotelauncher.pl "$script > $scripto 2> $scripte" ;
#
+++EOSCRIPT+++
            }; # if ($hosts[$pos] ne $HOST)
            ###
            print $ERRFH "## $chldpid ## Running job \"$thestep($thejob)\"".
                         " on sequence \"$theseq($thechr)\".\n".
                         "## $chldpid ## Writing script to \"$script\"...\n";
            $handle->shlock();
            open(TMPFH,"> $script");
            print TMPFH $pre_script.$pre_job.
                      $jobs{$thejob}{steps}{$thestep}{script}.$post_script;
            close(TMPFH);
            $handle->shunlock();
            ###
            $syscmd = <<"+++EOFRSH+++";
### LAUNCHING JOB: $thejob -> $thestep" ;
###   ON SEQUENCE: $thechr -> $theseq" ; 
#
/bin/chmod a+x $script ;
# Process Status Reporter File
export PSRF="$scriptx" ;
# Run Job
$run_at
# Returning exit status from executed script
c=0;
while [ \\( ! -e "\$PSRF" \\) -a \$c -lt 900 ] ; # 900sec == 15min
  do {
    sleep 2 ;
    c=`expr \$c + 2` ;
    } ;
  done ;
exit \`cat \$PSRF 2> /dev/null || echo 3\` ;
                               # exit_code==3 if cannot open PSRF (UNAVAILABLE)
### END OF JOB ###
+++EOFRSH+++
            print $ERRFH $syscmd if $_verbose{DEBUG};
            $syserr = system($syscmd);
            ###
            # print $ERRFH $mesg{};
            ($script_stat,$script_err) =
                 &report_crow_status($syserr,$thejob,$theseq,$chldpid);
        }; # else if !$skip_next[0]
        $handle->shlock();
        &update_DB_exec_tbl($script_stat,$chrseq_code,$jobstep_code,
                            $hosts[$pos],$chldpid,$stdout,$script_err);
        $handle->shunlock();
        # removing scripts once they have been run
        print $ERRFH "## $chldpid ## Removing scripts from tmp dir !!!\n";
        system("cat $scripte >> $TMP/.err/$thechr.$theseq.err");
        system("cat $scripto >> $TMP/.out/$thechr.$theseq.out");
        unlink($script,$scriptx,$scripto,$scripte);
    }; # foreach job
    # &mod_semaphore($pos,0,0,0);
    $handle->shlock();
    $semaphore[$pos] = '0:0:0';
    $handle->shunlock();
    #
    print $ERRFH "## $chldpid ## Child process is exiting now !!!\n";
    exit(0); # child process exits when done
} # breed_crows
sub mod_semaphore() {
    my ($p,$v,$sq,$jb) = @_;
    $handle->shlock();
    $semaphore[$p] = "$v\:$sq\:$jb";
    $handle->shunlock();
} # mod_semaphore
sub report_crow_status() {
    my ($err,$job,$seq,$ppid) = @_;
    my ($okflg,$emsg,$whatever,$whatelse);
    ($okflg,$emsg,$err) = &check_syscall_exit($err);
    $err = $exit_codes{'CODES'}{$err};
    print $ERRFH "## $ppid ## ERROR MSG: ".
                 ($exit_codes{$err}{MSG}->($ppid,$job,$seq,$emsg))."\n";
    $whatelse = $exit_codes{$err}{SHORT};
    $whatever = ($okflg) ? $status{'DONE'}{'code'}
                         : $status{'CHECK'}{'code'};
    return ($whatever, $whatelse);
} # report_crow_status
sub init_DB_exec_tbl() { # to db_Hsapiens.pm ?
    my ($thehost,$thepid,$seqcode,$statcode,$statstr,$stepary) = @_;
    $handle->shlock();
    foreach my $stpary (@{ $stepary }) {
        my ($j,$s) = @{ $stpary };
        &update_DB_exec_tbl($statcode,$seqcode,$jobs{$j}{steps}{$s}{code},
                            $thehost,$thepid,undef,$statstr);
    }; # foreach $stpary
    $handle->shunlock();
} # init_DB_exec_tbl
sub update_DB_exec_tbl() { # to db_Hsapiens.pm
    my ($stat,$cseq,$cstep,$chost,$ppid,$sout,$serr) = @_;
    my (@sel_fields,@data_fields,$tbl,@fld);
    defined($sout) || ($sout = 'NULL');
    defined($serr) || ($serr = 'NULL');
    if ($stat != $status{'SKIPPED'}{'code'} && $skip_next[0]) {
        # if (!defined($skip_next[1])) { # $skip_next[1] is always set as $T/$F
        #    $stat = $status{'DIED'}{'code'}; # Something happened to child
        # } else {
        if ($skip_next[1]) {
            $stat = $status{'DIED'}{'code'};
            $serr  = $exit_codes{'PROGDOWN'}{SHORT};
        } else {
            $stat = $status{'KILLED'}{'code'};
            $serr  = $exit_codes{'USERHALT'}{SHORT};
        };
        # };
    };
    ($tbl, @fld) = qw( tb_exec 0 1 ); # we do not tae care of execution PID (2)
    @sel_fields =  qw( chr_seq job_step exec_pid
                       status exec_date host user stdout stderr );
    @data_fields = ( $cseq, $cstep, $ppid,
                     $stat, $CDATE, $chost, $USER, "$sout", "$serr" );
    &put_row_fields($tbl, \@fld, \@sel_fields, \@data_fields);
} # update_DB_exec_tbl
@ 

\subsubsctn{Sequence and jobs related vars}

<<stepper.pl: global vars>>=
my $TMP = $ENV{TMP};
@ 

<<HIDE: stepper.pl: global vars>>=
my ($BASE,@seqs,@jobs,%jobscode);
$BASE = "/home/ug/jabril/development/projects/sgp/humus/tests/childs";
@@seqs = qw( seq1  seq2  seq3  seq4  seq5  seq6  seq7  seq8  seq9  seq10
            seq11 seq12 seq13 seq14 seq15 seq16 seq17 seq18 seq19 seq20 );
@@jobs = qw( job1 job2 job3 job4 job5 );
%jobscode = ();
@ 

<<stepper.pl: forked childs related vars>>=
my ($hostord,$hostjobs,$hostip,$hostbash,$hostpbs) = (0..4);
my (%HOSTS,@hosts,$hc,$gid,%pids,$pid,$maxjobs,
    $handle,$sem,@semaphore,$seqs_done);
%pids = ();
$hc = 0;
%HOSTS = (
  # hostname => [ order   numjobs  ip                  bash.p            pbsflg ]
  # aleph    => [ $hc++,  1,       '193.147.240.53',   '/bin/bash',      $T     ],
    monstre1 => [ $hc++,  1,       '193.147.240.61',   '/usr/bin/bash',  $F     ],
    monstre2 => [ $hc++,  1,       '193.147.240.62',   '/usr/bin/bash',  $F     ],
    monstre3 => [ $hc++,  1,       '193.147.240.63',   '/usr/bin/bash',  $F     ],
    monstre4 => [ $hc++,  1,       '193.147.240.64',   '/usr/bin/bash',  $F     ],
  # ik12     => [ $hc++,  1,       '193.147.240.128',  '/usr/bin/bash',  $F     ],
  # ik13     => [ $hc++,  1,       '193.147.240.129',  '/usr/bin/bash',  $F     ],
  # i8       => [ $hc++,  1,       '193.147.240.131',  '/usr/bin/bash',  $F     ],
  # i10      => [ $hc++,  1,       '193.147.240.130',  '/usr/bin/bash',  $F     ],
  # i26      => [ $hc++,  1,       '193.147.240.132',  '/usr/bin/bash',  $F     ],
    );
@@hosts = map  { shift @$_; @$_ }
         sort { $a->[0] <=> $b->[0] }
         map  { [ $HOSTS{$_}[$hostord], ($_) x $HOSTS{$_}[$hostjobs] ] }
         keys %HOSTS;
$maxjobs = scalar(@hosts);
$gid = $$;
$handle = tie @semaphore, 'IPC::Shareable', undef, { destroy => 1 };
@@semaphore = ( '0:0:0' ) x $maxjobs;
@

\subsubsctn{[[remotelauncher.pl]]: Executing remote jobs}

The following script, [[remotelauncher.pl]], prevents rsh to exit prematurely due to a NFS delay when writing the script to be launched in the remote host. It waits for a while (as much as 900 seconds), checking if script will be available from the shared disks and executing it if found or returning a 'Command not found' error.

<<tangling: perl scripts>>=
# 
echo "# --> \$BIN/remotelauncher.pl" 1>&2 ;
notangle -R'remotelauncher.pl' \
    $WORK/$nwfile.nw | cpif $BIN/remotelauncher.pl ;
perl -c $BIN/remotelauncher.pl ;
is_exec $BIN/remotelauncher.pl ;
#
@

<<remotelauncher.pl>>=
<<PERL shebang>>
# remotelauncher.pl
#
# USAGE: remotelauncher.pl <filename>
#
use strict;
<<Global Vars - Counter>>
my (@param,$err,$secs_incr);
#
@@param = split /\s+/o, "@ARGV";
#
print STDERR "###--WAITING--> $param[0] \n";
($n,$c,$_cntN,$secs_incr) = (0,".",60,2);
while (!(-x $param[0])) {
    sleep $secs_incr;
    $n += $secs_incr;
    &counter($n,$c);
    exit(127) if $n >= 900; # exit_code==127 if command not found (NOCMD) 
                            # after 900 seconds
};
&counter_end($n,$c);
#
print STDERR "###--RUNNING--> @param \n";
$err = system("@param");
exit($err);
#
sub fill_left() { ($_[2] x ($_[1] - length($_[0]))).$_[0] }
<<Common PERL subs - Counter>>
@ 


<<Checking IPC system stack>>=
# This is a bash command-line to check IPC status...
c=0;
while [ 1 ];
  do {
    clear ;
    perl -e '
      ($s,$m,$h,undef,undef,undef,undef,undef,undef) = localtime(shift @ARGV);
      print "#" x 50, sprintf(" \%02d:\%02d:\%02d\n",$h-1,$m,$s);
      ' $c;
    ipcs;
    sleep 15;
    c=`expr $c + 15`;
    };
  done;
@ 


\subsubsctn{[[viewstatustbl.pl]]: Checking current values of [[tb_exec]]}

This script is a command-line previewer of the execution table on the database, [[stv]] will be the graphical user interface to the database if we have enough time.

<<tangling: perl scripts>>=
# 
echo "# --> \$BIN/viewstatustbl.pl" 1>&2 ;
notangle -R'viewstatustbl.pl' \
    $WORK/$nwfile.nw | cpif $BIN/viewstatustbl.pl ;
perl -c $BIN/viewstatustbl.pl ;
is_exec $BIN/viewstatustbl.pl ;
#
@ 

<<viewstatustbl.pl>>=
<<PERL shebang>>
# viewstatustbl.pl
#
use strict;
use db_Hsapiens;
use global qw( :ExecReport );
&init_timer(\@exectime);
$PROG = 'viewstatustbl.pl';
$PRGVER = '0.9beta';
#
# MAIN
&program_started($PROG);
&open_DB();
&view_exec_tbl();
&close_DB();
&program_finished($PROG);
exit(0);
#
# SUBS
sub view_exec_tbl() {
    my $txt;
    $sth = $dbh->prepare(qq{
      SELECT  c.id AS C,
              s.id AS SEQNAME,
              m.id AS JOB,
              j.id AS STEP,
              t.id AS STATUS,
              x.host AS HOST,
              x.exec_pid AS PID,
              x.exec_date AS EXECDATE,
              x.stderr AS ERRORMSG
         FROM tb_chromosome AS c,
              tb_sequence AS s,
              tb_job AS m,
              tb_step AS j,
              tb_status AS t,
              tb_exec AS x
        WHERE s.chr = c.code
          AND x.chr_seq = s.code
          AND j.job = m.code
          AND x.job_step = j.code
          AND x.status = t.code
        ORDER BY c.code, s.code, m.code, j.code
           });
    $sth->execute;
    $txt = "\| \%".join("s \| \%",@{ $sth->{mysql_max_length} })."s \|\n";
    printf STDOUT $txt, @{ $sth->{NAME} };
    while (my @fld = $sth->fetchrow_array()) {
        printf STDOUT $txt, @fld;
    };
    $sth->finish;
} # view_exec_tbl
@ 


\subsctn{[[global.pm]]: Shared {\perl} code} %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

<<tangling: perl modules>>=
# 
# mySQL perl scripts: interacting with mySQL DB
echo "# --> \$LIBPERL/global.pm" 1>&2 ;
notangle -R'shared functions and settings' \
    $WORK/$nwfile.nw | cpif $LIBPERL/global.pm ;
perl -c $LIBPERL/global.pm ;
is_exec $LIBPERL/global.pm ;
#
@ 

<<shared functions and settings>>=
<<PERL shebang>>
# global.pm
#
package global;
use strict;
use vars qw(
           @ISA @EXPORT @EXPORT_OK %EXPORT_TAGS $VERSION 
           $PLVER $PROG $PRGVER $USAGE $DATE $CDATE $USER $HOST
           $T $F @skip_next @exectime %_verbose
           $ERRFH %Messages %exit_codes $EXIT_REPORT_FILE
           %CmdLineDefs %CmdLineOpts $n $c $_cntN
           );

use Exporter;
$VERSION = 1.00;
@@ISA = qw(Exporter);
@@EXPORT = qw(
           $PLVER $PROG $PRGVER $USAGE $DATE $CDATE $USER $HOST
           $T $F @skip_next %Messages %_verbose $ERRFH
           &init_timer &timing @exectime &get_date
           &init_signals &trap_signals &trap_signals_prog
           &program_started &program_finished
           &parse_cmdline %CmdLineDefs %CmdLineOpts
           &check_syscall_exit &the_end %exit_codes $EXIT_REPORT_FILE
           &match_argv_num &check_file &check_dir
           &counter &counter_end $n $c $_cntN
           &min &max
           );
@@EXPORT_OK = qw(
           &comment_line &header &left_header &right_header
           &fill_right &fill_left &fill_mid
           );
%EXPORT_TAGS = (
           # ParseCMDLN => [ qw( &parse_cmdline %CmdLineDefs %CmdLineOpts ) ],
           MathFuncts => [ qw( &min &max ) ],
           ExecReport => [ qw( $PLVER $PROG $PRGVER $USAGE 
                               $DATE $CDATE $USER $HOST $ERRFH
                               &program_started &program_finished 
                               &init_timer @exectime ) ],
           StringFill => [ qw( &fill_right &fill_left &fill_mid ) ],
           Counter    => [ qw( &counter &counter_end $n $c $_cntN ) ],
           CheckFiles => [ qw( &check_file &check_dir ) ],
           ExitStatus => [ qw( &check_syscall_exit &the_end 
                               %exit_codes $EXIT_REPORT_FILE
                               &match_argv_num $ERRFH ) ],
           );
    # AdminFunc => [ qw( &connection_details &load_to_tbl_ifdef ) ],
    # );
# use lib "$LIBPERL";

###
### Setting Default Variables
###
$ERRFH = \*STDERR;
($T,$F) = (1,0);
$PLVER = sprintf("v%vd",$^V);
$PROG  = 'UNDEF';
$PRGVER = 'UNDEF';
$USAGE = 'WARNING: Program variable "$USAGE" was not defined yet...';
$DATE  = localtime;
$CDATE = &get_date();
if (defined($ENV{USER})) {
    $USER = $ENV{USER};
} else {
    chomp($USER = `whoami`);
};
if (defined($ENV{HOSTNAME})) {
    $HOST = $ENV{HOSTNAME};
} else {
    chomp($HOST = `hostname`);
};
$HOST =~ s/\.imim\.es$//o;
if (defined($ENV{PSRF})) {
    $EXIT_REPORT_FILE = $ENV{PSRF};
} else {
    $EXIT_REPORT_FILE = "/tmp/$$";
};
<<global.pm: messages>>
<<global.pm: normalized exit codes>>

###
### Shareable functions
###
<<global.pm: timing>>
<<global.pm: trapping signals>>
<<global.pm: reporting messages>>
<<global.pm: parsing command-line args>>
<<global.pm: validate file/dir>>
<<global.pm: check exit status for sys calls>>
<<global.pm: normalized exit>>
<<global.pm: general functions>>
<<Common PERL subs - Counter>>

#
# Exiting from "global" package
1;
@
@ 

\subsubsctn{Timing processes}

<<global.pm: timing>>= 
#
# Timing definitions
use Benchmark;
@exectime = ();
sub init_timer() {
    my $refary = shift;
    @{ $refary } = (new Benchmark);
    return;
} # init_timer
sub timing() {
    my ($refary,$tmp) = @_;
    my $flg = defined($tmp) || $F;
    push @{ $refary } , (new Benchmark);
    my $mx = $#{ $refary };
    # partial time 
    $flg || do {
        return timestr(timediff($refary->[$mx],$refary->[($mx - 1)]));
    };
    # total time
    return timestr(timediff($refary->[$mx],$refary->[0]));
} # timing
sub get_date() {
    return
        sprintf("%04d%02d%02d%02d%02d%02d",
                sub { $_[5] + 1900, $_[4] + 1, $_[3], $_[2], $_[1], $_[0]
                      }->(localtime) );
} # get_date
@ 

\subsubsctn{Trapping system signals}

<<global.pm: trapping signals>>=
#
# Trapping signals
<<global.pm: use POSIX>>
sub init_signals() {
    $SIG{HUP}  = \&trap_signals_prog;
    $SIG{ABRT} = \&trap_signals;
    $SIG{INT}  = \&trap_signals;
    $SIG{QUIT} = \&trap_signals;
    $SIG{TERM} = \&trap_signals;
    $SIG{KILL} = \&trap_signals;
    $SIG{CHLD} = \&child_reaper; # 'IGNORE';
    @skip_next = ($F, undef);
} # init_signals
sub trap_signals() {
    print $ERRFH $Messages{'USER_HALT'}->($PROG);
    @skip_next = ($T, $F);
} # trap_signals
sub trap_signals_prog() {
    print $ERRFH $Messages{'PROCESS_HALT'}->($PROG);
    @skip_next = ($T, $T);
} # trap_signals_prog
@ 

Just to avoid zombie child processes we are now trying the following code\footnote{The code has been adapted from recipe 16.19, pp592, of ``Perl CookBook''} instead of setting [[$SIG{CHLD}]] to [[IGNORE]] (causing child processed to be automatically reaped), because that approach does not work reliably in our case. 
 
% $SIG{CHLD} = 'IGNORE' child processes are automatically reaped, or not ???
<<global.pm: trapping signals>>=
sub child_reaper() {
    my $cpid;
    $cpid = waitpid(-1, &WNOHANG);
    if (($cpid != -1) && WIFEXITED($?)) {
        # $skip_next[2] = $T;
        print $ERRFH $Messages{'CHILD_EXIT'}->($PROG, $cpid);
    };
    $SIG{CHLD} = \&child_reaper;
} # child_reaper
@

We also require the following module to get [[&child_reaper]] working:

<<global.pm: use POSIX>>=
use POSIX qw( :signal_h :errno_h :sys_wait_h );
@

<<global: warnings - input/output>>=
USER_HALT    => sub {
         my $name = shift;
         return
           &header(
             $mlin{'warn_len'}->(),$mlin{'warn_base'}->(),
             $mlin{'warn_pre'}->(),$mlin{'warn_post'}->(),
             $mlin{'warn_line'}->(),$mlin{'empty_warn_line'}->(),
             "$name has been stopped by user !!!",
             "---------- Exiting NOW !!! ----------",
             $mlin{'empty_warn_line'}->(),$mlin{'warn_line'}->(),
             );
     },
PROCESS_HALT => sub {
         my $name = shift;
         return
           &header(
             $mlin{'warn_len'}->(),$mlin{'warn_base'}->(),
             $mlin{'warn_pre'}->(),$mlin{'warn_post'}->(),
             $mlin{'warn_line'}->(),$mlin{'empty_warn_line'}->(),
             "------- $name is down !!! -------",
             "---------- Exiting NOW !!! ----------",
             $mlin{'empty_warn_line'}->(),$mlin{'warn_line'}->(),
             );
     },
CHILD_EXIT => sub {
         my ($cxprg,$cxpid) = @_;
         return
           &header(
	         $mlin{'warn_len'}->(),$mlin{'warn_base'}->(),
             $mlin{'warn_pre'}->(),$mlin{'warn_post'}->(),
             $mlin{'warn_line'}->(),$mlin{'empty_warn_line'}->(),
             "---- $cxprg main loop child reaper ----",
             "Child process >>$cxpid<< has died !!!",
             $mlin{'empty_warn_line'}->(),$mlin{'warn_line'}->(),
             );
     },
CHILD_KILLED => sub {
         my ($cxprg,$cxpid) = @_;
         return
           &header(
	         $mlin{'warn_len'}->(),$mlin{'warn_base'}->(),
             $mlin{'warn_pre'}->(),$mlin{'warn_post'}->(),
             $mlin{'warn_line'}->(),$mlin{'empty_warn_line'}->(),
             "---- $cxprg main loop child reaper ----",
             "Child process >>$cxpid<< has died !!!",
             $mlin{'empty_warn_line'}->(),$mlin{'warn_line'}->(),
             );
     },
@

\subsubsctn{Processing messages}

<<global.pm: messages>>=
#
# Program status strings.
($_verbose{DEBUG}, $_verbose{RAW}, $_verbose{COLOR}) = ($F) x 3;
#
use Term::ANSIColor;
my $_pre_flg = $F;
my $term_width = 80;
my %mlin = (
    error_base     => sub {
                        my $str = "\<\<\<\< ERROR \>\>\>\>";
                        $_verbose{COLOR} && 
                            ($str = color("bold red").$str.color("reset"));
                        return $str." ";
                      },
    error_pre      => sub {
                        my $str = "\<\<\<";
                        $_verbose{COLOR} && 
                            ($str = color("yellow").$str.color("reset"));
                        return $str;
                      },
    error_post     => sub {
                        my $str = "\>\>\>";
                        $_verbose{COLOR} && 
                            ($str = color("yellow").$str.color("reset"));
                        return $str;
                      },
    error_len      => sub { return ($term_width - ( 16 + 3 + 3 )) },
      # error_base + error_pre + error_post
    warn_base      => sub {
                        my $str = "\<\<\< WARNING \>\>\>";
                        $_verbose{COLOR} && 
                            ($str = color("bold yellow").$str.color("reset"));
                        return $str." ";
                      },
    warn_pre       => sub {
                        my $str = "\<\<\<";
                        $_verbose{COLOR} && 
                            ($str = color("yellow").$str.color("reset"));
                        return $str;
                      },
    warn_post      => sub {
                        my $str = "\>\>\>";
                        $_verbose{COLOR} && 
                            ($str = color("yellow").$str.color("reset"));
                        return $str;
                      },
    warn_len       => sub { return ($term_width - ( 16 + 3 + 3 )) },
      # error_base + error_pre + error_post
    comment_base   => sub { return "" },
    comment_pre    => sub {
                        my $str = "###";
                        $_verbose{COLOR} && 
                            ($str = color("green").$str.color("reset"));
                        return $str;
                      },
    comment_post   => sub {
                        my $str = "###";
                        $_verbose{COLOR} && 
                            ($str = color("green").$str.color("reset"));
                        return $str;
                      },
    comment_len    => sub { return ($term_width - ( 0 + 3 + 3 )) },
      # comment_base + comment_pre + comment_post
    dbi_base       => sub {
                        my $str = "### ";
                        $_verbose{COLOR} && 
                            ($str = color("cyan").$str.color("reset"));
                        return $str;
                      },
    dbi_pre        => sub {
                        my $str = "MySQL *";
                        $_verbose{COLOR} && 
                            ($str = color("cyan").$str.color("reset"));
                        return $str;
                      },
    dbi_post       => sub {
                        my $str = "*";
                        $_verbose{COLOR} && 
                            ($str = color("cyan").$str.color("reset"));
                        return $str;
                      },
    dbi_len        => sub { return ($term_width - ( 4 + 7 + 1 )) },
      # dbi_base + dbi_pre + dbi_post
    spacer         => sub { return "###" },
    );
#
$mlin{'error_line'} = sub {
                        my $str = ('-' x $mlin{'error_len'}->());
                        $_verbose{COLOR} && 
                            ($str = color("yellow").$str.color("reset"));
                        return $str;
                      };
$mlin{'empty_error_line'} = sub { return (' ' x $mlin{'error_len'}->()) };
#
$mlin{'warn_line'} = sub { return $mlin{'error_line'}->() };
$mlin{'empty_warn_line'} = sub { return $mlin{'empty_error_line'}->() };
#
$mlin{'comment_line'} = sub {
                        my $str = ("#" x $mlin{'comment_len'}->());
                        $_verbose{COLOR} && 
                            ($str = color("green").$str.color("reset"));
                        return $str;
                      };
$mlin{'empty_comment_line'} = sub { return (' ' x $mlin{'comment_len'}->()) };
#
$mlin{'dbi_line'} = sub {
                        my $str = ("*" x $mlin{'dbi_len'}->());
                        $_verbose{COLOR} && 
                            ($str = color("cyan").$str.color("reset"));
                        return $str;
                      };
$mlin{'empty_dbi_line'} = sub { return (' ' x $mlin{'dbi_len'}->()) };
#
%Messages = (
    # ERROR MESSAGES
    <<global: warnings - environment settings>>
    <<global: warnings - input/output>>
    <<global: warnings - parsing command-line options>>
    # WORKING MESSAGES
    <<global: messages - program start-stop>>
    <<global: messages - interacting with DB>>
    <<global: messages - parsing command-line options>>
   ); # %Messages
@

<<global.pm: reporting messages>>=
#
# Reporting program status and messages
sub comment_line() {
    my ($tlen,$base,$pre,@lns) = @_;
    my ($comment,$ln);
    foreach $ln (@lns) {
        $ln =~ s/^$/ /o; 
        $comment .= "$base$pre $ln\n";
        };
    return $comment;
} # header
sub header() {
    my ($tlen,$base,$pre,$post,@lns) = @_;
    my $comment = $_pre_flg ? $mlin{'spacer'}->()."\n" : '';
    $_pre_flg || ($_pre_flg = $T); 
    foreach my $ln (@lns) { 
        $comment .= "$base$pre".
                    (&fill_mid($ln,$tlen," "))."$post\n";
        };
    return $comment;
} # header
sub left_header() {
    my ($tlen,$base,$pre,$post,@lns) = @_;
    my $comment = $_pre_flg ? $mlin{'spacer'}->()."\n" : '';
    $_pre_flg || ($_pre_flg = $T); 
    foreach my $ln (@lns) { 
        $comment .= "$base$pre".
                    (&fill_left($ln,$tlen," "))."$post\n";
        };
    return $comment;
} # left_header
sub right_header() {
    my ($tlen,$base,$pre,$post,@lns) = @_;
    my $comment = $_pre_flg ? $mlin{'spacer'}->()."\n" : '';
    $_pre_flg || ($_pre_flg = $T); 
    foreach my $ln (@lns) { 
        $comment .= "$base$pre".
                    (&fill_right($ln,$tlen," "))."$post\n";
        };
    return $comment;
} # right_header
sub program_started() {
    my $prog = shift;
    print $ERRFH $Messages{'HEADER'}->("RUNNING $prog",'',
        "Host: $HOST","User: $USER","Perl: $PLVER",'',"Date: $DATE");
} # program_started
sub program_finished() {
    my $prog = shift;
    my $txt = &timing(\@exectime,$T);
    # $txt =~ s/(secs)\s+(\()/$1\n$2/o;
    $txt =~ s{^\s*(\d+)\s+wallclock\s+secs\s+(\()}{\n$2}o && do {
        $txt = sprintf("Total Execution Time: %02d:%02d:%02d (%d secs)%s",
                  sub { ($_[2]-1, $_[1], $_[0]) }->(localtime($1)),$1,$txt);
    };
    print $ERRFH $Messages{'HEADER'}->("$prog HAS FINISHED",'',
                 (split /\n/, $txt));
} # program_finished
@

<<global: messages - program start-stop>>=
HEADER       => sub {
         my @mssg = @_;
         return
           &header(
	         $mlin{'comment_len'}->(),$mlin{'comment_base'}->(),
             $mlin{'comment_pre'}->(),$mlin{'comment_post'}->(),
             $mlin{'comment_line'}->(),
             "", @mssg, "",
             $mlin{'comment_line'}->(),
             );
     },
@

<<global: warnings - environment settings>>=
ENVNOTDEF    => sub {
         my $mssg = shift;
         return
           &header(
             $mlin{'error_len'}->(),$mlin{'error_base'}->(),
             $mlin{'error_pre'}->(),$mlin{'error_post'}->(),
             $mlin{'error_line'}->(),$mlin{'empty_error_line'}->(),
             "Following environment variable is NOT defined: $mssg",
             $mlin{'empty_error_line'}->(),$mlin{'error_line'}->(),           
             );
     },
@

\subsubsctn{Interacting with DB standard messages}

<<global: messages - interacting with DB>>=
DBIHEADER    => sub {
         my @mssg = @_;
         return
           &right_header(
	         $mlin{'dbi_len'}->(),$mlin{'dbi_base'}->(),
             $mlin{'dbi_pre'}->(),$mlin{'dbi_post'}->(),
             $mlin{'dbi_line'}->(),
             &prespc(@mssg),
             $mlin{'dbi_line'}->(),
             );
     },
DBIMSG       => sub {
         my @mssg = @_;
         return &comment_line($mlin{'dbi_len'}->(),$mlin{'dbi_base'}->(),
                              $mlin{'dbi_pre'}->(),@mssg);
     },
DBICMD       => sub {
         my @mssg = (split /[\n]/o, $_[0]);
         @mssg = map { s/^\s{6}//o; $_ } @mssg;
         return &comment_line($mlin{'dbi_len'}->(),$mlin{'dbi_base'}->(),
                              $mlin{'dbi_pre'}->(),@mssg);
     },
@


\subsubsctn{Parsing command-line}

<<global.pm: parsing command-line args>>=
#
# Checking for exact ARGV number
sub match_argv_num() {
    my ($arg,$num) = @_;
    (scalar(@{ $arg }) != $num) && do {
        # print $ERRFH $Messages{'CMDLINE_ERROR'}->($PROG,"@ARGV");
        print $ERRFH "## $PROG ## EXITING NOW: CHECK COMMAND-LINE OPTIONS!!!\n";
        exit($exit_codes{'COMMANDLINE'}{CODE});
    };
} # match_argv_num
@ 

<<global.pm: parsing command-line args>>=
#
# Parsing command-line options
use Getopt::Long;
Getopt::Long::Configure qw/ bundling /;
%CmdLineDefs = ();
%CmdLineOpts = ();

sub parse_cmdline() {
    # we ensure here that options hash always exist 
    # (and that it has a default option: 'help')
    $CmdLineOpts{'version'} = sub { 
            print STDERR "#### Hi, you are running $PROG version $PRGVER ...\n";
            exit(1);
        };
    $CmdLineOpts{'debug'} = sub {
            ($_verbose{DEBUG}, $_verbose{RAW}) = ($T, $T);
        };
    $CmdLineOpts{'v|verbose'} = sub {
            $_verbose{RAW} = $T;
        };
    $CmdLineOpts{'V|color-verbose'} = sub {
            ($_verbose{RAW}, $_verbose{COLOR}) = ($T, $T);
        };
    $CmdLineOpts{'h|help|?'} = sub {
            print $ERRFH $Messages{'SHOW_HELP'}->($USAGE);
            exit(1);
        };
    # looking for STDIN "-" to avoid problems with GetOptions
    my $cmdln_stdin = undef;
    for (my $a = 0; $a <= $#ARGV; $a++) { 
        next unless $ARGV[$a] =~ /^-$/o;
        $cmdln_stdin = $a - $#ARGV;
        splice(@ARGV,$a,1);
    };    
    # parsing command-line
    $SIG{__WARN__} = sub {
            print $ERRFH $Messages{'CMDLINE_OPT_ERR'}->($_[0]);
        };
    GetOptions(%CmdLineOpts) || do {
            &program_started($PROG);
            print $ERRFH $Messages{'CMDLINE_ERROR'}->($PROG,"??? @ARGV");
            exit($exit_codes{'COMMANDLINE'}{CODE});
        };
    $SIG{__WARN__} = 'DEFAULT';
    # if "-" return to its position on cmd-line
    my $t = scalar(@ARGV);
    defined($cmdln_stdin) && do {
        abs($cmdln_stdin) > $t && ($cmdln_stdin = -$t);
	    $cmdln_stdin > 0  && ($cmdln_stdin = 0 );
        $t += $cmdln_stdin;
        splice(@ARGV,$t,0,'-');
    };
} # parse_cmdline
@ 

<<global: messages - parsing command-line options>>=
SHOW_HELP    => sub {
         my @mssg = split /[\n]/og, shift;
         return 
           &right_header(
	         $mlin{'comment_len'}->(),$mlin{'comment_base'}->(),
             $mlin{'comment_pre'}->(),$mlin{'comment_post'}->(),
             $mlin{'comment_line'}->(),
             &prespc(@mssg),
             $mlin{'comment_line'}->(),
             );
     },
@ 

<<global: warnings - parsing command-line options>>=
CMDLINE_OPT_ERR => sub {
         my $mssg = shift;
         $mssg =~ s/^\s*//o;
         $mssg =~ s/\s*$//o;
         return
           &right_header(
	         $mlin{'warn_len'}->(),$mlin{'warn_base'}->(),
             $mlin{'warn_pre'}->(),$mlin{'warn_post'}->(),
             $mlin{'warn_line'}->(),
             &prespc("Error trapped while processing command-line:",
                     (" "x8)."--> $mssg <--"),
             $mlin{'warn_line'}->(),
             );
     },
CMDLINE_ERROR   => sub {
         my ($name,@mssg) = @_;
         return
           &right_header(
	         $mlin{'error_len'}->(),$mlin{'error_base'}->(),
             $mlin{'error_pre'}->(),$mlin{'error_post'}->(),
             $mlin{'error_line'}->(),
             &prespc(@mssg, "",
                     "Please, check your command-line options!!!",
                     (" "x8)."Type \"$name --help\" for help..."),
             $mlin{'error_line'}->(),
             );
     },
@


\subsubsctn{Validating filenames and directories}

<<HIDE: global.pm: validate file/dir>>=
#
# Filename and directories validation
sub check_file() {
    my $stdin_flg = $F;
    &report("CHECKING_FILENAMES");
  FILECHK: foreach my $test_file (@ARGV) {
        $test_file ne '-' && do {
            -e $test_file || do {
                &warn('FILE_NO_OPEN',$T,$test_file);
                next FILECHK;
            };
            &report('READING_FILE',$test_file);
            push @data_files, $test_file;
            next FILECHK;
        };
        $stdin_flg = $T;
        push @data_files, '-';
	}; # foreach
    scalar(@data_files) == 0 && do {
        push @data_files, '-';
        $stdin_flg = $T;
    };
    $stdin_flg && &report('READING_STDIN');
} # check_file
@ 

<<warnings - input/output>>=
FILE_NO_OPEN =>
  $spl.$Warn."Cannot Open Current file \"\%s\" . Not used !!!\n".$spl,
@
<<messages - input/output>>=
CHECKING_FILENAMES =>
  $sp."### Validating INPUT FILENAMES\n".$sp,
READING_FILE =>
  "###---> \"\%s\" exists, including as Input File.\n",
READING_STDIN =>
  "###---> Including GFF records from standard input.\n",  
@

<<global.pm: validate file/dir>>=
#
sub check_dir() {
    my (@odir) = @_;
    (scalar(@odir) == 0) && (return 0);
    my @okdir = ();
    foreach my $thisdir (@odir) {
        ( -e $thisdir && -d _ ) || do {
            print $ERRFH "# Making directory: $thisdir\n";
            (mkdir $thisdir) || do {
                print $ERRFH "# Error making directory \"$thisdir\": SKIPPING !!!\n";
                push @okdir, $F;
                next;
            };
            push @okdir, $T;
            next;
        };
        print $ERRFH "# Directory \"$thisdir\" ALREADY EXIST...\n";
        push @okdir, $T; 
    }; # foreach $d
    return @okdir;
} # check_dir
@


\subsubsctn{Checking exit status for system calls}

We check for exit signals returned by system once it has run the command-line defined in [[$cmdline]] variable (we use the recipe shown in the O'Reilly book, ``Programming Perl'', 2$^n$ edition, page 230). %' 

<<global.pm: check exit status for sys calls>>=
# 
# Checking exit status for sys calls
sub check_syscall_exit() {
    my $prog_exit = 0xffff & shift;
    my ($exitflg,$exitstr) = ($F,'');
    $exitstr = sprintf("Command returned %#04x : ", $prog_exit);
    if ($prog_exit == 0) {
        $exitflg = $T;
        $exitstr .= "ran with normal exit ...";
    }
    elsif ($prog_exit == 0xff00) {
        $exitstr .= "command failed: $! ...";
    }
    elsif (($prog_exit & 0xff) == 00) {
        $prog_exit >>= 8;
        $exitstr .= "ran with non-zero exit status $prog_exit ...";
    }
    else {
        $exitstr .= "ran with ";
        if ($prog_exit &   0x80) {
            $prog_exit &= ~0x80;
            $exitstr .= "coredump from ";
            };
        $exitstr .= "signal $prog_exit ...";
    };
    return ($exitflg,$exitstr,$prog_exit);
} # check_syscall_exit
@

<<HIDE: >>=
perl -e '
  use global;
  @kmd = (
           "echo $USER",
           "echo $USER; exit;",
           "echo $USER; exit 0;",
           "echo $USER; exit 1;",
           "ls echo",
           "ls echo; exit",
           "ls echo; exit 0",
           "perl -e \"exit(0);\"",
           "perl -e \"exit(1);\"",
           "perl -e \"exit(2);\"",
         ); 
  foreach $cmd (@kmd) {
      $kk = system($cmd);
      ($f,$s) = &check_syscall_exit($kk);
      print STDOUT ("#" x 60)."\n".
                   "# Command line:\n".$cmd."\n".
                   "# Program returned signal $kk\n".
                   "# Did it run ? ".($f ? "Yes" : "No")."\n".
                   "# Diagnostics:\n$s\n\n";
  }; # foreach 
' 
@ 

\begin{table}[!t]
\begin{center}
\begin{tabular}{|lrl|}\hline
\textbf{EXIT KEY}  & \textbf{EXIT CODE}  & \textbf{DESCRIPTION} \\ \hline\hline
OK            &   0 & Everything was OK (as default) \\
KO            &   1 & Errors found (standard)        \\
UNDEF         &   2 & Unknown exit status (not defined)   \\
UNAVAILABLE   &   3 & Could not find/create status file   \\ \hline\hline
USERHALT      &   4 & Process halted by user ([[CTRL+C]]) \\
PROGHALT      &   5 & Process halted by program (kill -9) \\
PROGDOWN      &   6 & Process is down                \\
NOFORK        &   8 & Could not fork child           \\
RSH           &  10 & RSH command failed             \\
PBS           &  12 & PBS command failed             \\ \hline\hline
NOTRUN        &  13 & Program was not executed (skipping) \\
CMDKO         &  14 & Command not found or failed... \\
CKO           &  15 & C program failed...            \\
PERLKO        &  16 & PERL script failed...          \\
GAWKKO        &  17 & GAWK script failed...          \\
BASHKO        &  18 & BASH script failed...          \\
FUNCKO        &  19 & BASH user defined function failed... \\ \hline\hline
NOFILE        &  20 & File not found                 \\
NOREADFILE    &  22 & Could not open file to read    \\
NOWRITEFILE   &  24 & Could not open file to write   \\
NOAPPENDFILE  &  26 & Could not open file to append  \\
EMPTYFILE     &  28 & File was found empty...        \\ \hline
NODIR         &  30 & Dir not found                  \\
NOREADDIR     &  32 & Could not open dir to read     \\
NOWRITEDIR    &  34 & Could not open dir to write    \\
NONEWDIR      &  36 & Could not create new dir       \\
EMPTYDIR      &  38 & Dir was found empty...         \\ \hline
NOBASHPIPE    &  40 & Error found in bash pipe       \\
NOREADPIPE    &  42 & Could not open pipe to read    \\
NOWRITEPIPE   &  44 & Could not open pipe to write   \\ \hline\hline
COMMANDLINE   &  60 & Error trapped when parsing commandline options \\
BADCMDLINEOPT &  62 & Wrong command-line option forced program exit  \\
ENVERROR      &  70 & Error trapped when setting shell environment   \\
ENVUNDEFVAR   &  72 & Environment variable not defined    \\ \hline\hline
DBCONNECT     & 100 & Could not connect to DataBase  \\
NOTRANSACTION & 110 & Could not process transaction  \\ \hline\hline
NOCMD         & 127 & Command not found              \\ \hline
\end{tabular}
\caption[Exit codes definition]{\label{tbl:exitcodes} \textbf{Exit codes definition.} When running external scripts will be interesting to retrieve the cause of abnormal exiting (given that OK exit is set to its default system exit code), so we set here a fixed code error description to be shared along different scripts. This enables us to distingish between remote shell execution errors and the errors generated by submitted scripts.}
\end{center}
\end{table}

<<global.pm: normalized exit>>=
# 
# Return to program caller a "normalized" error code
sub the_end() { 
    my $k = shift || 'UNDEF';
    defined($exit_codes{$k}) || ($k = 'UNDEF');
    ($k eq 'OK' || $k eq 'KO') || do {
        $exit_codes{$k}{MSG}->();
    };
    open(XRF,"> $EXIT_REPORT_FILE") || do {
        exit($exit_codes{'UNAVAILABLE'}{CODE});
    };
    print XRF $exit_codes{$k}{CODE};
    close(XRF);
    exit($exit_codes{$k}{CODE});
} # the_end
@

<<global.pm: normalized exit codes>>=
%exit_codes = (
    'OK' => { 
         CODE  =>   0,
         SHORT => "Everything was OK",
         MSG   => sub { return $exit_codes{'OK'}{SHORT} },
         },
    'KO' => { 
         CODE  =>   1,
         SHORT => "Errors found (not specified)",
         MSG   => sub { return $exit_codes{'KO'}{SHORT} },
         },
    'UNDEF' => { 
         CODE  =>   2,
         SHORT => "Unknown exit status (not defined)",
         MSG   => sub { return $exit_codes{'UNDEF'}{SHORT} },
         },
    'UNAVAILABLE' => { 
         CODE  =>   3,
         SHORT => "Could not find/create status file",
         MSG   => sub { return $exit_codes{'UNAVAILABLE'}{SHORT} },
         },
    'USERHALT' => { 
         CODE  =>   4,
         SHORT => "Process halted by user ([[CTRL+C]])",
         MSG   => sub { return $exit_codes{'USERHALT'}{SHORT} },
         },
    'PROGHALT' => { 
         CODE  =>   5,
         SHORT => "Process halted by program (kill -9)",
         MSG   => sub { return $exit_codes{'PROGHALT'}{SHORT} },
         },
    'PROGDOWN' => { 
         CODE  =>   6,
         SHORT => "Process is down",
         MSG   => sub { return $exit_codes{'PROGDOWN'}{SHORT} },
         },
    'NOFORK' => { 
         CODE  =>   8,
         SHORT => "Could not fork child",
         MSG   => sub { return $exit_codes{'NOFORK'}{SHORT} },
         },
    'RSH' => { 
         CODE  =>  10,
         SHORT => "RSH command failed",
         MSG   => sub { return $exit_codes{'RSH'}{SHORT} },
         },
    'PBS' => { 
         CODE  =>  12,
         SHORT => "PBS command failed",
         MSG   => sub { return $exit_codes{'PBS'}{SHORT} },
         },
    'NOTRUN' => { 
         CODE  =>  13,
         SHORT => "Program was not executed",
         MSG   => sub { return $exit_codes{'NOTRUN'}{SHORT} },
         },
    'CMDKO' => { 
         CODE  =>  14,
         SHORT => "Command not found or failed...",
         MSG   => sub { return $exit_codes{'CMDKO'}{SHORT} },
         },
    'CKO' => { 
         CODE  =>  15,
         SHORT => "C program failed...",
         MSG   => sub { return $exit_codes{'CKO'}{SHORT} },
         },
    'PERLKO' => { 
         CODE  =>  16,
         SHORT => "PERL script failed...",
         MSG   => sub { return $exit_codes{'PERLKO'}{SHORT} },
         },
    'GAWKKO' => { 
         CODE  =>  17,
         SHORT => "GAWK script failed...",
         MSG   => sub { return $exit_codes{'GAWKKO'}{SHORT} },
         },
    'BASHKO' => { 
         CODE  =>  18,
         SHORT => "BASH script failed...",
         MSG   => sub { return $exit_codes{'BASHKO'}{SHORT} },
         },
    'FUNCKO' => { 
         CODE  =>  19,
         SHORT => "BASH user defined function failed...",
         MSG   => sub { return $exit_codes{'FUNCKO'}{SHORT} },
         },
    'NOFILE' => { 
         CODE  =>  20,
         SHORT => "File not found",
         MSG   => sub { return $exit_codes{'NOFILE'}{SHORT} },
         },
    'NOREADFILE' => { 
         CODE  =>  22,
         SHORT => "Could not open file to read",
         MSG   => sub { return $exit_codes{'NOREADFILE'}{SHORT} },
         },
    'NOWRITEFILE' => { 
         CODE  =>  24,
         SHORT => "Could not open file to write",
         MSG   => sub { return $exit_codes{'NOWRITEFILE'}{SHORT} },
         },
    'NOAPPENDFILE' => { 
         CODE  =>  26,
         SHORT => "Could not open file to append",
         MSG   => sub { return $exit_codes{'NOAPPENDFILE'}{SHORT} },
         },
    'EMPTYFILE' => { 
         CODE  =>  28,
         SHORT => "File was found empty...",
         MSG   => sub { return $exit_codes{'NOAPPENDFILE'}{SHORT} },
         },
    'NODIR' => { 
         CODE  =>  30,
         SHORT => "Directory not found",
         MSG   => sub { return $exit_codes{'NODIR'}{SHORT} },
         },
    'NOREADDIR' => { 
         CODE  =>  32,
         SHORT => "Could not open directory to read",
         MSG   => sub { return $exit_codes{'NOREADDIR'}{SHORT} },
         },
    'NOWRITEDIR' => { 
         CODE  =>  34,
         SHORT => "Could not open directory to write",
         MSG   => sub { return $exit_codes{'NOWRITEDIR'}{SHORT} },
         },
    'NONEWDIR' => { 
         CODE  =>  36,
         SHORT => "Could not create new directory",
         MSG   => sub { return $exit_codes{'NONEWDIR'}{SHORT} },
         },
    'EMPTYDIR' => { 
         CODE  =>  38,
         SHORT => "Dir was found empty...",
         MSG   => sub { return $exit_codes{'NONEWDIR'}{SHORT} },
         },
    'NOBASHPIPE' => { 
         CODE  =>  40,
         SHORT => "Error found in bash pipe",
         MSG   => sub { return $exit_codes{'NOBASHPIPE'}{SHORT} },
         },
    'NOREADPIPE' => { 
         CODE  =>  42,
         SHORT => "Could not open pipe to read",
         MSG   => sub { return $exit_codes{'NOREADPIPE'}{SHORT} },
         },
    'NOWRITEPIPE' => { 
         CODE  =>  44,
         SHORT => "Could not open pipe to write",
         MSG   => sub { return $exit_codes{'NOWRITEPIPE'}{SHORT} },
         },
    'COMMANDLINE' => { 
         CODE  =>  60,
         SHORT => "Error trapped when parsing commandline options",
         MSG   => sub { return $exit_codes{'COMMANDLINE'}{SHORT} },
         },
    'BADCMDLINEOPT' => { 
         CODE  =>  62,
         SHORT => "Wrong command-line option forced program exit",
         MSG   => sub { return $exit_codes{'BADCMDLINEOPT'}{SHORT} },
         },
    'ENVERROR' => { 
         CODE  =>  70,
         SHORT => "Error trapped when setting shell environment",
         MSG   => sub { return $exit_codes{'ENVERROR'}{SHORT} },
         },
    'ENVUNDEFVAR' => { 
         CODE  =>  72,
         SHORT => "Environment variable not defined",
         MSG   => sub { return $exit_codes{'ENVUNDEFVAR'}{SHORT} },
         },
    'DBCONNECT' => { 
         CODE  => 100,
         SHORT => "Could not connect to DataBase",
         MSG   => sub { return $exit_codes{'DBCONNECT'}{SHORT} },
         },
    'NOTRANSACTION' => { 
         CODE  => 110,
         SHORT => "Could not process transaction",
         MSG   => sub { return $exit_codes{'NOTRANSACTION'}{SHORT} },
         },
    'NOCMD' => { 
         CODE  => 127,
         SHORT => "Command not found",
         MSG   => sub { return $exit_codes{'NOCMD'}{SHORT} },
         },
    );
%{ $exit_codes{'CODES'} } = ( map { $exit_codes{$_}{'CODE'}, $_ }
                              keys %exit_codes );
@

\subsubsctn{Execution status helper scripts: [[exit.pl]] and [[getremoteinfo.pl]]}

<<exit.pl: retrieving status codes>>=
<<PERL shebang>>
# exit.pl
#
use strict;
use global qw( :ExitStatus );
my $key = shift @ARGV || 'UNDEF';
printf STDOUT "%d", ( defined($exit_codes{$key})
                        ? $exit_codes{$key}{CODE}
                        : $exit_codes{UNDEF}{CODE} );
exit(0);
@ 

The following short script informs us about few parameters we must check on remote machines that affect the execution of all the scripts we could launch via [[rsh]] from [[stepper.pl]]:

<<getremoteinfo.pl: checking remote hosts shared params>>=
<<PERL shebang>>
# getremoteinfo.pl
#
$MOLBIO="/usr/local/molbio";
$TMP="$MOLBIO/share/sgp/tmp";
$TMP2="/projects/H.sapiens/tmp";
# Get hostname
if (defined($ENV{HOSTNAME})) {
    $HOST = $ENV{HOSTNAME};
} else {
    chomp($HOST = `hostname`);
};
$HOST =~ s/\.imim\.es$//o;
#
chomp($WB = `which bash`);
#
# Directories that must exist in host
if (-e "$MOLBIO" && -d _) { $DIRFLG="YES" }
else { $DIRFLG=" NO" };
#
if (-e "$TMP" && -d _ ) { $TMPFLG="YES" }
else { $TMPFLG=" NO" };
$flg = 1;
open(KK,"> $TMP/kk") || ($flg = 0);
$flg && do {
    close(KK);
    unlink("$TMP/kk");
};
if ($TMPFLG eq "YES" && $flg) { $TMPWTRFLG="Writable" }
else {
    if ($TMPFLG eq "YES") {
        $TMPWTRFLG="ReadOnly";
    } else {
        $TMPWTRFLG="UnMountd";
    };
};
#
if (-e "$TMP2" && -d _ ) { $TMPFLG2="YES" }
else { $TMPFLG2=" NO" };
$flg = 1;
open(KK,"> $TMP2/kk") || ($flg = 0);
$flg && do {
    close(KK);
    unlink("$TMP2/kk");
};
if ($TMPFLG2 eq "YES" && $flg) { $TMPWTRFLG2="Writable" }
else {
    if ($TMPFLG2 eq "YES") {
        $TMPWTRFLG2="ReadOnly";
    } else {
        $TMPWTRFLG2="UnMountd";
    };
};
#
# Output required info about host
print STDOUT sprintf("--> %16s --> perl v%vd ".
                     "--> \"bash\" ? %s ".
                     "--> \"molbio\" ? %s ".
                     "--> \"tmpbin\" ? %s (%s) ".
                     "--> \"tmpprj\" ? %s (%s)\n",
       "$HOST.imim.es",$^V,$WB,$DIRFLG,$TMPFLG,$TMPWTRFLG,$TMPFLG2,$TMPWTRFLG2);
#
exit(0);
@ 

<<tangling: perl scripts>>=
# 
# Retrieve status codes from step scripts execution
echo "# --> \$BIN/exit.pl" 1>&2 ;
notangle -R'exit.pl: retrieving status codes' \
    $WORK/$nwfile.nw | cpif $BIN/exit.pl ;
perl -c $BIN/exit.pl ;
is_exec $BIN/exit.pl ;
#
echo "# --> \$BIN/getremoteinfo.pl" 1>&2 ;
notangle -R'getremoteinfo.pl: checking remote hosts shared params' \
    $WORK/$nwfile.nw | cpif $BIN/getremoteinfo.pl ;
perl -c $BIN/getremoteinfo.pl ;
is_exec $BIN/getremoteinfo.pl ;
#
for n in monstre1 monstre2 monstre3 monstre4 ik12 ik13 i8 i10 i26 aleph ;
  do {
       rsh $n.imim.es $BIN/getremoteinfo.pl ;
    } ;
  done ;
#
@ 

<<HIDE: >>=
perl -e '
  use global;
  foreach $h (keys %exit_codes) { $mesg{$exit_codes{$h}{CODE}} = $h; };
  $kk=system("echo HOLA; exit 20;");
  ($a,$b,$c)= &check_syscall_exit($kk);
  printf "## EXEC %s (%s:%s) --- flg: %s > %s\n", $kk, $c, $mesg{$c}, $a, $b;
  $ko=system <<'\''++++EOF++++'\'';
function the_end () {
  perl -e '\''use global qw( :ExitStatus );
    $a = shift @ARGV;
    printf STDOUT "%d", ( defined($exit_codes{$a})
                          ? $exit_codes{$a}{CODE}
                          : $exit_codes{UNDEF}{CODE} ); '\'' $1;
}
echo "HOLA";
exit `the_end "UNDEF"` ;
++++EOF++++
  ($a,$b,$c)= &check_syscall_exit($ko);
  printf "## EXEC %s (%s:%s) --- flg: %s > %s\n", $ko, $c, $mesg{$c}, $a, $b; '
@ 


\subsubsctn{General functions}

<<global.pm: general functions>>=
# 
# General functions
sub max() {
    my $z = shift @_;
    foreach my $l (@_) { $z = $l if $l > $z };
    return $z;
} # max
sub min() {
    my $z = shift @_;
    foreach my $l (@_) { $z = $l if $l < $z };
    return $z;
} # min
#
sub fill_right() { return $_[0].($_[2] x ($_[1] - length($_[0]))) }
sub fill_left()  { return ($_[2] x ($_[1] - length($_[0]))).$_[0] }
sub fill_mid()   { 
    my $l = length($_[0]);
    my $k = int(($_[1] - $l)/2);
    return ($_[2] x $k).$_[0].($_[2] x ($_[1] - ($l + $k)));
} # fill_mid
sub prespc() { return ( map { " $_" } @_ ); } 
@


\subsctn{Implementing scripts with [[Tk]]} %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\subsubsctn{[[stv]]: \textsc{s}tatus \textsc{t}able \textsc{v}iewer}

<<tangling: perl Tk scripts>>=
# 
# Tk perl scripts
echo "# --> \$BIN/stv" 1>&2 ;
notangle -R'stv: Status Table Viewer' $WORK/$nwfile.nw | cpif $BIN/stv ;
perl -c $BIN/stv ;
is_exec $BIN/stv ;
#
@ 

<<stv: Status Table Viewer>>=
<<PERL shebang>>
# stv - visualizing a dinamic status table in perl Tk (pTk)
#
use strict;
use Tk;
# database interface module
# use lib "$LIBPERL";
use db_Hsapiens;
#
use global;
&init_timer(\@exectime);
#
$PROG = 'stv';
$PRGVER = '0.9alpha';

<<RGB color codes hash>>
my @chrom = qw/ 1 2 3 4 X Y /; # to load from DB
my @jobs  = qw/ Masking Homology GenePred SGP /; # to load from DB
my (%col,%row); 

#
## MAIN
&parse_cmdline();
&program_started($PROG);
# Open mySQL DataBase conection
&open_DB();
# Initialize Tk table
&Init_Window();
# Infinite loop to dispatch incoming events
MainLoop();
# Disconecting from mySQL DB
&close_DB();
#
&program_finished($PROG);
exit(0);

#
## SUBS
sub Init_Window() {
    # Create main window
    my $main_window = MainWindow->new();
    $main_window->title("Status Table Viewer");

    # Instatiating widgets
    $col{HEADER} = $main_window->Frame(
                    borderwidth => 2,
                    foreground  => $color{yellow},
                    )->pack(
                        side   => 'left',
                        fill   => 'y', 
                        expand => 'y',
                        );
    $row{HEADER}{HEADER} = $col{HEADER}->Label(
                               text        => "CHR->\nPROG-v",
                             # anchor      => 'n',
                               width       => 10,
                               height      => 2,
                               foreground  => $color{black},
                               background  => $color{lightgrey},
                               borderwidth => 2,
                               )->pack();
    foreach my $j (@jobs) {
        $row{HEADER}{$j} = $col{HEADER}->Label(
                               text        => "$j",
                             # anchor      => 'n',
                               width       => 10,
                               height      => 2,
                               foreground  => $color{black},
                               background  => $color{dodgerblue}, #'lightblue',
                               borderwidth => 2,
                               )->pack();
    }; # foreach @jobs

    foreach my $j (@chrom) {
        my $frame = $main_window->Frame(
                    borderwidth => 2,
                    foreground  => $color{yellow},
                    )->pack(
                        side   => 'left',
                        fill   => 'y', 
                        expand => 'y',
                        );
        %{ $row{$j} } = (); 
        $col{$j} = $frame;
        $row{$j}{HEADER} = $col{$j}->Label(
                               text        => "Chr $j",
                             # anchor      => 'n',
                               width       => 6,
                               height      => 2,
                               foreground  => $color{black},
                               background  => $color{lightgrey},
                               borderwidth => 2,
                               )->pack();
        foreach my $i (@jobs) {
            $row{$j}{$i} = $col{$j}->Label(
                               text        => "-",
                             # anchor      => 'n',
                               width       => 6,
                               height      => 2,
                               foreground  => $color{black},
                               background  => $color{orange},
                               borderwidth => 2,
                               )->pack();
        }; # foreach @jobs
    }; # foreach @chrom
} # Init_Window
@ 

<<RGB color codes hash>>=
my %color = (
#
        'white'        => '#FFFFFF',
        'black'        => '#000000',
        'slategrey'    => '#9FB6CD',
        'grey'         => '#BEBEBE',
        'lightgrey'    => '#D3D3D3',
        'lightslategrey' => '#708090',
#
        'magenta'      => '#FF00FF',
        'lightpink'    => '#FFB6C1',
        'purple'       => '#9370DB',
        'lavender'     => '#E6E6FA',
#
        'cyan'         => '#00FFFF',
        'lightcyan'    => '#E0FFFF',
        'skyblue'      => '#87CEEB',
        'palecyan'     => '#AFEEEE',
#
        'blue'         => '#0000FF',
        'lightblue'    => '#ADD8E6',
        'steelblue'    => '#4682B4',
        'dodgerblue'   => '#1C86EE',
        'midnightblue' => '#191970',
#
        'green'        => '#00FF00',
        'seagreen'     => '#2E8B57',
        'forestgreen'  => '#228B22',
        'darkgreen'    => '#006400',
        'palegreen'    => '#98FB98',
#
        'yellow'       => '#FFFF00',
        'orange'       => '#FFA500',
        'gold'         => '#FFD700',
        'khaki'        => '#F0E68C',
#
        'red'          => '#FF0000',
        'salmon'       => '#FA8072',
        'coral'        => '#FF7F50',
        'firebrick'    => '#B22222',
#
        'brown'        => '#A52A2A',
        'siena'        => '#A0522D',
        'saddlebrown'  => '#8B4513',
        'tan'          => '#D2B48C',
        'burlywood'    => '#FFD39B',
    );
@

\subsctn{Tests} %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

<<Testing scripts: >>=
#
perl -e '
  use strict;
  my ($seq,$src,$ftr,$ori,$end,$sco,$str,$frm) = (0..7);
  my @frame = ( 3, 1, 2 ); # frm 0 -> blastfrm 3
                           # frm 1 -> blastfrm 1
                           # frm 2 -> blastfrm 2
  my %SEQlen;
  my ($chr, $seqln, $input, $odir) = @ARGV;

  &child("$odir/$chr");
  &main();
  close(STDOUT);

sub child() {
  my $base = shift;
  open(FGFF,"> $base.fullgff");
  open(CGFF,"| sort +3n -6 +6 -7 - > $base.gff");
  # reopen STDOUT in parent and return
  return if my $pid = open(STDOUT, "| -");
  die("### Cannot fork: $!") unless defined($pid);
  # process STDIN in child
  while (<STDIN>) {
      my $j = $_;
      print FGFF $j;
      next if $j =~ /^#/o;
      next if $j =~ /^\s*$/o;
      $j =~ s/;\s+Strand//o;
      $j =~ s/;\s+Frame//o;
      $j =~ s/;\s+E_value.*$//o;
      print CGFF $j;
  }; # STDIN
  # do not let child return to main!!!
  exit;
} # sub child

sub main() {
  my @files = ();
  my %g = ( "+1" => 0,  "+2" => 1,  "+3" => 2,  "+" => 3,
            "-1" => 4,  "-2" => 5,  "-3" => 6,  "-" => 7,
                       "all" => 8,            "sum" => [ (0) x 9 ] );
  my ($cf,$cr);
  open(FRGLEN, "< $seqln");
  while (<FRGLEN>) {
      next if /^#/o;
      next if /^\s*$/o;
      chomp;
      my @l = split /\s+/og, $_;
      $SEQlen{$l[0]} = $l[1];
  }; # while
  close(FRGLEN);
  open(FRGLST, "< $input.report");
  while (<FRGLST>) {
      next if /^#/o;
      next if /^\s*$/o;
      chomp;
      s/^\s*//o;
      my @l = split /\s+/og, $_;
      ($l[2] > 0) && do {
          push @files, [ $l[$#l], ($l[0] - 1) ];
      };
      # skipping fragments without HSPs
  }; # while
  close(FRGLST);
  #
  print STDERR "#\n# $chr has ".(scalar @files)." fragments (files)\n#\n# ".
               (sprintf("%8s %8s %8s  %s\n","#hsp","#hsp(+)","#hsp(-)","file"));
  system("/bin/rm","$input.parseblast.err");
  foreach my $fl (@files) {
      $cf = $cr = 0;
      my ($fname,$offset) = ("$input/$fl->[0]", $fl->[1]);
      open(TBXFL, "parseblast --fullgff --full-scores --comments".
                  " --verbose --bit-score $fname 2>> $input.parseblast.err |");
      my @l;
      while (<TBXFL>) {
          next if /^\s*$/o;
          /^#/o && do {
              print STDOUT $_;
              next;
          };
          chomp;
          @l = split /\s+/og, $_, 9;
          $l[$seq] = $chr;
          $l[$src] = "tblastx";
          $l[$ftr] = "hsp";
          $l[$ori] += $offset;
          $l[$end] += $offset;
          if ($l[$str] eq "-") {
              $l[$frm] = $frame[(($SEQlen{$chr} - $l[$end] + 1) % 3)];
              $cr++;
          } else {
              $l[$frm] = $frame[($l[$ori] % 3)];
              $cf++;
          };
          print STDOUT join("\t", @l)."\n";
          $g{sum}[$g{"$l[$str]$l[$frm]"}]++;
      }; # while
      close(TBXFL);
      printf STDERR "  %8s %8s %8s  %s\n",($cf+$cr),$cf,$cr,$fl->[0];
  }; # foreach
  $g{sum}[$g{"+"}] = $g{sum}[$g{"+1"}] + $g{sum}[$g{"+2"}] + $g{sum}[$g{"+3"}];
  $g{sum}[$g{"-"}] = $g{sum}[$g{"-1"}] + $g{sum}[$g{"-2"}] + $g{sum}[$g{"-3"}];
  $g{sum}[$g{"all"}] = $g{sum}[$g{"+"}] + $g{sum}[$g{"-"}];
  print STDERR "# TOTAL ".$g{sum}[$g{"all"}]." HSPs on $chr: ".
               $g{sum}[$g{"+"}]." forward, ".$g{sum}[$g{"-"}]." reverse.\n";
  foreach my $t (qw/ +1 +2 +3 -1 -2 -3 /) {
     printf STDERR "#\t%s : %s\n",$t,$g{sum}[$g{$t}];
  }; # foreach
} # sub main
' $CHR $SDIR/$HSAPID/length $IDIR $ODIR 2> $ODIR.report ;
#
@
 
<<Testing scripts: >>=
#
# cat > run_local_childs <<'###EOF###';
cat > run_remote_childs <<'###EOF###';
#!/usr/local/bin/perl -w
  use strict;
  use IPC::Shareable; # XAVI must install this !!!!!
  my @seqs = qw( seq1  seq2  seq3  seq4  seq5  seq6  seq7  seq8  seq9  seq10
                 seq11 seq12 seq13 seq14 seq15 seq16 seq17 seq18 seq19 seq20 );
  my @jobs = qw( job1 job2 job3 job4 job5 );
  my $BASE = "/home/ug/jabril/development/projects/sgp/humus/tests/childs";
  my %jobscode = (
      job1 => <<'$$$EOF$$$',
#
perl -e '
  ($jn,$dr) = @ARGV;
  print STDOUT "Running $jn on $ENV{CWD}: $ENV{USER} at $ENV{HOSTNAME}\n";
  print STDERR "## Output was sent to $jn.out";
  sleep(5);
  print STDERR "## Sleep period has finished";
  exit(0);
  ' "job1($MPID)" $HOME > $SEQ.job1.out 2> $SEQ.job1.err;
#
$$$EOF$$$
      job2 => <<'$$$EOF$$$',
#
STRING=`hostname`;
#
echo "HEY it is me: $USER @ $STRING" > $SEQ.job2.out 2> $SEQ.job2.err;
#
$$$EOF$$$
      job3 => <<'$$$EOF$$$',
#
STRING=`hostname`;
wc /seq/genomes/H.sapiens/golden_path_20010806/chromosomes/chr1.fa | \
  perl -e '$h = shift;
           $wc = <>;
           print "# $ENV{USER} at $h \n# File length is: $wc\n";
          ' $STRING - \
          > $SEQ.job3.out \
         2> $SEQ.job3.err ;
#
$$$EOF$$$
      job4 => "",
      job5 => "",
  );
#  $jobscode{job1} =~ s/(\n)/$1#--> /og ;
#  print STDOUT "#--> ".$jobscode{job1}."\n" ;

  my @pids = ();
  my ($pid,$sem);
  my @hosts = qw( monstre1 monstre2 monstre3 monstre4 ik12 ik13 i8 i10 i26 );
  my $maxjobs = scalar(@hosts);
  my @semaphore ;
  my $gid = $$;

  my $handle = tie @semaphore, 'IPC::Shareable', undef, { destroy => 1 };
  @semaphore = ( 0 ) x $maxjobs;

open(FHERR, "> $BASE/run.rpt");
  # BEGIN brown_dispatcher
  print FHERR "### MAIN $gid ### BEGIN MAIN LOOP\n".
              "### MAIN $gid ### SEMAPHORE: @semaphore\n";
  my $pending_seqs = scalar(@seqs);
  while ($pending_seqs > 0) {
      for ($sem = 0; $sem < $maxjobs; $sem++) {
         $semaphore[$sem] || do {
             next if (! &is_host_there($hosts[$sem]));
             next if $pending_seqs == 0; # next unless scalar(@seqs) > 0;
             &breed_crows( shift @seqs, $sem);
             push @pids, $pid;
             --$pending_seqs;
         }; # if job semaphore == 0 then fork child
         &do_wait();
      }; # for semaphores...
  }; # while
  while (&all_done(\@semaphore)) { &do_wait(); };
  print FHERR "### MAIN $gid ### All Jobs ID: \n @pids \n".
              "### MAIN $gid ### END MAIN LOOP\n";
  # END brown_dispatcher

close(FHERR);
  exit(0);

  sub do_wait() {
      sleep 1; # select(undef,undef,undef,1);
      print FHERR "### MAIN $gid ### SEMAPHORE: @semaphore\n";
  } # do_wait
  sub all_done() {
      my $aryref = shift;
      my $sum = 0;
      $handle->shlock();
      for (my $s = 0; $s < $maxjobs; $s++) {
          $sum += $semaphore[$s];
      }; # for semaphores...
      $handle->shunlock();
      return ($sum>0) ? 1 : 0;
  } # all_done
  sub is_host_there() {
      my $host = shift;
      system("rsh $host echo $host 2>/dev/null 1>&2; exit") == 0  && do {
          print FHERR "### MAIN $gid ### Connection to $host available...\n";
          return 1;
      };
      print FHERR "### MAIN $gid ### Connection to $host NOT available...\n";       
      return 0;
  } # is_host_there
  sub breed_crows() {
      my ($pre,$clhpid);
      my ($seq,$pos) = @_;
      return if $pid = fork(); # return to parent, follows child code
      $clhpid = "$$.$gid";
      $handle->shlock();
      $semaphore[$pos] = $clhpid;
      $handle->shunlock();
      print FHERR "## $clhpid ## Running child \"$clhpid\" on sequence \"$seq\".\n";
      $pre = sprintf("SEQ=$BASE/data/%s ;\nMPID=%s ;\n",$seq,$clhpid);
      foreach my $job (qw( job1 job2 job3 )) {
          print FHERR "## $clhpid ## Running job \"$job\" on sequence \"$seq\".\n";
          open(TMP,"> $BASE/tmp/$clhpid");
          print TMP $pre.$jobscode{$job};
          close(TMP);
          system <<"#@#EOF#@#"
/bin/chmod a+x $BASE/tmp/$clhpid ;
rsh $hosts[$pos].imim.es $BASE/tmp/$clhpid ;
/bin/rm $BASE/tmp/$clhpid ;
#@#EOF#@#
      }; # foreach job
      $handle->shlock();
      $semaphore[$pos] = 0;
      $handle->shunlock();
      print FHERR "## $clhpid ## Child \"$clhpid\" is going to finish.\n";
      exit(0); # child process exits when done
  } # breed_crows
###EOF###
#
@ 

<<HIDE: >>=
cat > getremoteinfo.pl <<'###EOF###';
#!/usr/local/bin/perl -w
print STDOUT sprintf("--> %s --> v%vd\n",$ENV{HOSTNAME},$^V);
###EOF###
chmod a+x getremoteinfo.pl ;
#
for n in monstre1 monstre2 monstre3 monstre4 ik12 ik13 i8 i10 i26;
  do {
     rsh $n /home/ug/jabril/development/projects/sgp/humus/tests/childs/getremoteinfo.pl;
     };
  done 
@ 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{comment}
\end{comment}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%
\newpage %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\sctn{Common code blocks}

\subsctn{PERL scripts}

<<PERL shebang>>=
#!/usr/local/bin/perl -w
# This is perl, version 5.6.1 built for i386-linux
#
<<Version Control Id Tag>>
#
@ 

<<PERL strict pragma + info>>=
use strict;
#
my $PVER = sprintf("v%vd",$^V);
my $DATE = localtime;
my ($USER,$HOST);
if (defined($ENV{USER})) {
    $USER = $ENV{USER};
} else {
    chomp($USER = `whoami`);
};
if (defined($ENV{HOSTNAME})) {
    $HOST = $ENV{HOSTNAME};
} else {
    chomp($HOST = `hostname`);
};
my $host = $HOST; ###
#
@

<<Global Constants - Boolean>>=
my ($T,$F) = (1,0); # for 'T'rue and 'F'alse
@ %def $T $F


\subsubsctn{Timing our scripts}

The '[[Benchmark]]' module encapsulates a number of routines to help to figure out how long it takes to execute a piece of code and the whole script.

<<Use Modules - Benchmark>>=
use Benchmark;
  <<Timer ON>>
@ 

See '[[man Benchmark]]' for further info about this package. 
We set an array to keep record of timing for each section.

<<Timer ON>>=
my @Timer = (new Benchmark);
@ 

<<Common PERL subs - Benchmark>>=
sub timing() {
    my $flg = shift || 0;
    push @Timer, (new Benchmark);
    # partial time 
    $flg || 
        (return timestr(timediff($Timer[$#Timer],$Timer[($#Timer - 1)])));
    # total time
    return timestr(timediff($Timer[$#Timer],$Timer[0]));
} # timing
@ 


\subsubsctn{Printing complex Data Structures}

With '[[Data::Dumper]]' we are able to pretty print complex data structures for debugging them.


<<Use Modules - Dumper>>=
use Data::Dumper;
local $Data::Dumper::Purity = 0;
local $Data::Dumper::Deepcopy = 1;
@ 


\subsubsctn{Common functions}

<<Skip comments and empty records>>=
next if /^\#/o;
next if /^\s*$/o;
chomp;
@

<<Common PERL subs - Min Max>>=
#
sub max() {
    my $z = shift @_;
    foreach my $l (@_) { $z = $l if $l > $z };
    return $z;
} # max
sub min() {
    my $z = shift @_;
    foreach my $l (@_) { $z = $l if $l < $z };
    return $z;
} # min
@

<<Common PERL subs - Text fill>>=
#
sub fill_right() { $_[0].($_[2] x ($_[1] - length($_[0]))) }
sub fill_left()  { ($_[2] x ($_[1] - length($_[0]))).$_[0] }
sub fill_mid()   { 
    my $l = length($_[0]);
    my $k = int(($_[1] - $l)/2);
    ($_[2] x $k).$_[0].($_[2] x ($_[1] - ($l+$k)));
} # fill_mid
@

These functions are used to report to STDERR a single char for each record processed (useful for reporting parsed records).

<<Common PERL subs - Counter>>=
#
sub counter { # $_[0]~current_pos++ $_[1]~char
    print STDERR "$_[1]";
    (($_[0] % $_cntN) == 0) && (print STDERR "[".&fill_left($_[0],6,"0")."]\n");
} # counter
#
sub counter_end { # $_[0]~current_pos   $_[1]~char
    (($_[0] % $_cntN) != 0) && (print STDERR "[".&fill_left($_[0],6,"0")."]\n");
} # counter_end
@

<<Global Vars - Counter>>=
my ($n,$c,$_cntN); # counter, char and width (for &counter function)
@ %def $n $c $_cntN


\subsubsctn{Common functions for reporting program processes}
\label{sec:messagerpt}

Function '[[report]]' requires that a hash variable '[[%MessageList]]' has been set, such hash contains the strings for each report message we will need. The first parameter for '[[report]]' is a key for that hash, in order to retrieve the message string, the other parameters passed are processed by the [[sprintf]] function on that string.

<<Common PERL subs - STDERR>>=
sub report() { print STDERR sprintf($MessageList{ shift @_ },@_) }
@

The same happens to '[[warn]]' function which also requires a hash variable '[[%ErrorList]]' containing the error messages.

<<Common PERL subs - STDERR>>=
sub warn() { print STDERR sprintf($ErrorList{ shift @_ }, @_) }
@

\subsctn{AWK scripts}

<<GAWK shebang>>=
#!/usr/bin/gawk -f
# GNU Awk 3.0.4
<<Version Control Id Tag>>
@

\subsctn{BASH scripts}

<<BASH shebang>>=
#!/usr/bin/bash
# GNU bash, version 2.03.6(1)-release (i386-redhat-linux-gnu)
<<Version Control Id Tag>>
@ 

<<BASH script start>>=
<<BASH shebang>>
#
SECONDS=0 # Reset Timing
# Which script are we running...
L="####################"
{ echo "$L$L$L$L";
  echo "### RUNNING [$0]";
  echo "### Current date:`date`";
  echo "###"; } 1>&2;
@

<<BASH script end>>=
{ echo "###"; echo "### Execution time for [$0] : $SECONDS secs";
  echo "$L$L$L$L";
  echo ""; } 1>&2;
#
exit 0
@

\subsctn{Version control tags}

This document is under Revision Control System (RCS). The version you are currently reading is the following:

<<Version Control Id Tag>>=
# $Id: humus.nw,v 1.33 2002-05-05 19:20:41 jabril Exp $
@ 

\newpage %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\sctn{Extracting code blocks from this document}

From this file we can obtain both the code and the
documentation. The following examples show what instructions are needed:

<<examples of tangling commands>>=
# showing line numbering comments in program
notangle -L -R"humus" $WORK/$nwfile.nw | \
   perl -ne '$.>1 && print' | cpif $BIN/humus ;
is_exec $BIN/humus ;
# reformating program with perltidy
notangle -R"humus" $WORK/$nwfile.nw | \
    perltidy - | cpif $BIN/humus ;
# html pretty-printing program with perltidy
notangle -R"humus" $WORK/$nwfile.nw | \
    perltidy -html - | cpif $DOCS/html/humus.html ;
#
@ 

\subsctn{Extracts Script code chunks from the {\noweb} file} % \\[-0.5ex]

Remember when tangling that '-L' option allows you to include program line-numbering relative to original {\noweb} file. Then the first line of the executable files is a comment, not a shebang, and must be removed to make scripts runnable.

<<tangling programs>>=
echo "# TANGLING PERL MODULES:" 1>&2 ;
<<tangling: perl modules>>
echo "# TANGLING mySQL PERL SCRIPTS:" 1>&2 ;
<<tangling: mySQL perl scripts>>
echo "# TANGLING PERL SCRIPTS:" 1>&2 ;
<<tangling: perl scripts>>
echo "# TANGLING PERL TK SCRIPTS:" 1>&2 ;
<<tangling: perl Tk scripts>>
@ 

\subsctn{Extracting different Config Files} % \\[-0.5ex]

<<tangling param files>>=
echo "# TANGLING MySQL SCRIPTS:" 1>&2 ;
<<tangling: mySQL scripts>>
echo "# TANGLING MySQL PARAM FILES:" 1>&2 ;
<<tangling: mySQL param>>
@ %$

\subsctn{Extracting documentation and \LaTeX{}'ing it} % \\[-0.5ex] %'

<<tangling complementary LaTeX files>>=
notangle -R"HIDE: LaTeX new definitions" $WORK/$nwfile.nw | \
    cpif $DOCS/defs.tex ;
notangle -R"HIDE: TODO" $WORK/$nwfile.nw | cpif $DOCS/todo.tex ; 
@ 

<<weaving>>=
<<BASH script start>>
# weaving and LaTeXing
<<BASH Environment Variables>>
<<tangling complementary LaTeX files>>
noweave -v -t4 -delay -x -filter 'elide "HIDE: *"' \
        $WORK/$nwfile.nw | cpif $DOCS/$nwfile.tex ;
# noweave -t4 -delay -index $WORK/$nwfile.nw > $DOCS/$nwfile.tex 
pushd $DOCS/ ;
#
latex $nwfile.tex ;
dvips $nwfile.dvi -o $nwfile.ps -t a4 ;
#
popd;
<<BASH script end>>
@ 

<<LaTeXing>>=
<<BASH script start>>
# only LaTeXing
<<BASH Environment Variables>>
pushd $DOCS/ ;
#
echo "### RUNNING LaTeX on $nwfile.tex" 1>&2 ;
latex $nwfile.tex ; 
latex $nwfile.tex ; 
latex $nwfile.tex ;
dvips $nwfile.dvi -o $nwfile.ps -t a4 ;
#
# pdflatex $nwfile.tex ;
echo "### CONVERTING PS to PDF: $nwfile" 1>&2 ;
ps2pdf $nwfile.ps $nwfile.pdf ;
#
popd ;
<<BASH script end>>
@ %$


\subsctn{Defining working shell variables for the current project} % \\[-0.5ex]

<<tangling shell variables>>=
# 
# BASH Environment Variables
echo "# Running notangle on $nwfile.nw: .bash_VARS" 1>&2 ;
notangle -R'BASH Environment Variables' $WORK/$nwfile.nw | \
         cpif $WORK/.bash_VARS ; 
echo "# Running notangle on $nwfile.nw: .project_VARS" 1>&2 ;
notangle -R'BASH Project Variables' $WORK/$nwfile.nw | \
         cpif $WORK/.project_VARS ;
# source $WORK/.bash_VARS ;
#
@

<<BASH Environment Variables>>=
#
# Setting Global Variables
# WORK is set by "setcwd"
WBIN="$WORK/bin" ;
WPARAM="$BIN/param" ;
WSRC="$WORK/src" ; # where to put the distributable files
DOCS="$WORK/docs" ;
DATA="$WORK/data" ;
TEST="$WORK/tests" ;
nwfile="humus" ;
export WBIN WPARAM WSRC DOCS DATA TEST nwfile ;
#
source $WORK/.project_VARS ;
@ 

<<BASH Project Variables>>=
#
umask 002 ;
#
BASE="/projects" ;
HBASE="$BASE/H.sapiens" ;
MBASE="$BASE/M.musculus" ;
export BASE HBASE MBASE ;
#
# Make these "six" vars independent from script (maybe join them with %HOSTS)
HSAP="/seq/genomes/H.sapiens/golden_path_20011222" ; # UCSC
HSAPID="20011222" ; HSAPSTR="20011222.UCSCgp" ;
HSEQ="$HSAP/chromFa" ; 
HSEQMSK="$HSAP/chromFa_msk" ; 
#
MMUS="/seq/genomes/M.musculus/MGSC_V3_20020411" ; # 
MMUSID="20020411" ; MMUSSTR="20020411.MGSCv3" ;
MSEQ="$MMUS/golden_path_200202MM/bigZips/unmasked" ; 
MSEQMSK="$MMUS/golden_path_200202MM/bigZips/masked" ; 
#
FTPTBX="$HBASE/.ftp/PankajAgarwal/20020425.tbx-20011222UCSCgp-20020411MGSCv3" ;
FTPTBXID="20020425" ;
RIKENTBX="$HBASE/.ftp/RIKEN/20020504.gparra/blast" ;
RIKENID="20020504.RIKEN" ;
MGSC_RKN="${MMUSSTR}+${RIKENID}" ;
#
export HSAP HSAPID HSAPSTR HSEQ HSEQMSK \
       MMUS MMUSID MMUSSTR MSEQ MSEQMSK \
       FTPTBX FTPTBXID RIKENTBX RIKENID MGSC_RKN ;
#
HUMUS="$HBASE/$HSAPSTR" ;
MUSHU="$MBASE/$MMUSSTR" ;
BBIN="/usr/local/molbio/share/sgp" ;
BIN="$BBIN/bin" ;
MySQLPAR="$BBIN/mySQL" ;
LIBPERL="$BBIN/libperl" ;
LIBSTEP="$BBIN/libstep" ;
SRC="$BBIN/src" ;
# TMP="$BBIN/tmp" ; # this is a read only system....
TMP="$HUMUS/tmp" ;
export HUMUS MUSHU BBIN BIN MySQLPAR LIBPERL LIBSTEP SRC TMP ;
#
<<BASH Variables: Perl>>
#
<<BASH Basic Shell Functions>>
<<BASH Functions: Handling large directories>>
<<BASH Functions: Get Gene Number from GENEID Output>>
#
MkDirs $BASE/H.sapiens $HUMUS $HUMUS/bin $TMP $BASE/M.musculus $MUSHU ;
#
@ 

<<BASH Basic Shell Functions>>=
#
# BASIC Shell Functions
#
function TheEnd ()
{
  #
  # USAGE: TheEnd <STATUS_KEY>
  # PSRF is Process Status Reporter File
  if [ "$PSRF" ] ;
  then
     SCODE=`( $BIN/exit.pl $1 | tee $PSRF ) 2> /dev/null` ;
  else
     SCODE=3 ; # UNAVAILABLE
  fi ;
  exit $SCODE ;
}
#
function MkDirs ()
{
  #
  # USAGE: MkDirs <path_list>
  #
  for name in "$@" ;
    do {
         if [ -d "$name" ] ;
         then 
           echo "### Directory Already Exist: $name" 1>&2 ;
         elif mkdir $name 2> /dev/null ;
           then
             echo "### Making New Directory   : $name" 1>&2 ;
         else
           echo "### CANNOT Create Directory: $name" 1>&2 ; 
           TheEnd NONEWDIR ; 
         fi ;
      } ;
    done ;
}
#
function is_exec ()
{
  #
  # USAGE: is_exec <filename_0>...<filename_N>
  for file in $@ ;
    do {
         if [ -x $file ] ;
         then
           echo "#    Script $file has execute permissions ..." 1>&2 ;
         else
           echo "#    Setting execute permissions for $file ..." 1>&2 ;
           chmod a+x $file 2> /dev/null ;
         fi ;
      } ;
    done ;
}
#
function CheckFile ()
{
  #
  # USAGE: CheckFile <MODE(RWAE)> <filename_0>...<filename_N>
  mode="$1" ; shift ;
  case $mode in
    R|r) tst="-r" ; err="NOREADFILE"   ; msg="readable"  ;;
    W|w) tst="-w" ; err="NOWRITEFILE"  ; msg="writeable" ;;
    A|a) tst="-w" ; err="NOAPPENDFILE" ; msg="writeable" ;;
      *) tst="-e" ; err="NOFILE"       ; msg="found"     ;;
  esac; 
  for file in "$@" ;
    do {
      if [ -f $file -a $tst $file ] ;
         then
           echo "#    $file IS $msg ..." 1>&2 ;
         else
           echo "#    $file IS NOT $msg ..." 1>&2 ;
           TheEnd $err ;
         fi ;
      } ;
    done ;
}
@

<<BASH Functions: Handling large directories>>=
#
function mega ()
{
  #
  # USAGE: mega "<command> [<cmd_params>]" <input_dir> <pattern> [<output_dir>]
  # EXAMPLES:
  #           mega "mv -v" $IDIR "^chr2_" $ODIR/ori # moves all chr2_* files
  #           mega "ls -a" $IDIR "^[^.]*"           # lists all files (not .*)
  M_CMD="$1" ;
  I_DIR=`echo $2 | sed 's/\/$//'` ;
  X_PAT="$3" ;
  [ "$4" ] && O_DIR=`echo $4 | sed 's/\/$//'` || O_DIR='' ;
  ls -1 $I_DIR | egrep $X_PAT - | while read n ;
    do {
         [ "$O_DIR" ] && T_DIR="$O_DIR/$n" || T_DIR='' ;
         $M_CMD $I_DIR/$n $T_DIR ;
       } ;
    done;
}
#
@ 

<<BASH Functions: Get Gene Number from GENEID Output>>=
#
# Counting gene number found in geneid output
function get_geneid_genes ()
{
  #
  # USAGE: get_geneid_genes geneid_out.gff > gene_list.rpt
  #
  # ($1 ~ /^\#/ && $2 ~ /^Gene$/ ) { print $0 } 
  gawk '($0 !~ /^[ \t]*$/ && $1 !~ /^\#/) {
      genes[$9]++;
      if (genes[$9]>1) {
        min[$9] = $4<min[$9] ? $4 : min[$9] ;
        max[$9] = $5>max[$9] ? $5 : max[$9] ;
      } else {
        min[$9] = $4 ;
        max[$9] = $5 ;
        strand[$9] = $7;
      };
      len[$9]+=$5-$4+1
    }
    END {
      for (n in genes) {
        print n, min[n], max[n], strand[n], len[n],genes[n];
      };
    }
  ' $1 | sort +1n +2n -3 - ;
}
#
@


\subsctn{Extracting code blocks for all the scripts}

Remember to set WORK variable at the very beggining, moving into the corresponding "[[/WORK/PATH/.../]]" directory and executing [[setcwd]] (a shell function that sets [[$WORK]] and sources [[.bash_VARS]]).

<<tangling>>=
#
# tangling all .*_VARS
notangle -R'tangling shell variables' $WORK/$nwfile.nw | bash ;
source $WORK/.bash_VARS ;
cp -v $WORK/.project_VARS $HUMUS/bin/.project_VARS;
#
notangle -Rweaving  $WORK/$nwfile.nw | cpif $WORK/nw2tex ;
notangle -RLaTeXing $WORK/$nwfile.nw | cpif $WORK/ltx ;
is_exec $WORK/nw2tex $WORK/ltx;
#
# tangling all param files
{ cat $WORK/.bash_VARS ;
  notangle -R'tangling param files' $WORK/$nwfile.nw ; } | bash ;
#
# tangling all scripts
{ cat $WORK/.bash_VARS ;
  notangle -R'tangling programs'    $WORK/$nwfile.nw ; } | bash ;
#
# tangling all steps
{ cat $WORK/.bash_VARS ;
  notangle -R'JOB COLLECTOR'        $WORK/$nwfile.nw ; } | bash ;
#
# updating LaTeX documents
$WORK/nw2tex ; $WORK/ltx ;
@ 

<<HIDE: >>=
pushd $TMP;
RM $TMP/.[eo]*/*;
$BIN/stepper.pl --debug 2> $TMP/.err/_ALL.err 1> $TMP/.out/_ALL.out
# ( $BIN/stepper.pl --debug --seq 22:chr22 --job HSAPgp_MMUScDNA_WUTBLASTX,SGP_HSAPgpa_RKNcDNA_TBX,SGP_HSAPgpa_MGSC+RKN_TBX --step SGP_HSAPgpa_MGSCv3_TBX:SGP_EVALUATION > $TMP/.out/_ALL_chr22.out ) 2>&1 | tee $TMP/.err/_ALL_chr22.err
#
ipcs -s | grep jabril | gawk '{print $2}' | while read n; do ipcrm sem $n; done;
ipcs -m | grep jabril | gawk '{print $2}' | while read n; do ipcrm shm $n; done;
#
$BIN/viewstatustbl.pl | enscript -1C -Gjf Courier5 -M A4
# homology results quick summary
( for n in 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 X Y Un ; do { N=`echo $n | tr [:lower:] [:upper:]`; [ "$N" != "UN" ] && ( echo '################################################### CHR '$n' #####'; perl -ne '/^\#\s+[cT+-]/o && print' $HUMUS/chr${N}/tblastx/20020425/hsp/chr${n}.report $HUMUS/chr${N}/tblastx/20020425/sr/chr${n}.report $HUMUS/chr${N}/sgp/20011222.UCSCgp-20020411.MGSCv3/hsp-sr/chr${n}.report ); } ; done ; for  n in 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 X Y Un ; do { N=`echo $n | tr [:lower:] [:upper:]`; { echo '########################################## CHR '$n'_random #####'; perl -ne '/^\#\s+[cT+-]/o && print' $HUMUS/chr${N}/tblastx/20020425/hsp/chr${n}_random.report $HUMUS/chr${N}/tblastx/20020425/sr/chr${n}_random.report $HUMUS/chr${N}/sgp/20011222.UCSCgp-20020411.MGSCv3/hsp-sr/chr${n}_random.report; }; } ; done ) 2>&1 | prtcode ;
# gene-pred results quick summary
( for n in 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 X Y Un ; do { N=`echo $n | tr [:lower:] [:upper:]`; { [ "$N" != "UN" ] && ( echo '################################################### CHR '$n' #####'; echo '### GENEID'; tail -20 $HUMUS/chr${N}/geneid/20011222/logs/chr${n}.geneid | egrep 'TOTAL:|Error:|segmentation fault'; head -4 $HUMUS/chr${N}/geneid/20011222/out/chr${n} ; echo '### SGP'; tail -20 $HUMUS/chr${N}/sgp/20011222.UCSCgp-20020411.MGSCv3/logs/chr${n}.sgp | egrep 'TOTAL:|Error:|segmentation fault'; head -4 $HUMUS/chr${N}/sgp/20011222.UCSCgp-20020411.MGSCv3/out/chr${n} ); }; echo ''; } ; done ; for  n in 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 X Y Un ; do { N=`echo $n | tr [:lower:] [:upper:]`; { echo '########################################## CHR '$n'_random #####'; echo '### GENEID'; tail -20 $HUMUS/chr${N}/geneid/20011222/logs/chr${n}_random.geneid | egrep 'TOTAL:|Error:|segmentation fault'; head -4 $HUMUS/chr${N}/geneid/20011222/out/chr${n}_random ; echo '### SGP'; tail -20 $HUMUS/chr${N}/sgp/20011222.UCSCgp-20020411.MGSCv3/logs/chr${n}_random.sgp | egrep 'TOTAL:|Error:|segmentation fault'; head -4 $HUMUS/chr${N}/sgp/20011222.UCSCgp-20020411.MGSCv3/out/chr${n}_random; }; echo ''; } ; done ) 2>&1 | prtcode ;
# gene-pred evaluation quick summary
# source $WORK/.bash_VARS ; $BIN/stepper.pl --step HSAP_GP_ANNOTATION:HSAP_GP_REFSEQ,HSAP_GP_ENSEMBL,HSAP_GP_GENSCAN,HSAP_GP_GENSCAN_EVAL --step HSAPgpa_MGSCv3_WUTBLASTX:EVALUATING_SRs --step GENEID_STD:GENEID_EVALUATION --step SGP_HSAPgpa_MGSCv3_TBX:SGP_EVALUATION  > $HUMUS/tmp/.err/_ALL_eval_t.err  2>&1 ;
#
egrep 'Error:|segmentation fault' $HUMUS/chr*/annotation/20011222/genscan/eval/chr*.genscan_*.[fr]?? ; egrep 'Error:|segmentation fault' $HUMUS/chr*/tblastx/20020425/eval/chr*.sr_*.[fr]?? ; egrep 'Error:|segmentation fault' $HUMUS/chr*/geneid/20011222/eval/chr*.geneid_*.[fr]?? ; egrep 'Error:|segmentation fault' $HUMUS/chr*/sgp/20011222.UCSCgp-20020411.MGSCv3/eval/chr*.sgp_*.[fr]?? ;
#
( for  n in 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 X Y Un ; do { N=`echo $n | tr [:lower:] [:upper:]`; { [ "$N" != "UN" ] && ( echo '################################################### CHR '$n' #####'; echo '### GENSCAN'; cat $HUMUS/chr${N}/annotation/20011222/genscan/eval/chr${n}.summary ; echo '### SRs'; cat $HUMUS/chr${N}/tblastx/20020425/eval/chr${n}.summary ; echo '### GENEID';  cat $HUMUS/chr${N}/geneid/20011222/eval/chr${n}.summary ; echo '### SGP';  cat $HUMUS/chr${N}/sgp/20011222.UCSCgp-20020411.MGSCv3/eval/chr${n}.summary ); };  echo ''; } ; done ; for  n in 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 X Y Un ; do { N=`echo $n | tr [:lower:] [:upper:]`; { echo '################################################### CHR '$n'_random #####'; echo '### GENSCAN'; cat $HUMUS/chr${N}/annotation/20011222/genscan/eval/chr${n}_random.summary ; echo '### SRs'; cat $HUMUS/chr${N}/tblastx/20020425/eval/chr${n}_random.summary ; echo '### GENEID';  cat $HUMUS/chr${N}/geneid/20011222/eval/chr${n}_random.summary ; echo '### SGP';  cat $HUMUS/chr${N}/sgp/20011222.UCSCgp-20020411.MGSCv3/eval/chr${n}_random.summary; };  echo ''; } ; done ) 2>&1  > $HUMUS/evaluations/EVAL.summary ;
$BIN/process_eval.pl    $HUMUS/evaluations/EVAL.summary > $HUMUS/evaluations/EVAL_prog.summary ;
$BIN/process_eval.pl -t $HUMUS/evaluations/EVAL.summary > $HUMUS/evaluations/EVAL_test.summary ;
enscript -1rC -Gjf Courier5 -M A4 $HUMUS/evaluations/EVAL.summary ;
enscript -1rC -Gjf Courier5 -M A4 $HUMUS/evaluations/EVAL_prog.summary ;
enscript -1rC -Gjf Courier5 -M A4 $HUMUS/evaluations/EVAL_test.summary ;
@ 

%
\end{document}
%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% pushd $HBASE/.fpt/PankajAgarwal/20020111.tbx-20010806UCSCgp-20011109SCphusion; ls -1 | while read n; do { gzip -v --best $n; }; done; popd
% gawk '{print $1, $2}' seqid_list | while read CHR SEQ; do { echo "### $CHR --> $SEQ"; p="chr$CHR/tblastx/20020111/ori/$SEQ/" ; ( ls -1 $p | gawk "{ print \"$p\"\$1 }" | while read n; do { gzip -v --best $n; }; done; ); }; done
%
%  n <- 10
%  g <- gl(n, 100, n * 100)
%  x <- rnorm(n * 100) + sqrt(codes(g)) 
%  boxplot(split(x, g), col = "lavender", notch = TRUE)
%  title(main = "Notched Boxplots", xlab = "Group", font.main = 4,
%    font.lab = 1)
%  par(bg = "white")
%  n <- 100
%  x <- c(0, cumsum(rnorm(n)))
%  y <- c(0, cumsum(rnorm(n)))
%  xx <- c(0:n, n:0)
%  yy <- c(x, rev(y))
